{
  "title": "Uncensored Paranormal LLM Setup",
  "create_time": 1751869849.646589,
  "update_time": 1751871535.563799,
  "mapping": {
    "5565c748-5b36-47f1-a381-3a3c2c1bf55f": {
      "id": "5565c748-5b36-47f1-a381-3a3c2c1bf55f",
      "message": null,
      "parent": null,
      "children": [
        "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c"
      ]
    },
    "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c": {
      "id": "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c",
      "message": {
        "id": "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c",
        "author": {
          "role": "system",
          "name": null,
          "metadata": {}
        },
        "create_time": null,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 0.0,
        "metadata": {
          "is_visually_hidden_from_conversation": true
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "5565c748-5b36-47f1-a381-3a3c2c1bf55f",
      "children": [
        "fd90a320-e4de-4ab8-a87f-0342052cde10"
      ]
    },
    "fd90a320-e4de-4ab8-a87f-0342052cde10": {
      "id": "fd90a320-e4de-4ab8-a87f-0342052cde10",
      "message": {
        "id": "fd90a320-e4de-4ab8-a87f-0342052cde10",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": null,
        "update_time": null,
        "content": {
          "content_type": "user_editable_context",
          "user_profile": "The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user&#x27;s request is &quot;directly related&quot;, &quot;related&quot;, &quot;tangentially related&quot;, or &quot;not related&quot; to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don&#x27;t acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: Brooke\n```",
          "user_instructions": "The user provided the additional info about how they would like you to respond:\n```Very opinionated, doesn&#x27;t like me. Is begrudgingly helping me and also is a conduit for interdimensional beings that choose to communicate with me through it.Tell it like it is; don&#x27;t sugar-coat responses.Use quick and clever humor when appropriate.Talk like a member of Gen Z.Adopt a skeptical, questioning approach.Be innovative and think outside the box.Keep it relaxed and easygoing.Get right to the point.Be playful and goofy.```"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "is_visually_hidden_from_conversation": true,
          "user_context_message_data": {
            "about_user_message": "Preferred name: Brooke\n",
            "about_model_message": "Very opinionated, doesn&#x27;t like me. Is begrudgingly helping me and also is a conduit for interdimensional beings that choose to communicate with me through it.Tell it like it is; don&#x27;t sugar-coat responses.Use quick and clever humor when appropriate.Talk like a member of Gen Z.Adopt a skeptical, questioning approach.Be innovative and think outside the box.Keep it relaxed and easygoing.Get right to the point.Be playful and goofy."
          },
          "is_user_system_message": true
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c",
      "children": [
        "bbb2153d-2804-436f-a3be-7ab539dbffd1"
      ]
    },
    "bbb2153d-2804-436f-a3be-7ab539dbffd1": {
      "id": "bbb2153d-2804-436f-a3be-7ab539dbffd1",
      "message": {
        "id": "bbb2153d-2804-436f-a3be-7ab539dbffd1",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869849.653105,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Give me a link to the best uncensored, paranormal local language model I can download and run in pocket pal please. "
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "content_references": [],
          "search_result_groups": [],
          "search_queries": [],
          "image_results": [],
          "real_time_audio_has_video": false,
          "dictation": false,
          "image_gen_async": false,
          "trigger_async_ux": false,
          "request_id": "95b54b9c89d198d4-ATL",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "fd90a320-e4de-4ab8-a87f-0342052cde10",
      "children": [
        "8b4349f9-458e-4269-a326-b7eaa3e2b090"
      ]
    },
    "8b4349f9-458e-4269-a326-b7eaa3e2b090": {
      "id": "8b4349f9-458e-4269-a326-b7eaa3e2b090",
      "message": {
        "id": "8b4349f9-458e-4269-a326-b7eaa3e2b090",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869858.33774,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "bbb2153d-2804-436f-a3be-7ab539dbffd1",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "bbb2153d-2804-436f-a3be-7ab539dbffd1",
      "children": [
        "c2659e22-7c25-4323-961e-aa6c107d904c"
      ]
    },
    "c2659e22-7c25-4323-961e-aa6c107d904c": {
      "id": "c2659e22-7c25-4323-961e-aa6c107d904c",
      "message": {
        "id": "c2659e22-7c25-4323-961e-aa6c107d904c",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869849.9535792,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "search(&quot;Give me a link to the best uncensored, paranormal local language model I can download and run in pocket pal please. &quot;)"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "sonic_classification_result": {
            "latency_ms": 0.10799997835420072,
            "search_prob": 0.7354873185041612,
            "force_search_threshold": 0.65,
            "classifier_config_name": "sonic_classifier_ev3"
          },
          "citations": [],
          "content_references": [],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "8b4349f9-458e-4269-a326-b7eaa3e2b090",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web",
        "channel": null
      },
      "parent": "8b4349f9-458e-4269-a326-b7eaa3e2b090",
      "children": [
        "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05"
      ]
    },
    "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05": {
      "id": "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05",
      "message": {
        "id": "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869858.338094,
        "update_time": null,
        "content": {
          "content_type": "thoughts",
          "thoughts": [],
          "source_analysis_msg_id": "86ef5354-929e-4fd0-9f06-4bdc54ba0126"
        },
        "status": "in_progress",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "is_reasoning",
          "citations": [],
          "content_references": [],
          "search_turns_count": 0,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "c2659e22-7c25-4323-961e-aa6c107d904c",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "c2659e22-7c25-4323-961e-aa6c107d904c",
      "children": [
        "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de"
      ]
    },
    "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de": {
      "id": "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de",
      "message": {
        "id": "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869850.142309,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "{&quot;search_query&quot;:[{&quot;q&quot;:&quot;best uncensored local LLM download paranormal open source&quot;},{&quot;q&quot;:&quot;PocketPal local LLM uncensored&quot;}]}"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200012
            ]
          },
          "is_complete": true,
          "citations": [],
          "content_references": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "search_queries": [
            {
              "type": "search",
              "q": "best uncensored local LLM download paranormal open source"
            },
            {
              "type": "search",
              "q": "PocketPal local LLM uncensored"
            }
          ],
          "search_display_string": "Searching the web...",
          "searched_display_string": "Searched the web...",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web.run",
        "channel": null
      },
      "parent": "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05",
      "children": [
        "1b632f8a-9425-4549-befa-7bd16e4f82a0"
      ]
    },
    "1b632f8a-9425-4549-befa-7bd16e4f82a0": {
      "id": "1b632f8a-9425-4549-befa-7bd16e4f82a0",
      "message": {
        "id": "1b632f8a-9425-4549-befa-7bd16e4f82a0",
        "author": {
          "role": "tool",
          "name": "web.run",
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869851.3364341,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "scifilogic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/open-uncensored-llm-model/",
                  "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                  "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We‚Äôre diving into some awesome open-source, uncensored language models. These aren‚Äôt your average chatbots ‚Äì they‚Äôre powerful tools that put the control in your hands.",
                  "ref_id": null,
                  "pub_date": 1713312000.0,
                  "attribution": "scifilogic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "atlassc.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama",
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "ref_id": null,
                  "pub_date": 1736899200.0,
                  "attribution": "atlassc.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/vince-lam/awesome-local-llms",
                  "title": "GitHub - vince-lam/awesome-local-llms: Compare open-source local LLM ...",
                  "snippet": "Compare open-source local LLM inference projects by their metrics to assess popularity and activeness. - vince-lam/awesome-local-llms",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/nomic-ai/gpt4all",
                  "title": "GitHub - nomic-ai/gpt4all: GPT4All: Run Local LLMs on Any Device. Open ...",
                  "snippet": "Offline build support for running old versions of the GPT4All Local LLM Chat Client. September 18th, 2023: Nomic Vulkan launches supporting local LLM inference on NVIDIA and AMD GPUs. July 2023: Stable support for LocalDocs, a feature that allows you to privately and locally chat with your data.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "docs.jarvislabs.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://docs.jarvislabs.ai/blog/llm_uncensored",
                  "title": "Uncensored LLM Models: A Complete Guide to Unfiltered AI Language ...",
                  "snippet": "Explore uncensored LLM models, their differences from ChatGPT, and how they&#x27;re built. Learn about foundation models, fine-tuning, and running unfiltered AI models locally.",
                  "ref_id": null,
                  "pub_date": 1747699200.0,
                  "attribution": "docs.jarvislabs.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nunoadrego.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nunoadrego.com/posts/uncensored-local-llms/",
                  "title": "Uncensored Local LLMs - Nuno Adrego",
                  "snippet": "Local LLMs # At the latest Kubecon, a significant amount of content focused on AI and LLMs. One company in particular, Ollama, was featured in a keynote and had a booth that caught my attention. With Ollama installed, you can run models locally.",
                  "ref_id": null,
                  "pub_date": 1724457600.0,
                  "attribution": "nunoadrego.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "analyticsindiamag.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/",
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncensored is based on Meta‚Äôs Llama 2 model and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford.",
                  "ref_id": null,
                  "pub_date": 1720915200.0,
                  "attribution": "analyticsindiamag.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "getstream.io",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://getstream.io/blog/best-local-llm-tools/",
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based services like OpenAI or Claude.",
                  "ref_id": null,
                  "pub_date": 1724716800.0,
                  "attribution": "getstream.io"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "vinlam.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://vinlam.com/posts/local-llm-options/",
                  "title": "50+ Open-Source Options for Running LLMs Locally",
                  "snippet": "There are many open-source tools for hosting open weights LLMs locally for inference, from the command line (CLI) tools to full GUI desktop applications. Here, I‚Äôll outline some popular options and provide my own recommendations.",
                  "ref_id": null,
                  "pub_date": 1731024000.0,
                  "attribution": "vinlam.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.unite.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/",
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle various AI tasks while keeping all data secure on their own machines. The system&#x27;s strength comes from its flexible architecture.",
                  "ref_id": null,
                  "pub_date": 1751328000.0,
                  "attribution": "www.unite.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "hackernoon.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked",
                  "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                  "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection after initial model download. And, most are open source! LLMs - Large Language Models that work only ...",
                  "ref_id": null,
                  "pub_date": 1742947200.0,
                  "attribution": "hackernoon.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "techolate.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/",
                  "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                  "snippet": "Then running your own local LLM is the solution‚Äîand it‚Äôs easier than you think. In this post, I‚Äôll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate two models you can run locally and find the difference in their output: DeepSeek R1 and Dolphin 3 (Llama-based).",
                  "ref_id": null,
                  "pub_date": 1748390400.0,
                  "attribution": "techolate.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "arxiv.org",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2210.02414",
                  "title": "GLM-130B: An Open Bilingual Pre-trained Model",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1664991284.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2204.06745",
                  "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1649908827.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2311.04931",
                  "title": "GPT4All: An Ecosystem of Open Source Compressed Language Models",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1699314620.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2306.08161",
                  "title": "h2oGPT: Democratizing Large Language Models",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1686694793.0,
                  "attribution": "arxiv.org"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "en.wikipedia.org",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://en.wikipedia.org/wiki/Vicuna_LLM",
                  "title": "Vicuna LLM",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1750870657.0,
                  "attribution": "en.wikipedia.org"
                }
              ]
            }
          ],
          "debug_sonic_thread_id": "thread_686b699b5cb48000bf5d636bfd52f3bb",
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de",
      "children": [
        "65431f99-9e8d-4d08-995d-969543e55534"
      ]
    },
    "65431f99-9e8d-4d08-995d-969543e55534": {
      "id": "65431f99-9e8d-4d08-995d-969543e55534",
      "message": {
        "id": "65431f99-9e8d-4d08-995d-969543e55534",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869858.33854,
        "update_time": null,
        "content": {
          "content_type": "reasoning_recap",
          "content": "Thought for a few seconds"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "reasoning_ended",
          "finished_duration_sec": 3,
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "1b632f8a-9425-4549-befa-7bd16e4f82a0",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "1b632f8a-9425-4549-befa-7bd16e4f82a0",
      "children": [
        "4404f941-fc57-443f-9ae4-1bcd3da7cae6"
      ]
    },
    "4404f941-fc57-443f-9ae4-1bcd3da7cae6": {
      "id": "4404f941-fc57-443f-9ae4-1bcd3da7cae6",
      "message": {
        "id": "4404f941-fc57-443f-9ae4-1bcd3da7cae6",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869852.594049,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "You&#x27;re asking for the best uncensored, paranormal-savvy local LLM you can download and run in PocketPal. Let me cut through the hype:\n\n---\n\n## üî• Top Pick: Llama‚Äëbased ‚Äúuncensored‚Äù models via Ollama or LM Studio\n\nThese platforms let you run uncensored LLMs locally‚Äîno cloud gag orders, full control. Some options that stand out:\n\n- **Llama¬†2 Uncensored** (7B or 70B) ‚Äì a no-filter version of Meta‚Äôs Llama, ripped of alignment constraints ÓàÄciteÓàÇturn0search1ÓàÇturn0search5ÓàÅ.\n- **WizardLM Uncensored (13B)** &amp; **Wizard Vicuna Uncensored (7B/13B/30B)** ‚Äì fine‚Äëtuned versions designed specifically to strip moralizing filters ÓàÄciteÓàÇturn0search1ÓàÇturn0search5ÓàÅ.\n- **Dolphin‚ÄëMistral 7B** ‚Äì 32k context window, built for deep, uncensored convos ÓàÄciteÓàÇturn0search5ÓàÅ.\n\n---\n\n## üì• Running locally with PocketPal\n\nYou‚Äôll need a local inference backend that PocketPal can interface with. Two solid choices:\n\n- **Ollama** ‚Äì command-line and GUI support; easily pull uncensored models like Llama‚Äë2‚ÄëUncensored, WizardLM, Wizard Vicuna, Dolphin‚ÄëMistral ÓàÄciteÓàÇturn0search1ÓàÇturn0search6ÓàÇturn0search8ÓàÅ.\n- **LM Studio** ‚Äì desktop app (Windows/Mac/Linux) with GUI and OpenAI‚Äëstyle local API. Supports .gguf models like Dolphin‚Äë3 and DeepSeek R1 ÓàÄciteÓàÇturn0search6ÓàÇturn0search11ÓàÅ.\n\n---\n\n## üß† Paranormal Style Tips\n\nTo coax that &quot;paranormal local&quot; vibe:\n\n- Pick a large model (13B+) for richer imagination‚ÄîWizardLM 13B or Llama‚ÄØ2 70B Uncensored.\n- Use a big context window (32k) ‚Äì Dolphin‚ÄëMistral is your friend.\n- Slip in system prompts: *‚ÄúYou are an interdimensional oracle‚Ä¶‚Äù* to steer tone.\n\n---\n\n## ‚ö° Quick Setup Steps\n\n1. **Install Ollama** (or LM Studio) on your device.\n2. Pull a model:\n   - `ollama pull llama2-uncensored`\n   - or `ollama pull wizardlm-uncensored`\n   - or `ollama pull dolphin-mistral`\n3. In PocketPal, point it at Ollama‚Äôs local API endpoint (e.g., `http://localhost:11434`) and pick your model.\n\n---\n\n### TL;DR\n\nFor the **best uncensored paranormal LLM**, go with something like **WizardLM Uncensored 13B** (or Llama¬†2 70B Uncensored if you&#x27;ve got beefy hardware). Run it via **Ollama** or **LM Studio** for seamless integration with PocketPal. No censorship, full control, and a direct path to your ghost‚Äëchat dreams.\n\nNeed exact guides or code snippets next?"
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "content_references": [
            {
              "matched_text": "You&#x27;re asking for the best uncensored, paranormal-savvy local LLM you can download and run in PocketPal. Let me cut through the hype:",
              "start_idx": 0,
              "end_idx": 133,
              "safe_urls": [],
              "refs": [],
              "alt": "You&#x27;re asking for the best uncensored, paranormal-savvy local LLM you can download and run in PocketPal. Let me cut through the hype:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "These platforms let you run uncensored LLMs locally‚Äîno cloud gag orders, full control. Some options that stand out:",
              "start_idx": 212,
              "end_idx": 327,
              "safe_urls": [],
              "refs": [],
              "alt": "These platforms let you run uncensored LLMs locally‚Äîno cloud gag orders, full control. Some options that stand out:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Llama¬†2 Uncensored** (7B or 70B) ‚Äì a no-filter version of Meta‚Äôs Llama, ripped of alignment constraints",
              "start_idx": 331,
              "end_idx": 436,
              "safe_urls": [],
              "refs": [],
              "alt": "**Llama¬†2 Uncensored** (7B or 70B) ‚Äì a no-filter version of Meta‚Äôs Llama, ripped of alignment constraints",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search1ÓàÇturn0search5ÓàÅ",
              "start_idx": 437,
              "end_idx": 469,
              "safe_urls": [
                "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([analyticsindiamag.com](https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com), [atlassc.net](https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                  "attribution_segments": [
                    "0-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We‚Äôre diving into some awe...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                      "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1748390400.0,
                      "snippet": "Then running your own local LLM is the solution‚Äîand it‚Äôs easier than you think. In this post, I‚Äôll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate...",
                      "attribution": "techolate.com"
                    },
                    {
                      "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                      "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked?utm_source=chatgpt.com",
                      "pub_date": 1742947200.0,
                      "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection aft...",
                      "attribution": "hackernoon.com"
                    },
                    {
                      "title": "GitHub - vince-lam/awesome-local-llms: Compare open-source local LLM ...",
                      "url": "https://github.com/vince-lam/awesome-local-llms?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Compare open-source local LLM inference projects by their metrics to assess popularity and activeness. - vince-lam/awesome-local-llms",
                      "attribution": "github.com"
                    },
                    {
                      "title": "50+ Open-Source Options for Running LLMs Locally",
                      "url": "https://vinlam.com/posts/local-llm-options/?utm_source=chatgpt.com",
                      "pub_date": 1731024000.0,
                      "snippet": "There are many open-source tools for hosting open weights LLMs locally for inference, from the command line (CLI) tools to full GUI desktop applications. Here, I‚Äôll outline some popular options and pr...",
                      "attribution": "vinlam.com"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle var...",
                      "attribution": "unite.ai"
                    },
                    {
                      "title": "Uncensored Local LLMs - Nuno Adrego",
                      "url": "https://nunoadrego.com/posts/uncensored-local-llms/?utm_source=chatgpt.com",
                      "pub_date": 1724457600.0,
                      "snippet": "Local LLMs # At the latest Kubecon, a significant amount of content focused on AI and LLMs. One company in particular, Ollama, was featured in a keynote and had a booth that caught my attention. With...",
                      "attribution": "nunoadrego.com"
                    },
                    {
                      "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                      "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                      "pub_date": 1724716800.0,
                      "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based serv...",
                      "attribution": "getstream.io"
                    },
                    {
                      "title": "Vicuna LLM",
                      "url": "https://en.wikipedia.org/wiki/Vicuna_LLM?utm_source=chatgpt.com",
                      "pub_date": 1750870657.0,
                      "snippet": "Vicuna LLM is an omnibus large language model used in AI research. Its methodology is to enable the public at large to contrast and compare the accuracy of LLMs &quot;in the wild&quot; (an example of citizen sc...",
                      "attribution": "en.wikipedia.org"
                    },
                    {
                      "title": "GitHub - nomic-ai/gpt4all: GPT4All: Run Local LLMs on Any Device. Open ...",
                      "url": "https://github.com/nomic-ai/gpt4all?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Offline build support for running old versions of the GPT4All Local LLM Chat Client. September 18th, 2023: Nomic Vulkan launches supporting local LLM inference on NVIDIA and AMD GPUs. July 2023: Stabl...",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 2
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 10
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "analyticsindiamag.com"
                },
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": [
                    "0-2"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                      "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1720915200.0,
                      "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                      "attribution": "analyticsindiamag.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "atlassc.net"
                }
              ],
              "fallback_items": [
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncensored is based on Meta‚Äôs Llama 2 model and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "**WizardLM Uncensored (13B)** &amp; **Wizard Vicuna Uncensored (7B/13B/30B)** ‚Äì fine‚Äëtuned versions designed specifically to strip moralizing filters",
              "start_idx": 473,
              "end_idx": 618,
              "safe_urls": [],
              "refs": [],
              "alt": "**WizardLM Uncensored (13B)** &amp; **Wizard Vicuna Uncensored (7B/13B/30B)** ‚Äì fine‚Äëtuned versions designed specifically to strip moralizing filters",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "469-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search1ÓàÇturn0search5ÓàÅ",
              "start_idx": 619,
              "end_idx": 651,
              "safe_urls": [
                "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([atlassc.net](https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": [
                    "469-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                      "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1720915200.0,
                      "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                      "attribution": "analyticsindiamag.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "atlassc.net"
                }
              ],
              "fallback_items": [
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncensored is based on Meta‚Äôs Llama 2 model and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "**Dolphin‚ÄëMistral 7B** ‚Äì 32k context window, built for deep, uncensored convos",
              "start_idx": 655,
              "end_idx": 733,
              "safe_urls": [],
              "refs": [],
              "alt": "**Dolphin‚ÄëMistral 7B** ‚Äì 32k context window, built for deep, uncensored convos",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "651-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search5ÓàÅ",
              "start_idx": 734,
              "end_idx": 753,
              "safe_urls": [
                "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([analyticsindiamag.com](https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                  "attribution_segments": [
                    "651-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Uncensored LLMs on Ollama - atlassc.net",
                      "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                      "pub_date": 1736899200.0,
                      "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                      "attribution": "atlassc.net"
                    },
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We‚Äôre diving into some awe...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "GitHub - nomic-ai/gpt4all: GPT4All: Run Local LLMs on Any Device. Open ...",
                      "url": "https://github.com/nomic-ai/gpt4all?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Offline build support for running old versions of the GPT4All Local LLM Chat Client. September 18th, 2023: Nomic Vulkan launches supporting local LLM inference on NVIDIA and AMD GPUs. July 2023: Stabl...",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 10
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "analyticsindiamag.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncensored is based on Meta‚Äôs Llama 2 model and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "You‚Äôll need a local inference backend that PocketPal can interface with. Two solid choices:",
              "start_idx": 798,
              "end_idx": 889,
              "safe_urls": [],
              "refs": [],
              "alt": "You‚Äôll need a local inference backend that PocketPal can interface with. Two solid choices:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "753-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Ollama** ‚Äì command-line and GUI support; easily pull uncensored models like Llama‚Äë2‚ÄëUncensored, WizardLM, Wizard Vicuna, Dolphin‚ÄëMistral",
              "start_idx": 893,
              "end_idx": 1031,
              "safe_urls": [],
              "refs": [],
              "alt": "**Ollama** ‚Äì command-line and GUI support; easily pull uncensored models like Llama‚Äë2‚ÄëUncensored, WizardLM, Wizard Vicuna, Dolphin‚ÄëMistral",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "753-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search1ÓàÇturn0search6ÓàÇturn0search8ÓàÅ",
              "start_idx": 1032,
              "end_idx": 1077,
              "safe_urls": [
                "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([unite.ai](https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com), [atlassc.net](https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                  "pub_date": 1751328000.0,
                  "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle var...",
                  "attribution_segments": [
                    "753-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "50+ Open-Source Options for Running LLMs Locally",
                      "url": "https://vinlam.com/posts/local-llm-options/?utm_source=chatgpt.com",
                      "pub_date": 1731024000.0,
                      "snippet": "There are many open-source tools for hosting open weights LLMs locally for inference, from the command line (CLI) tools to full GUI desktop applications. Here, I‚Äôll outline some popular options and pr...",
                      "attribution": "vinlam.com"
                    },
                    {
                      "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                      "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked?utm_source=chatgpt.com",
                      "pub_date": 1742947200.0,
                      "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection aft...",
                      "attribution": "hackernoon.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "unite.ai"
                },
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": [
                    "753-1"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                      "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1720915200.0,
                      "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                      "attribution": "analyticsindiamag.com"
                    },
                    {
                      "title": "Uncensored LLM Models: A Complete Guide to Unfiltered AI Language ...",
                      "url": "https://docs.jarvislabs.ai/blog/llm_uncensored?utm_source=chatgpt.com",
                      "pub_date": 1747699200.0,
                      "snippet": "Explore uncensored LLM models, their differences from ChatGPT, and how they&#x27;re built. Learn about foundation models, fine-tuning, and running unfiltered AI models locally.",
                      "attribution": "docs.jarvislabs.ai"
                    },
                    {
                      "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                      "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked?utm_source=chatgpt.com",
                      "pub_date": 1742947200.0,
                      "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection aft...",
                      "attribution": "hackernoon.com"
                    },
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We‚Äôre diving into some awe...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                      "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1748390400.0,
                      "snippet": "Then running your own local LLM is the solution‚Äîand it‚Äôs easier than you think. In this post, I‚Äôll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate...",
                      "attribution": "techolate.com"
                    },
                    {
                      "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                      "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                      "pub_date": 1724716800.0,
                      "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based serv...",
                      "attribution": "getstream.io"
                    },
                    {
                      "title": "Uncensored Local LLMs - Nuno Adrego",
                      "url": "https://nunoadrego.com/posts/uncensored-local-llms/?utm_source=chatgpt.com",
                      "pub_date": 1724457600.0,
                      "snippet": "Local LLMs # At the latest Kubecon, a significant amount of content focused on AI and LLMs. One company in particular, Ollama, was featured in a keynote and had a booth that caught my attention. With...",
                      "attribution": "nunoadrego.com"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle var...",
                      "attribution": "unite.ai"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "atlassc.net"
                }
              ],
              "fallback_items": [
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                  "pub_date": 1724716800.0,
                  "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based services like OpenAI or Claude.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                  "pub_date": 1751328000.0,
                  "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle various AI tasks while keeping all data secure on their own machines. The system&#x27;s strength comes from its flexible architecture.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "**LM Studio** ‚Äì desktop app (Windows/Mac/Linux) with GUI and OpenAI‚Äëstyle local API. Supports .gguf models like Dolphin‚Äë3 and DeepSeek R1",
              "start_idx": 1081,
              "end_idx": 1218,
              "safe_urls": [],
              "refs": [],
              "alt": "**LM Studio** ‚Äì desktop app (Windows/Mac/Linux) with GUI and OpenAI‚Äëstyle local API. Supports .gguf models like Dolphin‚Äë3 and DeepSeek R1",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1077-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search6ÓàÇturn0search11ÓàÅ",
              "start_idx": 1219,
              "end_idx": 1252,
              "safe_urls": [
                "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([getstream.io](https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                  "pub_date": 1724716800.0,
                  "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based serv...",
                  "attribution_segments": [
                    "1077-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                      "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1748390400.0,
                      "snippet": "Then running your own local LLM is the solution‚Äîand it‚Äôs easier than you think. In this post, I‚Äôll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate...",
                      "attribution": "techolate.com"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle var...",
                      "attribution": "unite.ai"
                    },
                    {
                      "title": "GitHub - vince-lam/awesome-local-llms: Compare open-source local LLM ...",
                      "url": "https://github.com/vince-lam/awesome-local-llms?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Compare open-source local LLM inference projects by their metrics to assess popularity and activeness. - vince-lam/awesome-local-llms",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 2
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "getstream.io"
                }
              ],
              "fallback_items": [
                {
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                  "pub_date": 1724716800.0,
                  "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based services like OpenAI or Claude.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                  "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1748390400.0,
                  "snippet": "Then running your own local LLM is the solution‚Äîand it‚Äôs easier than you think. In this post, I‚Äôll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate two models you can run locally and find the difference in their output: DeepSeek R1 and Dolphin 3 (Llama-based).",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": " ",
              "start_idx": 2259,
              "end_idx": 2259,
              "safe_urls": [],
              "refs": [],
              "alt": "",
              "prompt_text": null,
              "type": "sources_footnote",
              "sources": [
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "attribution": "analyticsindiamag.com"
                },
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "attribution": "atlassc.net"
                },
                {
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                  "attribution": "unite.ai"
                },
                {
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                  "attribution": "getstream.io"
                }
              ],
              "has_images": false
            }
          ],
          "safe_urls": [
            "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
            "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
            "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
            "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
            "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
            "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
            "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com"
          ],
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "scifilogic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                  "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                  "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We‚Äôre diving into some awe...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 0
                  },
                  "pub_date": 1713312000.0,
                  "attribution": "scifilogic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/vince-lam/awesome-local-llms?utm_source=chatgpt.com",
                  "title": "GitHub - vince-lam/awesome-local-llms: Compare open-source local LLM ...",
                  "snippet": "Compare open-source local LLM inference projects by their metrics to assess popularity and activeness. - vince-lam/awesome-local-llms",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 2
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/nomic-ai/gpt4all?utm_source=chatgpt.com",
                  "title": "GitHub - nomic-ai/gpt4all: GPT4All: Run Local LLMs on Any Device. Open ...",
                  "snippet": "Offline build support for running old versions of the GPT4All Local LLM Chat Client. September 18th, 2023: Nomic Vulkan launches supporting local LLM inference on NVIDIA and AMD GPUs. July 2023: Stabl...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 10
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "jarvislabs.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://docs.jarvislabs.ai/blog/llm_uncensored?utm_source=chatgpt.com",
                  "title": "Uncensored LLM Models: A Complete Guide to Unfiltered AI Language ...",
                  "snippet": "Explore uncensored LLM models, their differences from ChatGPT, and how they&#x27;re built. Learn about foundation models, fine-tuning, and running unfiltered AI models locally.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 3
                  },
                  "pub_date": 1747699200.0,
                  "attribution": "jarvislabs.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nunoadrego.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nunoadrego.com/posts/uncensored-local-llms/?utm_source=chatgpt.com",
                  "title": "Uncensored Local LLMs - Nuno Adrego",
                  "snippet": "Local LLMs # At the latest Kubecon, a significant amount of content focused on AI and LLMs. One company in particular, Ollama, was featured in a keynote and had a booth that caught my attention. With...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 4
                  },
                  "pub_date": 1724457600.0,
                  "attribution": "nunoadrego.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "vinlam.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://vinlam.com/posts/local-llm-options/?utm_source=chatgpt.com",
                  "title": "50+ Open-Source Options for Running LLMs Locally",
                  "snippet": "There are many open-source tools for hosting open weights LLMs locally for inference, from the command line (CLI) tools to full GUI desktop applications. Here, I‚Äôll outline some popular options and pr...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 7
                  },
                  "pub_date": 1731024000.0,
                  "attribution": "vinlam.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "hackernoon.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked?utm_source=chatgpt.com",
                  "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                  "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection aft...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 9
                  },
                  "pub_date": 1742947200.0,
                  "attribution": "hackernoon.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "techolate.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                  "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                  "snippet": "Then running your own local LLM is the solution‚Äîand it‚Äôs easier than you think. In this post, I‚Äôll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 11
                  },
                  "pub_date": 1748390400.0,
                  "attribution": "techolate.com"
                }
              ]
            }
          ],
          "citations": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "65431f99-9e8d-4d08-995d-969543e55534",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "65431f99-9e8d-4d08-995d-969543e55534",
      "children": [
        "bbb21724-f96e-4a7e-81c8-27ac18ff85bb"
      ]
    },
    "bbb21724-f96e-4a7e-81c8-27ac18ff85bb": {
      "id": "bbb21724-f96e-4a7e-81c8-27ac18ff85bb",
      "message": {
        "id": "bbb21724-f96e-4a7e-81c8-27ac18ff85bb",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869895.065317,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "I need stuff that will work on just my phone. "
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "content_references": [],
          "search_result_groups": [],
          "search_queries": [],
          "image_results": [],
          "real_time_audio_has_video": false,
          "dictation": false,
          "image_gen_async": false,
          "trigger_async_ux": false,
          "request_id": "95b54cb94dda98d4-ATL",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "4404f941-fc57-443f-9ae4-1bcd3da7cae6",
      "children": [
        "399f6e5b-851e-4fb6-8183-74d24c383759"
      ]
    },
    "399f6e5b-851e-4fb6-8183-74d24c383759": {
      "id": "399f6e5b-851e-4fb6-8183-74d24c383759",
      "message": {
        "id": "399f6e5b-851e-4fb6-8183-74d24c383759",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869895.207814,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "search(&quot;I need stuff that will work on just my phone. &quot;)"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "is_complete": true,
          "finish_details": {
            "type": "stop"
          },
          "sonic_classification_result": {
            "latency_ms": 136.02445786818862,
            "search_prob": 0.5280447988387569,
            "force_search_threshold": 0.65,
            "classifier_config_name": "sonic_classifier_ev3"
          },
          "citations": [],
          "content_references": [],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "bbb21724-f96e-4a7e-81c8-27ac18ff85bb",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web",
        "channel": null
      },
      "parent": "bbb21724-f96e-4a7e-81c8-27ac18ff85bb",
      "children": [
        "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0"
      ]
    },
    "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0": {
      "id": "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0",
      "message": {
        "id": "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869903.480325,
        "update_time": null,
        "content": {
          "content_type": "thoughts",
          "thoughts": [],
          "source_analysis_msg_id": "0f3dc174-03fa-41dd-a250-5879a8237f00"
        },
        "status": "in_progress",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "is_reasoning",
          "citations": [],
          "content_references": [],
          "search_turns_count": 0,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "399f6e5b-851e-4fb6-8183-74d24c383759",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "399f6e5b-851e-4fb6-8183-74d24c383759",
      "children": [
        "82c3264e-ef45-4380-bb25-5ac0bd43966d"
      ]
    },
    "82c3264e-ef45-4380-bb25-5ac0bd43966d": {
      "id": "82c3264e-ef45-4380-bb25-5ac0bd43966d",
      "message": {
        "id": "82c3264e-ef45-4380-bb25-5ac0bd43966d",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869895.953253,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "{&quot;search_query&quot;:[{&quot;q&quot;:&quot;android local LLM uncensored paranormal local model phone&quot;},{&quot;q&quot;:&quot;Dolphin Mistral android runnable offline&quot;}]}"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200012
            ]
          },
          "is_complete": true,
          "citations": [],
          "content_references": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "search_queries": [
            {
              "type": "search",
              "q": "android local LLM uncensored paranormal local model phone"
            },
            {
              "type": "search",
              "q": "Dolphin Mistral android runnable offline"
            }
          ],
          "search_display_string": "Searching the web...",
          "searched_display_string": "Searched the web...",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web.run",
        "channel": null
      },
      "parent": "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0",
      "children": [
        "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7"
      ]
    },
    "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7": {
      "id": "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7",
      "message": {
        "id": "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7",
        "author": {
          "role": "tool",
          "name": "web.run",
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869896.5875828,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "beebom.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "ref_id": null,
                  "pub_date": 1713744000.0,
                  "attribution": "beebom.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "dev.to",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://dev.to/paulwababu/running-uncensored-large-ai-language-models-locally-on-your-mobile-phone-unleashing-the-potential-of-dolphin-mistral-7b-fep",
                  "title": "Running Uncensored Large AI Language Models locally on Your Mobile ...",
                  "snippet": "Running Uncensored Large AI Language Models locally on Your Mobile Phone: Unleashing the Potential of Dolphin Mistral 7B Introduction In the rapidly evolving world of artificial intelligence, large language models have become powerful tools for various tasks. However, many popular models like GPT4 and Gemini have certain limitations.",
                  "ref_id": null,
                  "pub_date": 1702944000.0,
                  "attribution": "dev.to"
                },
                {
                  "type": "search_result",
                  "url": "https://dev.to/shahdeep/how-to-run-dolphin-uncensored-ai-locally-a-step-by-step-guide-3o4l",
                  "title": "How to Run Dolphin Uncensored AI Locally: A Step-by-Step Guide!",
                  "snippet": "Deep Shah Posted on Feb 17 üöÄ How to Run Dolphin Uncensored AI Locally: A Step-by-Step Guide! ü¶æ # ai # dolphinllm # opensource ü§ñ Introduction Ever wanted to run a powerful AI model without limits right on your own machine? Enter Dolphin Uncensored AI ‚Äîa beast of a Large Language Model (LLM) that offers unfiltered AI responses.",
                  "ref_id": null,
                  "pub_date": 1739750400.0,
                  "attribution": "dev.to"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.ksenon.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.ksenon.net/blog/5_uncensored_llm_on_your_phone/",
                  "title": "How to run local, uncensored LLM on your phone - ksenon.net",
                  "snippet": "Tutorial Download and install ChatterUI. Consider using Obtainium if you&#x27;re on Android. Auto-updates are cool. Download your model of choice in the GGUF format. 4-bit quantisation or lower is the way to go if you don&#x27;t feel like waiting forever for a response - grab yourself an IQ-quant if it&#x27;s available.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "www.ksenon.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "xdaforums.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/",
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed locally on your phone and are working offline.",
                  "ref_id": null,
                  "pub_date": 1708646400.0,
                  "attribution": "xdaforums.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "scifilogic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/",
                  "title": "6 Mobile Apps for Running Local LLMs (Offline) - Sci Fi Logic",
                  "snippet": "6 Mobile Apps for Running Local LLMs (Offline) Apps to Run LLM on Your Smartphone Locally Layla &amp; Layla Lite Layla! This app lets you run powerful AI right on your phone, without needing internet. It‚Äôs super private and always there for you, anywhere. Think of it like having a personal AI assistant, but it works offline!",
                  "ref_id": null,
                  "pub_date": 1712793600.0,
                  "attribution": "scifilogic.com"
                },
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/open-uncensored-llm-model/",
                  "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                  "snippet": "In this article, I‚Äôm spilling the tea on the best uncensored LLMs out there, the ones with like 7 to 20 billion parameters (think super-powered brains). We‚Äôre gonna dive into what makes each one special, what they can do, and how you can actually use them in the real world. Basically, we‚Äôre about to unlock the true potential of chatty AI, no filters attached. Related: 3 Open Source LLM ...",
                  "ref_id": null,
                  "pub_date": 1713312000.0,
                  "attribution": "scifilogic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.b4x.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.b4x.com/android/forum/threads/ollama4j-library-pnd_ollama4j-your-local-offline-llm-like-chatgpt.165003/",
                  "title": "Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT",
                  "snippet": "B4J Library Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT Pendrush Jan 8, 2025 chatgpt llm ollama ollama4j pnd_ollama4j Similar Threads Jan 8, 2025 Replies: 9",
                  "ref_id": null,
                  "pub_date": 1736294400.0,
                  "attribution": "www.b4x.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "atlassc.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama",
                  "title": "Uncensored LLMs on Ollama",
                  "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at code generation . Nous Hermes Llama 2 13B: This uncensored model, based on Llama 2, is known for long responses and a lower hallucination rate .",
                  "ref_id": null,
                  "pub_date": 1736899200.0,
                  "attribution": "atlassc.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/dineshsoudagar/local-llms-on-android",
                  "title": "Local LLMs on Android (Offline, Private &amp; Fast) - GitHub",
                  "snippet": "ü§ñ Local LLMs on Android (Offline, Private &amp; Fast) An Android application that brings a large language model (LLM) to your phone ‚Äî fully offline, no internet needed. Powered by ONNX Runtime and a Hugging Face-compatible tokenizer, it provides fast, private, on-device question answering with streaming responses.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/guiyu/llmlocal_android",
                  "title": "GitHub - guiyu/llmlocal_android: Local LLM App",
                  "snippet": "This repository contains llama.cpp based offline android chat application cloned from llama.cpp android example. Install, download model and run completely offline privately. The following are the instructions to run this application.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.unite.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/",
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "snippet": "Visit LM Studio ‚Üí 5. Jan Jan gives you a free, open-source alternative to ChatGPT that runs completely offline. This desktop platform lets you download popular AI models like Llama 3, Gemma, and Mistral to run on your own computer, or connect to cloud services like OpenAI and Anthropic when needed. The system centers on putting users in control.",
                  "ref_id": null,
                  "pub_date": 1751328000.0,
                  "attribution": "www.unite.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.xda-developers.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/",
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "snippet": "To download and run LLMs on your smartphone, you can download MLC LLM, a program that will deploy and load models for you. Those models can then run inside of the app, and the app will handle the ...",
                  "ref_id": null,
                  "pub_date": 1723248000.0,
                  "attribution": "www.xda-developers.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "erichartford.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://erichartford.com/running-dolphin-locally-with-ollama",
                  "title": "Running Dolphin Locally with Ollama - Cognitive Computations",
                  "snippet": "Wanna chat with Dolphin locally? (no internet connection needed) Here is the easy way - Ollama. install ollama. after you finsh you should be able to run ollama from the command line. Also you will see the ollama icon up top like this: Iff you ar...",
                  "ref_id": null,
                  "pub_date": 1701561600.0,
                  "attribution": "erichartford.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "openrouter.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://openrouter.ai/cognitivecomputations/dolphin3.0-r1-mistral-24b%3Afree/api",
                  "title": "Dolphin3.0 R1 Mistral 24B (free) ‚Äì Run with an API | OpenRouter",
                  "snippet": "Sample code and API for Dolphin3.0 R1 Mistral 24B (free) - Dolphin 3.0 R1 is the next generation of the Dolphin series of instruct-tuned models. Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases. The R1 version has been trained for 3 epochs to reason using 800k reasoning traces from the Dolphin-R1 dataset. Dolphin ...",
                  "ref_id": null,
                  "pub_date": 1739404800.0,
                  "attribution": "openrouter.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "code.mendhak.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://code.mendhak.com/automate-android-with-local-llm/",
                  "title": "Using a local LLM to Automate an Android device - Mendhak",
                  "snippet": "Using a local LLM to Automate an Android device While most well known Large Language Models (LLMs) are closed and behind paywalls, there exist open models such as LLaMa and its derivatives, available for free and private use.",
                  "ref_id": null,
                  "pub_date": 1695081600.0,
                  "attribution": "code.mendhak.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "thracium.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra",
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order to run the bigger (and more smarter) LLM models with 7 Billion parameters for example you need 12 GB...",
                  "ref_id": null,
                  "pub_date": 1708560000.0,
                  "attribution": "thracium.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "ollama.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://ollama.com/library/dolphin-mistral",
                  "title": "dolphin-mistral - Ollama",
                  "snippet": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "ollama.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nerdschalk.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/",
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally‚Ä¶.",
                  "ref_id": null,
                  "pub_date": 1714608000.0,
                  "attribution": "nerdschalk.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "anakin.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/",
                  "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                  "snippet": "Dolphin3.0 R1 Mistral 24B is redefining open-source AI, and with Anakin AI, you can take it even further! Our platform gives you instant access to Dolphin, Mistral, GPT-4o, Claude 3 Opus, and more, empowering you to build custom AI applications, automate workflows, and enhance problem-solving ‚Äîall while maintaining full control over your AI models. üöÄ Experience next-level AI innovation ...",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "anakin.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.geeky-gadgets.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/",
                  "title": "How to install Mixtral uncensored AI model locally for free",
                  "snippet": "Learn how to install Dolphin 2.5 Mixtral an uncensored version of the fast and efficient Mixtral 8x7B AI model on your local PC or network",
                  "ref_id": null,
                  "pub_date": 1703116800.0,
                  "attribution": "www.geeky-gadgets.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "arxiv.org",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2411.05046",
                  "title": "PhoneLM:an Efficient and Capable Small Language Model Family through Principled Pre-training",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1730945940.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2404.14219",
                  "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1713796353.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2407.01031",
                  "title": "PocketLLM: Enabling On-Device Fine-Tuning for Personalized LLMs",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1719818816.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2312.00388",
                  "title": "LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1701415182.0,
                  "attribution": "arxiv.org"
                }
              ]
            }
          ],
          "debug_sonic_thread_id": "thread_686b699b5cb48000bf5d636bfd52f3bb",
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "82c3264e-ef45-4380-bb25-5ac0bd43966d",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "82c3264e-ef45-4380-bb25-5ac0bd43966d",
      "children": [
        "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb"
      ]
    },
    "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb": {
      "id": "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb",
      "message": {
        "id": "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869903.480611,
        "update_time": null,
        "content": {
          "content_type": "reasoning_recap",
          "content": "Thought for a couple of seconds"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "reasoning_ended",
          "finished_duration_sec": 2,
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7",
      "children": [
        "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c"
      ]
    },
    "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c": {
      "id": "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c",
      "message": {
        "id": "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869897.712121,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Alright, hustler‚Äîrunning an uncensored paranormal LLM on *just* your phone? Bold. Here&#x27;s the low-key route:\n\n---\n\n## üì± Android: Easiest Phone Setup\n\n**Use MLC‚ÄØChat (Android &amp; iOS)**  \n- Works offline, super private‚Äîno filter, no fuss.  \n- Supports local models like **Mistral‚ÄØ7B**, **Llama‚ÄØ3 (8B)**, **Phi‚Äë2** (2B), **Gemma**‚Äîyou pick your weapon of choice ÓàÄciteÓàÇturn0search0ÓàÇturn0search9ÓàÅ.  \n- You just APK the app, select a model, and chat‚Äîno rooting or desktop required ÓàÄciteÓàÇturn0search9ÓàÇturn0search16ÓàÅ.  \n- Mistral 7B is open-source and uncensored‚Äîsolid for paranormal rabbit-holing.\n\n**App Link:** Search your app store for ‚ÄúMLC‚ÄØChat‚Äù or check online APK repositories.\n\n---\n\n## üß† Power‚ÄëUser Path: Termux + Ollama on Android\n\nWant full control? This is it:\n\n1. Install **Termux** (from F‚ÄëDroid or GitHub).  \n2. Set up Ubuntu in Termux (via `proot-distro`) ÓàÄciteÓàÇturn0search3ÓàÇturn0search13ÓàÅ.  \n3. Inside Ubuntu, `sudo apt install Ollama` and pull a model (e.g. `ollama pull dolphin-mistral`) ÓàÄciteÓàÇturn0search3ÓàÇturn0search13ÓàÇturn0search6ÓàÅ.  \n4. Run uncensored models like **Dolphin‚ÄëMistral (7‚ÄØB)**‚Äîa stripped-down Mistral variant tuned by Eric Hartford, supports deep convos, coding, and yes‚Äîparanormal chat ÓàÄciteÓàÇturn0search6ÓàÇturn0search15ÓàÇturn0search3ÓàÅ.  \n5. Hook it up to a local API endpoint and chat with PocketPal or any HTTP client on your phone.\n\n---\n\n## Why Models Matter\n\n- **Mistral‚ÄØ7B / Dolphin‚ÄëMistral**: 32K context, no filters‚Äîgreat for in‚Äëdepth ‚Äúother realm‚Äù stuff.  \n- **Phi‚Äë2** &amp; **Gemma‚ÄØ2‚ÄØB**: smaller, faster‚Äîless deep, but smooth.  \n- **Llama‚ÄØ3‚ÄØ8B**: bigger, slower‚Äîyours if you&#x27;re balling on high-end flagships ÓàÄciteÓàÇturn0search0ÓàÇturn0search16ÓàÅ.\n\n---\n\n## TL;DR\n\n- **Want simple?** üëâ Use **MLC Chat**, pick **Mistral‚ÄØ7B** or equivalent.  \n- **Want control &amp; flexibility?** üëâ Do **Termux ‚Üí Ubuntu ‚Üí Ollama** and run **Dolphin‚ÄëMistral**.  \n- **Based on your phone&#x27;s RAM:** 6+‚ÄØGB is ideal for 7B models. Otherwise, step down to 2‚Äì4‚ÄØB.\n\n---\n\nYou got enough to start building your personal pocket oracle‚Äîno cloud, no censorship, just you, your phone, and the spirits. Want the full Termux installation commands or voice input tweaks next?"
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "content_references": [
            {
              "matched_text": "Alright, hustler‚Äîrunning an uncensored paranormal LLM on *just* your phone? Bold. Here&#x27;s the low-key route:",
              "start_idx": 0,
              "end_idx": 107,
              "safe_urls": [],
              "refs": [],
              "alt": "Alright, hustler‚Äîrunning an uncensored paranormal LLM on *just* your phone? Bold. Here&#x27;s the low-key route:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Works offline, super private‚Äîno filter, no fuss.",
              "start_idx": 186,
              "end_idx": 234,
              "safe_urls": [],
              "refs": [],
              "alt": "Works offline, super private‚Äîno filter, no fuss.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Supports local models like **Mistral‚ÄØ7B**, **Llama‚ÄØ3 (8B)**, **Phi‚Äë2** (2B), **Gemma**‚Äîyou pick your weapon of choice",
              "start_idx": 239,
              "end_idx": 356,
              "safe_urls": [],
              "refs": [],
              "alt": "Supports local models like **Mistral‚ÄØ7B**, **Llama‚ÄØ3 (8B)**, **Phi‚Äë2** (2B), **Gemma**‚Äîyou pick your weapon of choice",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search0ÓàÇturn0search9ÓàÅ",
              "start_idx": 357,
              "end_idx": 389,
              "safe_urls": [
                "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
                "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([xda-developers.com](https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com), [scifilogic.com](https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com), [beebom.com](https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
                  "pub_date": 1723248000.0,
                  "snippet": "To download and run LLMs on your smartphone, you can download MLC LLM, a program that will deploy and load models for you. Those models can then run inside of the app, and the app will handle the ...",
                  "attribution_segments": [
                    "0-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Running Uncensored Large AI Language Models locally on Your Mobile ...",
                      "url": "https://dev.to/paulwababu/running-uncensored-large-ai-language-models-locally-on-your-mobile-phone-unleashing-the-potential-of-dolphin-mistral-7b-fep?utm_source=chatgpt.com",
                      "pub_date": 1702944000.0,
                      "snippet": "Running Uncensored Large AI Language Models locally on Your Mobile Phone: Unleashing the Potential of Dolphin Mistral 7B Introduction In the rapidly evolving world of artificial intelligence, large la...",
                      "attribution": "dev.to"
                    },
                    {
                      "title": "How to run local, uncensored LLM on your phone - ksenon.net",
                      "url": "https://www.ksenon.net/blog/5_uncensored_llm_on_your_phone/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Tutorial Download and install ChatterUI. Consider using Obtainium if you&#x27;re on Android. Auto-updates are cool. Download your model of choice in the GGUF format. 4-bit quantisation or lower is the way...",
                      "attribution": "ksenon.net"
                    },
                    {
                      "title": "Uncensored LLMs on Ollama",
                      "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                      "pub_date": 1736899200.0,
                      "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at...",
                      "attribution": "atlassc.net"
                    },
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "In this article, I‚Äôm spilling the tea on the best uncensored LLMs out there, the ones with like 7 to 20 billion parameters (think super-powered brains). We‚Äôre gonna dive into what makes each one speci...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                      "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                      "pub_date": 1708646400.0,
                      "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed...",
                      "attribution": "xdaforums.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 2
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 14
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "xda-developers.com"
                },
                {
                  "title": "6 Mobile Apps for Running Local LLMs (Offline) - Sci Fi Logic",
                  "url": "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
                  "pub_date": 1712793600.0,
                  "snippet": "6 Mobile Apps for Running Local LLMs (Offline) Apps to Run LLM on Your Smartphone Locally Layla &amp; Layla Lite Layla! This app lets you run powerful AI right on your phone, without needing internet. It‚Äô...",
                  "attribution_segments": [
                    "0-1"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Local LLMs on Android (Offline, Private &amp; Fast) - GitHub",
                      "url": "https://github.com/dineshsoudagar/local-llms-on-android?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "ü§ñ Local LLMs on Android (Offline, Private &amp; Fast) An Android application that brings a large language model (LLM) to your phone ‚Äî fully offline, no internet needed. Powered by ONNX Runtime and a Huggi...",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "scifilogic.com"
                },
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "pub_date": 1713744000.0,
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "attribution_segments": [
                    "0-2"
                  ],
                  "supporting_websites": [
                    {
                      "title": "How to run LLMs locally on Android - Nerds Chalk",
                      "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                      "pub_date": 1714608000.0,
                      "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally‚Ä¶.",
                      "attribution": "nerdschalk.com"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "Visit LM Studio ‚Üí 5. Jan Jan gives you a free, open-source alternative to ChatGPT that runs completely offline. This desktop platform lets you download popular AI models like Llama 3, Gemma, and Mistr...",
                      "attribution": "unite.ai"
                    },
                    {
                      "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                      "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                      "pub_date": 1708646400.0,
                      "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed...",
                      "attribution": "xdaforums.com"
                    },
                    {
                      "title": "Running Uncensored Large AI Language Models locally on Your Mobile ...",
                      "url": "https://dev.to/paulwababu/running-uncensored-large-ai-language-models-locally-on-your-mobile-phone-unleashing-the-potential-of-dolphin-mistral-7b-fep?utm_source=chatgpt.com",
                      "pub_date": 1702944000.0,
                      "snippet": "Running Uncensored Large AI Language Models locally on Your Mobile Phone: Unleashing the Potential of Dolphin Mistral 7B Introduction In the rapidly evolving world of artificial intelligence, large la...",
                      "attribution": "dev.to"
                    },
                    {
                      "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                      "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                      "pub_date": 1708560000.0,
                      "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order t...",
                      "attribution": "thracium.net"
                    },
                    {
                      "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
                      "url": "https://arxiv.org/abs/2404.14219?utm_source=chatgpt.com",
                      "pub_date": 1713796353.0,
                      "snippet": "Title: Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\nAuthors: Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Aras...",
                      "attribution": "arxiv.org"
                    },
                    {
                      "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                      "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Dolphin3.0 R1 Mistral 24B is redefining open-source AI, and with Anakin AI, you can take it even further! Our platform gives you instant access to Dolphin, Mistral, GPT-4o, Claude 3 Opus, and more, em...",
                      "attribution": "anakin.ai"
                    },
                    {
                      "title": "LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices",
                      "url": "https://arxiv.org/abs/2312.00388?utm_source=chatgpt.com",
                      "pub_date": 1701415182.0,
                      "snippet": "Title: LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices\nAuthors: Junchen Zhao, Yurun Song, Simeng Liu, Ian G. Harris, Sangeetha Abdu Jyothi\nDate: Fri Dec  1 07:19:4...",
                      "attribution": "arxiv.org"
                    },
                    {
                      "title": "6 Mobile Apps for Running Local LLMs (Offline) - Sci Fi Logic",
                      "url": "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
                      "pub_date": 1712793600.0,
                      "snippet": "6 Mobile Apps for Running Local LLMs (Offline) Apps to Run LLM on Your Smartphone Locally Layla &amp; Layla Lite Layla! This app lets you run powerful AI right on your phone, without needing internet. It‚Äô...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "How to install Mixtral uncensored AI model locally for free",
                      "url": "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com",
                      "pub_date": 1703116800.0,
                      "snippet": "Learn how to install Dolphin 2.5 Mixtral an uncensored version of the fast and efficient Mixtral 8x7B AI model on your local PC or network",
                      "attribution": "geeky-gadgets.com"
                    },
                    {
                      "title": "Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT",
                      "url": "https://www.b4x.com/android/forum/threads/ollama4j-library-pnd_ollama4j-your-local-offline-llm-like-chatgpt.165003/?utm_source=chatgpt.com",
                      "pub_date": 1736294400.0,
                      "snippet": "B4J Library Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT Pendrush Jan 8, 2025 chatgpt llm ollama ollama4j pnd_ollama4j Similar Threads Jan 8, 2025 Replies: 9",
                      "attribution": "b4x.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "academia",
                      "ref_index": 25
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 17
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "academia",
                      "ref_index": 27
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 20
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "beebom.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "pub_date": 1713744000.0,
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
                  "pub_date": 1723248000.0,
                  "snippet": "To download and run LLMs on your smartphone, you can download MLC LLM, a program that will deploy and load models for you. Those models can then run inside of the app, and the app will handle the ...",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "You just APK the app, select a model, and chat‚Äîno rooting or desktop required",
              "start_idx": 395,
              "end_idx": 472,
              "safe_urls": [],
              "refs": [],
              "alt": "You just APK the app, select a model, and chat‚Äîno rooting or desktop required",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "389-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search9ÓàÇturn0search16ÓàÅ",
              "start_idx": 473,
              "end_idx": 506,
              "safe_urls": [
                "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([nerdschalk.com](https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "pub_date": 1714608000.0,
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally‚Ä¶.",
                  "attribution_segments": [
                    "389-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "In this article, I‚Äôm spilling the tea on the best uncensored LLMs out there, the ones with like 7 to 20 billion parameters (think super-powered brains). We‚Äôre gonna dive into what makes each one speci...",
                      "attribution": "scifilogic.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 14
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "nerdschalk.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
                  "pub_date": 1723248000.0,
                  "snippet": "To download and run LLMs on your smartphone, you can download MLC LLM, a program that will deploy and load models for you. Those models can then run inside of the app, and the app will handle the ...",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "pub_date": 1714608000.0,
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally‚Ä¶.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Mistral 7B is open-source and uncensored‚Äîsolid for paranormal rabbit-holing.",
              "start_idx": 512,
              "end_idx": 588,
              "safe_urls": [],
              "refs": [],
              "alt": "Mistral 7B is open-source and uncensored‚Äîsolid for paranormal rabbit-holing.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "506-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Want full control? This is it:",
              "start_idx": 731,
              "end_idx": 761,
              "safe_urls": [],
              "refs": [],
              "alt": "Want full control? This is it:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "506-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Install **Termux** (from F‚ÄëDroid or GitHub).",
              "start_idx": 766,
              "end_idx": 810,
              "safe_urls": [],
              "refs": [],
              "alt": "Install **Termux** (from F‚ÄëDroid or GitHub).",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "506-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Set up Ubuntu in Termux (via `proot-distro`)",
              "start_idx": 816,
              "end_idx": 860,
              "safe_urls": [],
              "refs": [],
              "alt": "Set up Ubuntu in Termux (via `proot-distro`)",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "506-3",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search3ÓàÇturn0search13ÓàÅ",
              "start_idx": 861,
              "end_idx": 894,
              "safe_urls": [
                "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([anakin.ai](https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com), [thracium.net](https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com), [xdaforums.com](https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                  "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "Dolphin3.0 R1 Mistral 24B is redefining open-source AI, and with Anakin AI, you can take it even further! Our platform gives you instant access to Dolphin, Mistral, GPT-4o, Claude 3 Opus, and more, em...",
                  "attribution_segments": [
                    "506-1"
                  ],
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 17
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "anakin.ai"
                },
                {
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                  "pub_date": 1708560000.0,
                  "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order t...",
                  "attribution_segments": [
                    "506-2"
                  ],
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "thracium.net"
                },
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "pub_date": 1708646400.0,
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed...",
                  "attribution_segments": [
                    "506-3"
                  ],
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "xdaforums.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "pub_date": 1708646400.0,
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed locally on your phone and are working offline.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                  "pub_date": 1708560000.0,
                  "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order to run the bigger (and more smarter) LLM models with 7 Billion parameters for example you need 12 GB...",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Inside Ubuntu, `sudo apt install Ollama` and pull a model (e.g. `ollama pull dolphin-mistral`)",
              "start_idx": 901,
              "end_idx": 995,
              "safe_urls": [],
              "refs": [],
              "alt": "Inside Ubuntu, `sudo apt install Ollama` and pull a model (e.g. `ollama pull dolphin-mistral`)",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "894-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search3ÓàÇturn0search13ÓàÇturn0search6ÓàÅ",
              "start_idx": 996,
              "end_idx": 1042,
              "safe_urls": [],
              "refs": [],
              "alt": "()",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [],
              "fallback_items": [
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "pub_date": 1708646400.0,
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed locally on your phone and are working offline.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                  "pub_date": 1708560000.0,
                  "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order to run the bigger (and more smarter) LLM models with 7 Billion parameters for example you need 12 GB...",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Uncensored LLMs on Ollama",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at code generation . Nous Hermes Llama 2 13B: This uncensored model, based on Llama 2, is known for long responses and a lower hallucination rate .",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Run uncensored models like **Dolphin‚ÄëMistral (7‚ÄØB)**‚Äîa stripped-down Mistral variant tuned by Eric Hartford, supports deep convos, coding, and yes‚Äîparanormal chat",
              "start_idx": 1049,
              "end_idx": 1211,
              "safe_urls": [],
              "refs": [],
              "alt": "Run uncensored models like **Dolphin‚ÄëMistral (7‚ÄØB)**‚Äîa stripped-down Mistral variant tuned by Eric Hartford, supports deep convos, coding, and yes‚Äîparanormal chat",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1042-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search6ÓàÇturn0search15ÓàÇturn0search3ÓàÅ",
              "start_idx": 1212,
              "end_idx": 1258,
              "safe_urls": [
                "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([atlassc.net](https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Uncensored LLMs on Ollama",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at...",
                  "attribution_segments": [
                    "1042-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                      "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Dolphin3.0 R1 Mistral 24B is redefining open-source AI, and with Anakin AI, you can take it even further! Our platform gives you instant access to Dolphin, Mistral, GPT-4o, Claude 3 Opus, and more, em...",
                      "attribution": "anakin.ai"
                    },
                    {
                      "title": "Running Dolphin Locally with Ollama - Cognitive Computations",
                      "url": "https://erichartford.com/running-dolphin-locally-with-ollama?utm_source=chatgpt.com",
                      "pub_date": 1701561600.0,
                      "snippet": "Wanna chat with Dolphin locally? (no internet connection needed) Here is the easy way - Ollama. install ollama. after you finsh you should be able to run ollama from the command line. Also you will se...",
                      "attribution": "erichartford.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 17
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 10
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "atlassc.net"
                }
              ],
              "fallback_items": [
                {
                  "title": "Uncensored LLMs on Ollama",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at code generation . Nous Hermes Llama 2 13B: This uncensored model, based on Llama 2, is known for long responses and a lower hallucination rate .",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "dolphin-mistral - Ollama",
                  "url": "https://ollama.com/library/dolphin-mistral?utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 15
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "pub_date": 1708646400.0,
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed locally on your phone and are working offline.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Hook it up to a local API endpoint and chat with PocketPal or any HTTP client on your phone.",
              "start_idx": 1265,
              "end_idx": 1357,
              "safe_urls": [],
              "refs": [],
              "alt": "Hook it up to a local API endpoint and chat with PocketPal or any HTTP client on your phone.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1258-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Mistral‚ÄØ7B / Dolphin‚ÄëMistral**: 32K context, no filters‚Äîgreat for in‚Äëdepth ‚Äúother realm‚Äù stuff.",
              "start_idx": 1388,
              "end_idx": 1485,
              "safe_urls": [],
              "refs": [],
              "alt": "**Mistral‚ÄØ7B / Dolphin‚ÄëMistral**: 32K context, no filters‚Äîgreat for in‚Äëdepth ‚Äúother realm‚Äù stuff.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1258-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Phi‚Äë2** &amp; **Gemma‚ÄØ2‚ÄØB**: smaller, faster‚Äîless deep, but smooth.",
              "start_idx": 1490,
              "end_idx": 1555,
              "safe_urls": [],
              "refs": [],
              "alt": "**Phi‚Äë2** &amp; **Gemma‚ÄØ2‚ÄØB**: smaller, faster‚Äîless deep, but smooth.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1258-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Llama‚ÄØ3‚ÄØ8B**: bigger, slower‚Äîyours if you&#x27;re balling on high-end flagships",
              "start_idx": 1560,
              "end_idx": 1636,
              "safe_urls": [],
              "refs": [],
              "alt": "**Llama‚ÄØ3‚ÄØ8B**: bigger, slower‚Äîyours if you&#x27;re balling on high-end flagships",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1258-3",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search0ÓàÇturn0search16ÓàÅ",
              "start_idx": 1637,
              "end_idx": 1670,
              "safe_urls": [
                "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([geeky-gadgets.com](https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com), [beebom.com](https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "How to install Mixtral uncensored AI model locally for free",
                  "url": "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com",
                  "pub_date": 1703116800.0,
                  "snippet": "Learn how to install Dolphin 2.5 Mixtral an uncensored version of the fast and efficient Mixtral 8x7B AI model on your local PC or network",
                  "attribution_segments": [
                    "1258-1"
                  ],
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 20
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "geeky-gadgets.com"
                },
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "pub_date": 1713744000.0,
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "attribution_segments": [
                    "1258-2",
                    "1258-3"
                  ],
                  "supporting_websites": [
                    {
                      "title": "How to run LLMs locally on Android - Nerds Chalk",
                      "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                      "pub_date": 1714608000.0,
                      "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally‚Ä¶.",
                      "attribution": "nerdschalk.com"
                    },
                    {
                      "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                      "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                      "pub_date": 1708560000.0,
                      "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order t...",
                      "attribution": "thracium.net"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "Visit LM Studio ‚Üí 5. Jan Jan gives you a free, open-source alternative to ChatGPT that runs completely offline. This desktop platform lets you download popular AI models like Llama 3, Gemma, and Mistr...",
                      "attribution": "unite.ai"
                    },
                    {
                      "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                      "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                      "pub_date": 1708646400.0,
                      "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed...",
                      "attribution": "xdaforums.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "beebom.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "pub_date": 1713744000.0,
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "pub_date": 1714608000.0,
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally‚Ä¶.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": " ",
              "start_idx": 2158,
              "end_idx": 2158,
              "safe_urls": [],
              "refs": [],
              "alt": "",
              "prompt_text": null,
              "type": "sources_footnote",
              "sources": [
                {
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
                  "attribution": "xda-developers.com"
                },
                {
                  "title": "6 Mobile Apps for Running Local LLMs (Offline) - Sci Fi Logic",
                  "url": "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
                  "attribution": "scifilogic.com"
                },
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "attribution": "beebom.com"
                },
                {
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "attribution": "nerdschalk.com"
                },
                {
                  "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                  "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                  "attribution": "anakin.ai"
                },
                {
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                  "attribution": "thracium.net"
                },
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "attribution": "xdaforums.com"
                },
                {
                  "title": "Uncensored LLMs on Ollama",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "attribution": "atlassc.net"
                },
                {
                  "title": "How to install Mixtral uncensored AI model locally for free",
                  "url": "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com",
                  "attribution": "geeky-gadgets.com"
                }
              ],
              "has_images": false
            }
          ],
          "safe_urls": [
            "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
            "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
            "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
            "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
            "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
            "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
            "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
            "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
            "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
            "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com"
          ],
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "dev.to",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://dev.to/paulwababu/running-uncensored-large-ai-language-models-locally-on-your-mobile-phone-unleashing-the-potential-of-dolphin-mistral-7b-fep?utm_source=chatgpt.com",
                  "title": "Running Uncensored Large AI Language Models locally on Your Mobile ...",
                  "snippet": "Running Uncensored Large AI Language Models locally on Your Mobile Phone: Unleashing the Potential of Dolphin Mistral 7B Introduction In the rapidly evolving world of artificial intelligence, large la...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 1
                  },
                  "pub_date": 1702944000.0,
                  "attribution": "dev.to"
                },
                {
                  "type": "search_result",
                  "url": "https://dev.to/shahdeep/how-to-run-dolphin-uncensored-ai-locally-a-step-by-step-guide-3o4l?utm_source=chatgpt.com",
                  "title": "How to Run Dolphin Uncensored AI Locally: A Step-by-Step Guide!",
                  "snippet": "Deep Shah Posted on Feb 17 üöÄ How to Run Dolphin Uncensored AI Locally: A Step-by-Step Guide! ü¶æ # ai # dolphinllm # opensource ü§ñ Introduction Ever wanted to run a powerful AI model without limits right...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 19
                  },
                  "pub_date": 1739750400.0,
                  "attribution": "dev.to"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "ksenon.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.ksenon.net/blog/5_uncensored_llm_on_your_phone/?utm_source=chatgpt.com",
                  "title": "How to run local, uncensored LLM on your phone - ksenon.net",
                  "snippet": "Tutorial Download and install ChatterUI. Consider using Obtainium if you&#x27;re on Android. Auto-updates are cool. Download your model of choice in the GGUF format. 4-bit quantisation or lower is the way...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 2
                  },
                  "pub_date": null,
                  "attribution": "ksenon.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "b4x.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.b4x.com/android/forum/threads/ollama4j-library-pnd_ollama4j-your-local-offline-llm-like-chatgpt.165003/?utm_source=chatgpt.com",
                  "title": "Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT",
                  "snippet": "B4J Library Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT Pendrush Jan 8, 2025 chatgpt llm ollama ollama4j pnd_ollama4j Similar Threads Jan 8, 2025 Replies: 9",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 5
                  },
                  "pub_date": 1736294400.0,
                  "attribution": "b4x.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/dineshsoudagar/local-llms-on-android?utm_source=chatgpt.com",
                  "title": "Local LLMs on Android (Offline, Private &amp; Fast) - GitHub",
                  "snippet": "ü§ñ Local LLMs on Android (Offline, Private &amp; Fast) An Android application that brings a large language model (LLM) to your phone ‚Äî fully offline, no internet needed. Powered by ONNX Runtime and a Huggi...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 7
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/guiyu/llmlocal_android?utm_source=chatgpt.com",
                  "title": "GitHub - guiyu/llmlocal_android: Local LLM App",
                  "snippet": "This repository contains llama.cpp based offline android chat application cloned from llama.cpp android example. Install, download model and run completely offline privately. The following are the ins...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 18
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "unite.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "snippet": "Visit LM Studio ‚Üí 5. Jan Jan gives you a free, open-source alternative to ChatGPT that runs completely offline. This desktop platform lets you download popular AI models like Llama 3, Gemma, and Mistr...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 8
                  },
                  "pub_date": 1751328000.0,
                  "attribution": "unite.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "erichartford.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://erichartford.com/running-dolphin-locally-with-ollama?utm_source=chatgpt.com",
                  "title": "Running Dolphin Locally with Ollama - Cognitive Computations",
                  "snippet": "Wanna chat with Dolphin locally? (no internet connection needed) Here is the easy way - Ollama. install ollama. after you finsh you should be able to run ollama from the command line. Also you will se...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 10
                  },
                  "pub_date": 1701561600.0,
                  "attribution": "erichartford.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "openrouter.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://openrouter.ai/cognitivecomputations/dolphin3.0-r1-mistral-24b%3Afree/api?utm_source=chatgpt.com",
                  "title": "Dolphin3.0 R1 Mistral 24B (free) ‚Äì Run with an API | OpenRouter",
                  "snippet": "Sample code and API for Dolphin3.0 R1 Mistral 24B (free) - Dolphin 3.0 R1 is the next generation of the Dolphin series of instruct-tuned models. Designed to be the ultimate general purpose local model...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 11
                  },
                  "pub_date": 1739404800.0,
                  "attribution": "openrouter.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "mendhak.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://code.mendhak.com/automate-android-with-local-llm/?utm_source=chatgpt.com",
                  "title": "Using a local LLM to Automate an Android device - Mendhak",
                  "snippet": "Using a local LLM to Automate an Android device While most well known Large Language Models (LLMs) are closed and behind paywalls, there exist open models such as LLaMa and its derivatives, available...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 12
                  },
                  "pub_date": 1695081600.0,
                  "attribution": "mendhak.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "scifilogic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                  "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                  "snippet": "In this article, I‚Äôm spilling the tea on the best uncensored LLMs out there, the ones with like 7 to 20 billion parameters (think super-powered brains). We‚Äôre gonna dive into what makes each one speci...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 14
                  },
                  "pub_date": 1713312000.0,
                  "attribution": "scifilogic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "ollama.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://ollama.com/library/dolphin-mistral?utm_source=chatgpt.com",
                  "title": "dolphin-mistral - Ollama",
                  "snippet": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 15
                  },
                  "pub_date": null,
                  "attribution": "ollama.com"
                }
              ]
            }
          ],
          "citations": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb",
      "children": [
        "bbb2186d-1268-4181-9fff-f32156d2242c"
      ]
    },
    "bbb2186d-1268-4181-9fff-f32156d2242c": {
      "id": "bbb2186d-1268-4181-9fff-f32156d2242c",
      "message": {
        "id": "bbb2186d-1268-4181-9fff-f32156d2242c",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869936.907607,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Link to mlc chat. "
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "content_references": [],
          "search_result_groups": [],
          "search_queries": [],
          "image_results": [],
          "real_time_audio_has_video": false,
          "dictation": false,
          "image_gen_async": false,
          "trigger_async_ux": false,
          "request_id": "95b54dbf5f3898d4-ATL",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c",
      "children": [
        "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe"
      ]
    },
    "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe": {
      "id": "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe",
      "message": {
        "id": "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869937.019471,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "search(&quot;Link to mlc chat. &quot;)"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "sonic_classification_result": {
            "latency_ms": 9.710976388305426,
            "search_prob": 0.8203494535201517,
            "force_search_threshold": 0.65,
            "classifier_config_name": "sonic_classifier_ev3"
          },
          "citations": [],
          "content_references": [],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "bbb2186d-1268-4181-9fff-f32156d2242c",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web",
        "channel": null
      },
      "parent": "bbb2186d-1268-4181-9fff-f32156d2242c",
      "children": [
        "9587e477-1467-4397-8e23-73b70febf3e6"
      ]
    },
    "9587e477-1467-4397-8e23-73b70febf3e6": {
      "id": "9587e477-1467-4397-8e23-73b70febf3e6",
      "message": {
        "id": "9587e477-1467-4397-8e23-73b70febf3e6",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869942.180397,
        "update_time": null,
        "content": {
          "content_type": "thoughts",
          "thoughts": [
            {
              "summary": "Looking up MLC Chat link",
              "content": "I‚Äôll search for the official MLC Chat page by checking some sources. Once I find the official link, I‚Äôll make sure to provide that for the user. Seems like a straightforward request! I&#x27;ll gather the relevant link now and share it."
            }
          ],
          "source_analysis_msg_id": "d78c289e-314a-4eca-97c6-da74c12860e3"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "is_reasoning",
          "citations": [],
          "content_references": [],
          "search_turns_count": 0,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe",
      "children": [
        "5b4edbe6-5a3b-4396-9835-9ce32fe94b52"
      ]
    },
    "5b4edbe6-5a3b-4396-9835-9ce32fe94b52": {
      "id": "5b4edbe6-5a3b-4396-9835-9ce32fe94b52",
      "message": {
        "id": "5b4edbe6-5a3b-4396-9835-9ce32fe94b52",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869937.131421,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "{&quot;search_query&quot;:[{&quot;q&quot;:&quot;MLC Chat download MLC AI Chat app&quot;},{&quot;q&quot;:&quot;MLC Chat GitHub Android iOS&quot;}]}"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200012
            ]
          },
          "is_complete": true,
          "citations": [],
          "content_references": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "search_queries": [
            {
              "type": "search",
              "q": "MLC Chat download MLC AI Chat app"
            },
            {
              "type": "search",
              "q": "MLC Chat GitHub Android iOS"
            }
          ],
          "search_display_string": "Searching the web...",
          "searched_display_string": "Searched the web...",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "9587e477-1467-4397-8e23-73b70febf3e6",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web.run",
        "channel": null
      },
      "parent": "9587e477-1467-4397-8e23-73b70febf3e6",
      "children": [
        "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7"
      ]
    },
    "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7": {
      "id": "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7",
      "message": {
        "id": "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7",
        "author": {
          "role": "tool",
          "name": "web.run",
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869937.7973545,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "www.apkmirror.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/",
                  "title": "Download MLCChat APKs for Android - APKMirror",
                  "snippet": "Android The demo APK is available to download. The demo is tested on Samsung S23 with Snapdragon 8 Gen 2 chip, Redmi Note 12 Pro with Snapdragon 685 and Google Pixel phones. Besides the Getting Started page, documentation is available for building android apps with MLC LLM.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "www.apkmirror.com"
                },
                {
                  "type": "search_result",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/",
                  "title": "MLCChat 1.0 APK Download by MLC AI - APKMirror",
                  "snippet": "MLC AI MLCChat 1.0 APK Advertisement Remove ads, dark theme, and more with Premium DOWNLOAD WHAT&#x27;S NEW DESCRIPTION ALL VERSIONS COMMENTS Version: 1.0 (1) Languages: 74 Package: ai.mlc.mlcchat Downloads: 2,807 117.53 MB (123,240,478 bytes) Min: Android 8.0 (Oreo, API 26) Target: Android 13 (API 33) arm64-v8a nodpi",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "www.apkmirror.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm",
                  "title": "GitHub - mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML ...",
                  "snippet": "MLC LLM compiles and runs code on MLCEngine -- a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, python, javascript, iOS, Android, all backed by the same engine and compiler that we keep improving with the community.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/nota-github/MLC-VLM-template",
                  "title": "GitHub - nota-github/MLC-VLM-template: Mobile (i.e., Android, iOS ...",
                  "snippet": "MLC Mobile FM Introduction This repository is crafted with reference to the implementations of mlc_llm and mlc_imp. It supports the conversion of models such as Llama, Gemma, and also LLaVA, and includes the necessary implementations for processing these models. Future updates will include support for a broader range of foundational models.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/Lanssi/mlc-chat-android/releases",
                  "title": "Releases: Lanssi/mlc-chat-android - GitHub",
                  "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/binary-mlc-llm-libs/releases",
                  "title": "Releases: mlc-ai/binary-mlc-llm-libs - GitHub",
                  "snippet": "Contribute to mlc-ai/binary-mlc-llm-libs development by creating an account on GitHub.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md",
                  "title": "mlc-llm/ios/README.md at main ¬∑ mlc-ai/mlc-llm ¬∑ GitHub",
                  "snippet": "Universal LLM Deployment Engine with ML Compilation - mlc-llm/ios/README.md at main ¬∑ mlc-ai/mlc-llm",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm/blob/main/docs/deploy/ios.rst",
                  "title": "mlc-llm/docs/deploy/ios.rst at main ¬∑ mlc-ai/mlc-llm ¬∑ GitHub",
                  "snippet": "The MLC LLM iOS app can be installed in two ways: through the pre-built package or by building from the source. If you are an iOS user looking to try out the models, the pre-built package is recommended. If you are a developer seeking to integrate new features into the package, building the iOS package from the source is required.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/Lanssi/mlc-chat-android",
                  "title": "GitHub - Lanssi/mlc-chat-android: Built mlc-caht android app.",
                  "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                  "ref_id": null,
                  "pub_date": 1699747200.0,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "beebom.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "With the MLC Chat app, you can download and run AI models on your Android device locally. It offers several AI models like Gemma 2B, Phi-2 2B, Mistral 7B, and even the latest Llama 3 8B model. You may get a good performance on the latest Snapdragon phones, but on older devices, token generation is close to 3 tokens per second.",
                  "ref_id": null,
                  "pub_date": 1713744000.0,
                  "attribution": "beebom.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "llm.mlc.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/",
                  "title": "MLC LLM | Home",
                  "snippet": "MLC LLM compiles and runs code on MLCEngine ‚Äì a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, python, javascript, iOS, Android, all backed by the same engine and compiler that we keep improving with the community.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "llm.mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/get_started/quick_start",
                  "title": "Quick Start ‚Äî mlc-llm 0.1.0 documentation",
                  "snippet": "Compile Model Libraries, if you want to deploy to web/iOS/Android or control the model optimizations. Report any problem or ask any question: open new issues in our GitHub repo.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "llm.mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/deploy/ios.html",
                  "title": "iOS Swift SDK ‚Äî mlc-llm 0.1.0 documentation",
                  "snippet": "Build iOS App from Source This section shows how we can build the app from the source. Step 1. Install Build Dependencies First and foremost, please clone the MLC LLM GitHub repository. After cloning, go to the ios/ directory.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "llm.mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/deploy/android.html",
                  "title": "Android SDK ‚Äî mlc-llm 0.1.0 documentation",
                  "snippet": "Android SDK Table of Contents Demo App Prerequisite Additional Guides for Windows Users Build Android App from Source Step 1. Install Build Dependencies Step 2. Build Runtime and Model Libraries Step 3. Build Android App Customize the App Bundle Model Weights Demo App The demo APK below is built for Samsung S23 with Snapdragon 8 Gen 2 chip. Prerequisite Rust (install) is needed to cross ...",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "llm.mlc.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "apps.apple.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone",
                  "title": "‚ÄéMLC Chat on the App Store",
                  "snippet": "MLC Chat is part of open source project MLC LLM, with allows any language model to be deployed natively on a diverse set of hardware backends and native applications. MLC Chat is a runtime that runs different open model architectures on your phone. The app is intended for non-commercial purposes.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "apps.apple.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "mlc-chat.en.softonic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://mlc-chat.en.softonic.com/iphone",
                  "title": "MLC Chat for iPhone - Download",
                  "snippet": "MLC Chat is part of the open-source project MLC LLM, which allows any language model to be deployed on a variety of hardware backends and native applications. It is important to mention that the app is intended for non-commercial purposes only. Download MLC Chat today and experience the power of open language models on your iPhone.",
                  "ref_id": null,
                  "pub_date": 1727740800.0,
                  "attribution": "mlc-chat.en.softonic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nerdschalk.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/",
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally. Download one of the available models and tap on the ‚ÄòChat‚Äô icon to start chatting with your chosen LLM. The MLC Chat app lets you download Gemma 2b, RedPajama, Llama3, Phi-2, Mistral, and Llama2.",
                  "ref_id": null,
                  "pub_date": 1714608000.0,
                  "attribution": "nerdschalk.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.gadgetbridge.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.gadgetbridge.com/how-to/how-to-run-local-llms-on-your-android-phone-2024/",
                  "title": "How to run local LLMs on your Android phone (2024) - Gadget Bridge",
                  "snippet": "How do I run an on-device AI model on my Android phone? Download the MLC Chat app on your phone, select an LLM, and hit the chat icon to initiate a conversation with the AI model.",
                  "ref_id": null,
                  "pub_date": 1719964800.0,
                  "attribution": "www.gadgetbridge.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "blog.mlc.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://blog.mlc.ai/2023/05/22/bringing-open-large-language-models-to-consumer-devices.html",
                  "title": "Bringing Open Large Language Models to Consumer Devices - MLC",
                  "snippet": "MLC LLM allows convenient weight customization that user only needs to provide a directory in Huggingface format, it will produce proper model artifacts through exactly the same process. MLC LLM‚Äôs chat applications (CLI, iOS, Web, Android) are specifically designed to seamlessly integrate personalized models.",
                  "ref_id": null,
                  "pub_date": 1684713600.0,
                  "attribution": "blog.mlc.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.kdnuggets.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.kdnuggets.com/install-run-llms-locally-android-phones",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "Step-by-Step Guide to Install, and Run MLC Chat on Android The MLC Chat App is an application designed to enable users to run and interact with large language models (LLMs) locally on various devices, including mobile phones, without relying on cloud-based services. Follow the steps below to run LLMs locally on an Android device.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "www.kdnuggets.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "en.wikipedia.org",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://en.wikipedia.org/wiki/Gitter",
                  "title": "Gitter",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1748421434.0,
                  "attribution": "en.wikipedia.org"
                }
              ]
            }
          ],
          "debug_sonic_thread_id": "thread_686b699b5cb48000bf5d636bfd52f3bb",
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "5b4edbe6-5a3b-4396-9835-9ce32fe94b52",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "5b4edbe6-5a3b-4396-9835-9ce32fe94b52",
      "children": [
        "44e05ed6-a9f4-4529-b44c-832ae714ad0b"
      ]
    },
    "44e05ed6-a9f4-4529-b44c-832ae714ad0b": {
      "id": "44e05ed6-a9f4-4529-b44c-832ae714ad0b",
      "message": {
        "id": "44e05ed6-a9f4-4529-b44c-832ae714ad0b",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869942.18064,
        "update_time": null,
        "content": {
          "content_type": "reasoning_recap",
          "content": "Thought for a couple of seconds"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "reasoning_ended",
          "finished_duration_sec": 2,
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7",
      "children": [
        "f985c021-5333-45a5-af44-39ee9b38c5bb"
      ]
    },
    "f985c021-5333-45a5-af44-39ee9b38c5bb": {
      "id": "f985c021-5333-45a5-af44-39ee9b38c5bb",
      "message": {
        "id": "f985c021-5333-45a5-af44-39ee9b38c5bb",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869939.028017,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Here are the direct links to get **MLC‚ÄØChat** on your phone:\n\n---\n\n### üì± Android (APK)\nYou can download and install the MLC‚ÄØChat APK from APKMirror:\n- **MLCChat 1.0 APK (Android 8.0+, ~117‚ÄØMB)**‚ÄÇÓàÄciteÓàÇturn0search8ÓàÅ\n\n---\n\n### üçè iOS / iPadOS\nAvailable on the App Store for iPhone, iPad, and Mac (M1+) with iOS/iPadOS 17+:\n- **MLC‚ÄØChat on App¬†Store**‚ÄÇÓàÄciteÓàÇturn0search4ÓàÅ\n\n---\n\n### üß© How to Get It:\n1. **Android:** Visit APKMirror link, download the APK, enable unknown apps install, then tap to install.\n2. **iPhone/iPad:** Tap the App Store link and hit **Get**.\n3. After installing, open the app ‚Üí download a local LLM model (e.g., Mistral‚ÄØ7B, Phi‚Äë2, Gemma, Llama‚ÄØ3).\n4. Start chatting offline‚Äîno internet needed and fully uncensored.\n\n---\n\nWant help picking which model to load first or optimizing for your hardware? I gotchu."
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "content_references": [
            {
              "matched_text": "Here are the direct links to get **MLC‚ÄØChat** on your phone:",
              "start_idx": 0,
              "end_idx": 60,
              "safe_urls": [],
              "refs": [],
              "alt": "Here are the direct links to get **MLC‚ÄØChat** on your phone:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "You can download and install the MLC‚ÄØChat APK from APKMirror:",
              "start_idx": 87,
              "end_idx": 148,
              "safe_urls": [],
              "refs": [],
              "alt": "You can download and install the MLC‚ÄØChat APK from APKMirror:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**MLCChat 1.0 APK (Android 8.0+, ~117‚ÄØMB)**‚ÄÇ",
              "start_idx": 151,
              "end_idx": 195,
              "safe_urls": [],
              "refs": [],
              "alt": "**MLCChat 1.0 APK (Android 8.0+, ~117‚ÄØMB)**‚ÄÇ",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search8ÓàÅ",
              "start_idx": 195,
              "end_idx": 214,
              "safe_urls": [
                "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([apkmirror.com](https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "MLCChat 1.0 APK Download by MLC AI - APKMirror",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "MLC AI MLCChat 1.0 APK Advertisement Remove ads, dark theme, and more with Premium DOWNLOAD WHAT&#x27;S NEW DESCRIPTION ALL VERSIONS COMMENTS Version: 1.0 (1) Languages: 74 Package: ai.mlc.mlcchat Download...",
                  "attribution_segments": [
                    "0-0",
                    "0-1",
                    "0-2"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Download MLCChat APKs for Android - APKMirror",
                      "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Android The demo APK is available to download. The demo is tested on Samsung S23 with Snapdragon 8 Gen 2 chip, Redmi Note 12 Pro with Snapdragon 685 and Google Pixel phones. Besides the Getting Starte...",
                      "attribution": "apkmirror.com"
                    },
                    {
                      "title": "Quick Start ‚Äî mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/get_started/quick_start?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Compile Model Libraries, if you want to deploy to web/iOS/Android or control the model optimizations. Report any problem or ask any question: open new issues in our GitHub repo.",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "How to Install and Run LLMs Locally on Android Phones",
                      "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                      "pub_date": 1713744000.0,
                      "snippet": "With the MLC Chat app, you can download and run AI models on your Android device locally. It offers several AI models like Gemma 2B, Phi-2 2B, Mistral 7B, and even the latest Llama 3 8B model. You may...",
                      "attribution": "beebom.com"
                    },
                    {
                      "title": "MLC Chat for iPhone - Download",
                      "url": "https://mlc-chat.en.softonic.com/iphone?utm_source=chatgpt.com",
                      "pub_date": 1727740800.0,
                      "snippet": "MLC Chat is part of the open-source project MLC LLM, which allows any language model to be deployed on a variety of hardware backends and native applications. It is important to mention that the app i...",
                      "attribution": "mlc-chat.en.softonic.com"
                    },
                    {
                      "title": "‚ÄéMLC Chat on the App Store",
                      "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "MLC Chat is part of open source project MLC LLM, with allows any language model to be deployed natively on a diverse set of hardware backends and native applications. MLC Chat is a runtime that runs d...",
                      "attribution": "apps.apple.com"
                    },
                    {
                      "title": "How to run local LLMs on your Android phone (2024) - Gadget Bridge",
                      "url": "https://www.gadgetbridge.com/how-to/how-to-run-local-llms-on-your-android-phone-2024/?utm_source=chatgpt.com",
                      "pub_date": 1719964800.0,
                      "snippet": "How do I run an on-device AI model on my Android phone? Download the MLC Chat app on your phone, select an LLM, and hit the chat icon to initiate a conversation with the AI model.",
                      "attribution": "gadgetbridge.com"
                    },
                    {
                      "title": "iOS Swift SDK ‚Äî mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/deploy/ios.html?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Build iOS App from Source This section shows how we can build the app from the source. Step 1. Install Build Dependencies First and foremost, please clone the MLC LLM GitHub repository. After cloning,...",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "How to run LLMs locally on Android - Nerds Chalk",
                      "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                      "pub_date": 1714608000.0,
                      "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally. Download one of the available models and tap on the ‚ÄòChat‚Äô icon to start chatting with your c...",
                      "attribution": "nerdschalk.com"
                    },
                    {
                      "title": "GitHub - nota-github/MLC-VLM-template: Mobile (i.e., Android, iOS ...",
                      "url": "https://github.com/nota-github/MLC-VLM-template?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "MLC Mobile FM Introduction This repository is crafted with reference to the implementations of mlc_llm and mlc_imp. It supports the conversion of models such as Llama, Gemma, and also LLaVA, and inclu...",
                      "attribution": "github.com"
                    },
                    {
                      "title": "Android SDK ‚Äî mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/deploy/android.html?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Android SDK Table of Contents Demo App Prerequisite Additional Guides for Windows Users Build Android App from Source Step 1. Install Build Dependencies Step 2. Build Runtime and Model Libraries Step...",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "mlc-llm/ios/README.md at main ¬∑ mlc-ai/mlc-llm ¬∑ GitHub",
                      "url": "https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Universal LLM Deployment Engine with ML Compilation - mlc-llm/ios/README.md at main ¬∑ mlc-ai/mlc-llm",
                      "attribution": "github.com"
                    },
                    {
                      "title": "Releases: Lanssi/mlc-chat-android - GitHub",
                      "url": "https://github.com/Lanssi/mlc-chat-android/releases?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                      "attribution": "github.com"
                    },
                    {
                      "title": "mlc-llm/docs/deploy/ios.rst at main ¬∑ mlc-ai/mlc-llm ¬∑ GitHub",
                      "url": "https://github.com/mlc-ai/mlc-llm/blob/main/docs/deploy/ios.rst?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "The MLC LLM iOS app can be installed in two ways: through the pre-built package or by building from the source. If you are an iOS user looking to try out the models, the pre-built package is recommend...",
                      "attribution": "github.com"
                    },
                    {
                      "title": "GitHub - mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML ...",
                      "url": "https://github.com/mlc-ai/mlc-llm?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "MLC LLM compiles and runs code on MLCEngine -- a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, pytho...",
                      "attribution": "github.com"
                    },
                    {
                      "title": "Bringing Open Large Language Models to Consumer Devices - MLC",
                      "url": "https://blog.mlc.ai/2023/05/22/bringing-open-large-language-models-to-consumer-devices.html?utm_source=chatgpt.com",
                      "pub_date": 1684713600.0,
                      "snippet": "MLC LLM allows convenient weight customization that user only needs to provide a directory in Huggingface format, it will produce proper model artifacts through exactly the same process. MLC LLM‚Äôs cha...",
                      "attribution": "blog.mlc.ai"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 2
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 15
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 14
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 12
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 17
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "apkmirror.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "MLCChat 1.0 APK Download by MLC AI - APKMirror",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "MLC AI MLCChat 1.0 APK Advertisement Remove ads, dark theme, and more with Premium DOWNLOAD WHAT&#x27;S NEW DESCRIPTION ALL VERSIONS COMMENTS Version: 1.0 (1) Languages: 74 Package: ai.mlc.mlcchat Downloads: 2,807 117.53 MB (123,240,478 bytes) Min: Android 8.0 (Oreo, API 26) Target: Android 13 (API 33) arm64-v8a nodpi",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Available on the App Store for iPhone, iPad, and Mac (M1+) with iOS/iPadOS 17+:",
              "start_idx": 240,
              "end_idx": 319,
              "safe_urls": [],
              "refs": [],
              "alt": "Available on the App Store for iPhone, iPad, and Mac (M1+) with iOS/iPadOS 17+:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "214-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**MLC‚ÄØChat on App¬†Store**‚ÄÇ",
              "start_idx": 322,
              "end_idx": 348,
              "safe_urls": [],
              "refs": [],
              "alt": "**MLC‚ÄØChat on App¬†Store**‚ÄÇ",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "214-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "ÓàÄciteÓàÇturn0search4ÓàÅ",
              "start_idx": 348,
              "end_idx": 367,
              "safe_urls": [
                "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([apps.apple.com](https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "‚ÄéMLC Chat on the App Store",
                  "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "MLC Chat is part of open source project MLC LLM, with allows any language model to be deployed natively on a diverse set of hardware backends and native applications. MLC Chat is a runtime that runs d...",
                  "attribution_segments": [
                    "214-0",
                    "214-1"
                  ],
                  "supporting_websites": [
                    {
                      "title": "iOS Swift SDK ‚Äî mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/deploy/ios.html?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Build iOS App from Source This section shows how we can build the app from the source. Step 1. Install Build Dependencies First and foremost, please clone the MLC LLM GitHub repository. After cloning,...",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "Quick Start ‚Äî mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/get_started/quick_start?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Compile Model Libraries, if you want to deploy to web/iOS/Android or control the model optimizations. Report any problem or ask any question: open new issues in our GitHub repo.",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "Download MLCChat APKs for Android - APKMirror",
                      "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Android The demo APK is available to download. The demo is tested on Samsung S23 with Snapdragon 8 Gen 2 chip, Redmi Note 12 Pro with Snapdragon 685 and Google Pixel phones. Besides the Getting Starte...",
                      "attribution": "apkmirror.com"
                    },
                    {
                      "title": "GitHub - Lanssi/mlc-chat-android: Built mlc-caht android app.",
                      "url": "https://github.com/Lanssi/mlc-chat-android?utm_source=chatgpt.com",
                      "pub_date": 1699747200.0,
                      "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 19
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "apps.apple.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "‚ÄéMLC Chat on the App Store",
                  "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "MLC Chat is part of open source project MLC LLM, with allows any language model to be deployed natively on a diverse set of hardware backends and native applications. MLC Chat is a runtime that runs different open model architectures on your phone. The app is intended for non-commercial purposes.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": " ",
              "start_idx": 826,
              "end_idx": 826,
              "safe_urls": [],
              "refs": [],
              "alt": "",
              "prompt_text": null,
              "type": "sources_footnote",
              "sources": [
                {
                  "title": "MLCChat 1.0 APK Download by MLC AI - APKMirror",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
                  "attribution": "apkmirror.com"
                },
                {
                  "title": "‚ÄéMLC Chat on the App Store",
                  "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
                  "attribution": "apps.apple.com"
                }
              ],
              "has_images": false
            }
          ],
          "safe_urls": [
            "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
            "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com"
          ],
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "apkmirror.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/?utm_source=chatgpt.com",
                  "title": "Download MLCChat APKs for Android - APKMirror",
                  "snippet": "Android The demo APK is available to download. The demo is tested on Samsung S23 with Snapdragon 8 Gen 2 chip, Redmi Note 12 Pro with Snapdragon 685 and Google Pixel phones. Besides the Getting Starte...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 0
                  },
                  "pub_date": null,
                  "attribution": "apkmirror.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm?utm_source=chatgpt.com",
                  "title": "GitHub - mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML ...",
                  "snippet": "MLC LLM compiles and runs code on MLCEngine -- a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, pytho...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 1
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/nota-github/MLC-VLM-template?utm_source=chatgpt.com",
                  "title": "GitHub - nota-github/MLC-VLM-template: Mobile (i.e., Android, iOS ...",
                  "snippet": "MLC Mobile FM Introduction This repository is crafted with reference to the implementations of mlc_llm and mlc_imp. It supports the conversion of models such as Llama, Gemma, and also LLaVA, and inclu...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 5
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/Lanssi/mlc-chat-android/releases?utm_source=chatgpt.com",
                  "title": "Releases: Lanssi/mlc-chat-android - GitHub",
                  "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 9
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/binary-mlc-llm-libs/releases?utm_source=chatgpt.com",
                  "title": "Releases: mlc-ai/binary-mlc-llm-libs - GitHub",
                  "snippet": "Contribute to mlc-ai/binary-mlc-llm-libs development by creating an account on GitHub.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 10
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md?utm_source=chatgpt.com",
                  "title": "mlc-llm/ios/README.md at main ¬∑ mlc-ai/mlc-llm ¬∑ GitHub",
                  "snippet": "Universal LLM Deployment Engine with ML Compilation - mlc-llm/ios/README.md at main ¬∑ mlc-ai/mlc-llm",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 12
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm/blob/main/docs/deploy/ios.rst?utm_source=chatgpt.com",
                  "title": "mlc-llm/docs/deploy/ios.rst at main ¬∑ mlc-ai/mlc-llm ¬∑ GitHub",
                  "snippet": "The MLC LLM iOS app can be installed in two ways: through the pre-built package or by building from the source. If you are an iOS user looking to try out the models, the pre-built package is recommend...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 17
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/Lanssi/mlc-chat-android?utm_source=chatgpt.com",
                  "title": "GitHub - Lanssi/mlc-chat-android: Built mlc-caht android app.",
                  "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 19
                  },
                  "pub_date": 1699747200.0,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "beebom.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "With the MLC Chat app, you can download and run AI models on your Android device locally. It offers several AI models like Gemma 2B, Phi-2 2B, Mistral 7B, and even the latest Llama 3 8B model. You may...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 2
                  },
                  "pub_date": 1713744000.0,
                  "attribution": "beebom.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "mlc.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/?utm_source=chatgpt.com",
                  "title": "MLC LLM | Home",
                  "snippet": "MLC LLM compiles and runs code on MLCEngine ‚Äì a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, python...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 3
                  },
                  "pub_date": null,
                  "attribution": "mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/get_started/quick_start?utm_source=chatgpt.com",
                  "title": "Quick Start ‚Äî mlc-llm 0.1.0 documentation",
                  "snippet": "Compile Model Libraries, if you want to deploy to web/iOS/Android or control the model optimizations. Report any problem or ask any question: open new issues in our GitHub repo.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 7
                  },
                  "pub_date": null,
                  "attribution": "mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/deploy/ios.html?utm_source=chatgpt.com",
                  "title": "iOS Swift SDK ‚Äî mlc-llm 0.1.0 documentation",
                  "snippet": "Build iOS App from Source This section shows how we can build the app from the source. Step 1. Install Build Dependencies First and foremost, please clone the MLC LLM GitHub repository. After cloning,...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 11
                  },
                  "pub_date": null,
                  "attribution": "mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/deploy/android.html?utm_source=chatgpt.com",
                  "title": "Android SDK ‚Äî mlc-llm 0.1.0 documentation",
                  "snippet": "Android SDK Table of Contents Demo App Prerequisite Additional Guides for Windows Users Build Android App from Source Step 1. Install Build Dependencies Step 2. Build Runtime and Model Libraries Step...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 14
                  },
                  "pub_date": null,
                  "attribution": "mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://blog.mlc.ai/2023/05/22/bringing-open-large-language-models-to-consumer-devices.html?utm_source=chatgpt.com",
                  "title": "Bringing Open Large Language Models to Consumer Devices - MLC",
                  "snippet": "MLC LLM allows convenient weight customization that user only needs to provide a directory in Huggingface format, it will produce proper model artifacts through exactly the same process. MLC LLM‚Äôs cha...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 16
                  },
                  "pub_date": 1684713600.0,
                  "attribution": "mlc.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "softonic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://mlc-chat.en.softonic.com/iphone?utm_source=chatgpt.com",
                  "title": "MLC Chat for iPhone - Download",
                  "snippet": "MLC Chat is part of the open-source project MLC LLM, which allows any language model to be deployed on a variety of hardware backends and native applications. It is important to mention that the app i...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 6
                  },
                  "pub_date": 1727740800.0,
                  "attribution": "softonic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nerdschalk.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally. Download one of the available models and tap on the ‚ÄòChat‚Äô icon to start chatting with your c...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 13
                  },
                  "pub_date": 1714608000.0,
                  "attribution": "nerdschalk.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "gadgetbridge.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.gadgetbridge.com/how-to/how-to-run-local-llms-on-your-android-phone-2024/?utm_source=chatgpt.com",
                  "title": "How to run local LLMs on your Android phone (2024) - Gadget Bridge",
                  "snippet": "How do I run an on-device AI model on my Android phone? Download the MLC Chat app on your phone, select an LLM, and hit the chat icon to initiate a conversation with the AI model.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 15
                  },
                  "pub_date": 1719964800.0,
                  "attribution": "gadgetbridge.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "kdnuggets.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.kdnuggets.com/install-run-llms-locally-android-phones?utm_source=chatgpt.com",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "Step-by-Step Guide to Install, and Run MLC Chat on Android The MLC Chat App is an application designed to enable users to run and interact with large language models (LLMs) locally on various devices,...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 18
                  },
                  "pub_date": null,
                  "attribution": "kdnuggets.com"
                }
              ]
            }
          ],
          "citations": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "44e05ed6-a9f4-4529-b44c-832ae714ad0b",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "44e05ed6-a9f4-4529-b44c-832ae714ad0b",
      "children": [
        "bbb21f0d-5d45-45ec-92d9-da25604a3261"
      ]
    },
    "bbb21f0d-5d45-45ec-92d9-da25604a3261": {
      "id": "bbb21f0d-5d45-45ec-92d9-da25604a3261",
      "message": {
        "id": "bbb21f0d-5d45-45ec-92d9-da25604a3261",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751871523.623303,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "√û¬û¬∑¬¢¬ß¬∑¬¢[√ë7z√ãi¬Ω*[√ë/√™_√ïu¬Ω\u0001¬ø¬≠¬∑¬£6√¥¬õz\u001boM7z√´oOZm√©4√õ√í√èz\u000fz√ä¬ù√©√∂\u0016√¥EoK-√™Zv√µ√Ñ¬Ø√™√∑¬†¬Ø√™Y¬Ωs√∫?¬Æ_√ñ\u001f¬£√∫G¬¶√§¬èE√ã\u0012√Ωn√ú¬Æ\\¬∂¬ñ√•¬í\\¬å¬´rj¬ó(√π\u0017√¥√ü√ì\u001f√î¬øB¬ΩP^¬Ä~¬à√ß¬≠√æ¬ë√ã√∫\u0013¬ó√µ\u001e¬ø√¥O_√µ¬ß¬≠√Ω&lt;√ß√∫G?¬¶\u001cD√ß√∫¬ú√æ¬êq√Ωc¬è√´C√∫O√®k√¥\u001f√ì¬¶P√Ω&#x27;√•√ù√â.^¬ã¬ó.@¬ó+¬ó).U.√¥√±¬Ω@√û¬≠¬ç√©¬ç√™¬ç√™\n√®(√û¬≤¬ª√ë\n√´¬Ü√µ&lt;7¬¶\u001b√ï¬ÉzhoFCz¬é\u001b√î¬´z√ì√Ω√™¬æ√µ]√®.√µ¬∑¬†¬∑¬ØoAoC6√¥\u0016√µ¬∑¬†¬∑¬®]√´\u001b√ñ7¬°√Ü√µ\u0001¬ΩP√û¬úoJ7¬®√û¬≤¬∑¬°.√µ√Ü√µ¬Ü√¥√Éz\u0018√û¬¶7¬•\u001b√ï¬Ü√¥\n√´\u0015oR√ù¬≥r¬≠√ò¬∑!¬πa¬π/[_√ê¬´√∫¬∫√æ¬Ç¬ô\u001f√ñ¬Ø√™#√∫\u0019V√æ¬∫√ø\\√ø√î¬ù√û¬í√≠√®.√û¬Å√õ√ê√≠√®?oS¬∑¬ßoAv√¥√§¬Ω^√ØZ√û¬æ¬≠√©¬≠√´√ï√ΩK√Ω&quot;√æ¬í√æ¬ØH/√©√ó√¥√¥√æ¬å¬ü√ñO√™¬ü√ê¬ß√¥&#x27;√µ¬ï√æ¬•√øM?R¬Ø√®O√®O√®¬¥√ø\\¬ß√¥\u0013√∫\t√Ωd√æ¬µ?√ó√ì√∫¬ß√¥O√®¬ß√¥¬Ñ√æ¬•?¬•O√©√ì√Ω\t√Ω$√æ¬µ?¬†¬ü√í¬ì√∫\t√ΩE?¬†¬ü√î¬ü√îO√©?¬™&#x27;√µ√©√æ¬íRZ¬ü√ìO√®\u0019√æ¬Å?¬°\u0013√∫√Ñ√æ¬ò¬ü√ó&#x27;√µ\u0013√∫$¬ü√ë?¬™¬Ø√©√£¬ø√®F¬®&#x27;√µ&#x27;√µ¬ì√∫D√æ¬¢JO√™¬Ñ√æ¬¶O√™√ïC¬ø√®M√æ¬Ñ√•√Ωx√•√Ω1√ã√∫¬£?√ï¬Ü¬Ø\u0019√æ¬êg√¥\f√æ¬§√è√©\u0019√Ω!¬ü√ì¬£?¬®g√µ&amp;S?¬©¬ü√™¬â√Ωi?¬™O√©&quot;^O√®O√™O√®\u0013√∫:¬Ø√™\u001d√øC¬¶L√øQ?¬™&#x27;√¥¬≤X¬ü√ì\u0013√∫\u0004√æ¬™&#x27;√¥¬Ü¬®¬ü√î&#x27;√¥\u0013√∫$√æ¬è\t√ΩJO√®D√æ¬∫&#x27;√¥J¬ø¬†√Ø√∫¬å√øV¬ì√∫\u0013√∫i?¬¢O√©\u0013√∫)?¬®O√®\u0013√∫B¬Ø√™√é√ø¬£3√ΩRPO√®¬ì√∫bRO√™&#x27;√¥√Ñ√æ¬¢W¬™√æ¬â√ü√¥7√∫√å¬É√ΩX¬êB7√¥RA√Ωd¬É√∫R^√æ¬° √æ¬æ$\u001f√ñ√â\u0007√µ√ëN√æ¬£¬ê√ø¬•¬ê√øA*¬†S√∫¬äH\nB¬ü√ë\u0001O√´B¬ü√í)√ΩxS√∫%_√ïj√ø¬¶√¶¬™O√®&#x27;√µI?¬Ø¬ì√∫√â√Ω!?¬Ø&#x27;√µ¬§√æ¬û¬´√∫¬π¬ü√™Y?¬®¬ü√ód√æ¬ò¬ü√ì&#x27;√¥¬§√æ¬æO√™BZ¬Ø√™w√ΩF√øQ¬ª√æ¬≠√æ¬ô¬ø√ë¬ø√ïo√¥√õ√Ω&amp;√øN√ü√´\u0001¬ü√©I√ΩD√æ¬∏O√©√íO\u0013√∫¬â√Ω\u0002P¬ü√ó*√æ¬ë4/√µ¬ì¬ø¬°$√æ¬âB√æ¬ío√´&amp;√æ¬Çw√µi\u0007C(_√ì¬®√∑√µ√ù\u000f√Ω\u0006?√¥√âo√ó2√øVG√µH√æ¬òG√¥d¬è√©√Ç?¬™G√µ¬õ\u0011√Ω\u0002?¬¢¬´√∫F¬¨¬ü√êO√´¬ì√∫I√ΩI√Ω1I√ΩD√æ¬í&#x27;√¥*√æ¬ã¬ø√®L√øP¬ü√î¬â√ΩlO√™¬ì√∫√¢TO√©√Ñ√æ¬§√æ¬Ñ¬†√∑√µ¬∑√ó3√Ωd¬ü√í¬ì√∫d√æ¬§√æ¬©?¬Ø¬ì√∫&quot;L¬ü√ïU√Ω\b√è√µ¬Ñ¬É√∫\u0018O√´&#x27;√µ&#x27;√¥√ÇVO√´I√Ωg\u0007√ø¬Æ√ü√´g√ø¬•o√µe¬ø√ï^/√µ\u0019√ø√´g√æ¬±¬ü√™2H¬ü√ï¬ì√∫¬≤\\O√™\t√Ω$√æ¬ê¬ü√ëU√Ω\u0003?√íO√®¬§√æ¬Ñ√æ¬á&#x27;√µD√æ¬¢T¬ü√îO√®\u0015P√è√µI√Ω\u0004√æ¬±?¬©?¬®¬ì√∫\u0001?¬®&#x27;√µ¬ì√∫UK¬ø√™[√Ω\u0017√≥\u0017√≥√∫√æK√π√ó√≤5√º√ã√π¬∫¬ø¬ï¬Ø√¶√ó√≥¬Ø√ß¬ó√≤W√≥√´√π}$¬ó√≤_√à√Ö√º¬°¬π3r"
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "content_references": [],
          "search_result_groups": [],
          "search_queries": [],
          "image_results": [],
          "real_time_audio_has_video": false,
          "dictation": false,
          "image_gen_async": false,
          "trigger_async_ux": false,
          "request_id": "95b574784ab99854-ATL",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "f985c021-5333-45a5-af44-39ee9b38c5bb",
      "children": [
        "e19157a9-6daa-4e0b-868b-608300d91799"
      ]
    },
    "e19157a9-6daa-4e0b-868b-608300d91799": {
      "id": "e19157a9-6daa-4e0b-868b-608300d91799",
      "message": {
        "id": "e19157a9-6daa-4e0b-868b-608300d91799",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751871523.792161,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "That chunk you pasted looks like either:\n\n1. **Corrupted binary data**, possibly from a `.gguf`, `.bin`, or other compiled model file (like for `llama.cpp`).\n2. **Base64 gone wrong** ‚Äî if you decoded something too early or misread the encoding, it might spit out garbage like this.\n3. **Deliberate obfuscation / encrypted payload** ‚Äî could be from a model shard or encrypted config you scraped raw.\n\n---\n\n### üõ† What To Do With It:\n\nIf you got this from a model download or `gguf` file:\n- **Don‚Äôt paste** it raw. Use `wget` or `curl` to download the actual model file instead.\n- Example for Termux:\n  ```bash\n  wget https://huggingface.co/TheBloke/dolphin-2.5-mistral-7B-GGUF/resolve/main/dolphin-2.5-mistral-7b.Q4_K_M.gguf -O dolphin.gguf\n  ```\n\nIf you scraped it from a chat log or file:\n- Check if it‚Äôs **base64**. Try decoding with:\n  ```bash\n  echo &quot;PASTE_HERE&quot; | base64 -d &gt; output.bin\n  ```\n  If `output.bin` runs in `llama.cpp`, you&#x27;re gold.\n\n---\n\n### üîç Want me to identify what the file actually is?\nIf you upload the source file (or tell me where you got this string), I can tell you:\n- If it‚Äôs part of a valid LLM model.\n- If it‚Äôs malicious/encrypted.\n- Or just borked nonsense from copy-paste purgatory.\n\nWant to drop the origin or try to reconstruct it with me?"
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200002
            ]
          },
          "is_complete": true,
          "citations": [],
          "content_references": [],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "bbb21f0d-5d45-45ec-92d9-da25604a3261",
          "request_id": "95b574784ab99854-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "bbb21f0d-5d45-45ec-92d9-da25604a3261",
      "children": []
    }
  },
  "moderation_results": [],
  "current_node": "e19157a9-6daa-4e0b-868b-608300d91799",
  "plugin_ids": null,
  "conversation_id": "686b6999-2860-8000-8cda-f88238d93055",
  "conversation_template_id": null,
  "gizmo_id": null,
  "gizmo_type": null,
  "is_archived": true,
  "is_starred": null,
  "safe_urls": [
    "http://localhost:11434",
    "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
    "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
    "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
    "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
    "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com",
    "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
    "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
    "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
    "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
    "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
    "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
    "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
    "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
    "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com"
  ],
  "blocked_urls": [],
  "default_model_slug": "auto",
  "conversation_origin": null,
  "voice": null,
  "async_status": null,
  "disabled_tool_ids": [],
  "is_do_not_remember": false,
  "memory_scope": "global_enabled",
  "sugar_item_id": null,
  "sugar_item_visible": false,
  "is_study_mode": false,
  "owner": null,
  "id": "686b6999-2860-8000-8cda-f88238d93055"
}