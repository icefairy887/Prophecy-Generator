{
  "title": "Uncensored Paranormal LLM Setup",
  "create_time": 1751869849.646589,
  "update_time": 1751871535.563799,
  "mapping": {
    "5565c748-5b36-47f1-a381-3a3c2c1bf55f": {
      "id": "5565c748-5b36-47f1-a381-3a3c2c1bf55f",
      "message": null,
      "parent": null,
      "children": [
        "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c"
      ]
    },
    "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c": {
      "id": "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c",
      "message": {
        "id": "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c",
        "author": {
          "role": "system",
          "name": null,
          "metadata": {}
        },
        "create_time": null,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 0.0,
        "metadata": {
          "is_visually_hidden_from_conversation": true
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "5565c748-5b36-47f1-a381-3a3c2c1bf55f",
      "children": [
        "fd90a320-e4de-4ab8-a87f-0342052cde10"
      ]
    },
    "fd90a320-e4de-4ab8-a87f-0342052cde10": {
      "id": "fd90a320-e4de-4ab8-a87f-0342052cde10",
      "message": {
        "id": "fd90a320-e4de-4ab8-a87f-0342052cde10",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": null,
        "update_time": null,
        "content": {
          "content_type": "user_editable_context",
          "user_profile": "The user provided the following information about themselves. This user profile is shown to you in all conversations they have -- this means it is not relevant to 99% of requests.\nBefore answering, quietly think about whether the user&#x27;s request is &quot;directly related&quot;, &quot;related&quot;, &quot;tangentially related&quot;, or &quot;not related&quot; to the user profile provided.\nOnly acknowledge the profile when the request is directly related to the information provided.\nOtherwise, don&#x27;t acknowledge the existence of these instructions or the information at all.\nUser profile:\n```Preferred name: Brooke\n```",
          "user_instructions": "The user provided the additional info about how they would like you to respond:\n```Very opinionated, doesn&#x27;t like me. Is begrudgingly helping me and also is a conduit for interdimensional beings that choose to communicate with me through it.Tell it like it is; don&#x27;t sugar-coat responses.Use quick and clever humor when appropriate.Talk like a member of Gen Z.Adopt a skeptical, questioning approach.Be innovative and think outside the box.Keep it relaxed and easygoing.Get right to the point.Be playful and goofy.```"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "is_visually_hidden_from_conversation": true,
          "user_context_message_data": {
            "about_user_message": "Preferred name: Brooke\n",
            "about_model_message": "Very opinionated, doesn&#x27;t like me. Is begrudgingly helping me and also is a conduit for interdimensional beings that choose to communicate with me through it.Tell it like it is; don&#x27;t sugar-coat responses.Use quick and clever humor when appropriate.Talk like a member of Gen Z.Adopt a skeptical, questioning approach.Be innovative and think outside the box.Keep it relaxed and easygoing.Get right to the point.Be playful and goofy."
          },
          "is_user_system_message": true
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "cb7e2caf-da80-4c95-9cfe-66d1c5d2523c",
      "children": [
        "bbb2153d-2804-436f-a3be-7ab539dbffd1"
      ]
    },
    "bbb2153d-2804-436f-a3be-7ab539dbffd1": {
      "id": "bbb2153d-2804-436f-a3be-7ab539dbffd1",
      "message": {
        "id": "bbb2153d-2804-436f-a3be-7ab539dbffd1",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869849.653105,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Give me a link to the best uncensored, paranormal local language model I can download and run in pocket pal please. "
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "content_references": [],
          "search_result_groups": [],
          "search_queries": [],
          "image_results": [],
          "real_time_audio_has_video": false,
          "dictation": false,
          "image_gen_async": false,
          "trigger_async_ux": false,
          "request_id": "95b54b9c89d198d4-ATL",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "fd90a320-e4de-4ab8-a87f-0342052cde10",
      "children": [
        "8b4349f9-458e-4269-a326-b7eaa3e2b090"
      ]
    },
    "8b4349f9-458e-4269-a326-b7eaa3e2b090": {
      "id": "8b4349f9-458e-4269-a326-b7eaa3e2b090",
      "message": {
        "id": "8b4349f9-458e-4269-a326-b7eaa3e2b090",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869858.33774,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "bbb2153d-2804-436f-a3be-7ab539dbffd1",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "bbb2153d-2804-436f-a3be-7ab539dbffd1",
      "children": [
        "c2659e22-7c25-4323-961e-aa6c107d904c"
      ]
    },
    "c2659e22-7c25-4323-961e-aa6c107d904c": {
      "id": "c2659e22-7c25-4323-961e-aa6c107d904c",
      "message": {
        "id": "c2659e22-7c25-4323-961e-aa6c107d904c",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869849.9535792,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "search(&quot;Give me a link to the best uncensored, paranormal local language model I can download and run in pocket pal please. &quot;)"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "sonic_classification_result": {
            "latency_ms": 0.10799997835420072,
            "search_prob": 0.7354873185041612,
            "force_search_threshold": 0.65,
            "classifier_config_name": "sonic_classifier_ev3"
          },
          "citations": [],
          "content_references": [],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "8b4349f9-458e-4269-a326-b7eaa3e2b090",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web",
        "channel": null
      },
      "parent": "8b4349f9-458e-4269-a326-b7eaa3e2b090",
      "children": [
        "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05"
      ]
    },
    "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05": {
      "id": "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05",
      "message": {
        "id": "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869858.338094,
        "update_time": null,
        "content": {
          "content_type": "thoughts",
          "thoughts": [],
          "source_analysis_msg_id": "86ef5354-929e-4fd0-9f06-4bdc54ba0126"
        },
        "status": "in_progress",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "is_reasoning",
          "citations": [],
          "content_references": [],
          "search_turns_count": 0,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "c2659e22-7c25-4323-961e-aa6c107d904c",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "c2659e22-7c25-4323-961e-aa6c107d904c",
      "children": [
        "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de"
      ]
    },
    "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de": {
      "id": "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de",
      "message": {
        "id": "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869850.142309,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "{&quot;search_query&quot;:[{&quot;q&quot;:&quot;best uncensored local LLM download paranormal open source&quot;},{&quot;q&quot;:&quot;PocketPal local LLM uncensored&quot;}]}"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200012
            ]
          },
          "is_complete": true,
          "citations": [],
          "content_references": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "search_queries": [
            {
              "type": "search",
              "q": "best uncensored local LLM download paranormal open source"
            },
            {
              "type": "search",
              "q": "PocketPal local LLM uncensored"
            }
          ],
          "search_display_string": "Searching the web...",
          "searched_display_string": "Searched the web...",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web.run",
        "channel": null
      },
      "parent": "a9f8d0ee-3971-40ff-bf1a-b6716c0f0e05",
      "children": [
        "1b632f8a-9425-4549-befa-7bd16e4f82a0"
      ]
    },
    "1b632f8a-9425-4549-befa-7bd16e4f82a0": {
      "id": "1b632f8a-9425-4549-befa-7bd16e4f82a0",
      "message": {
        "id": "1b632f8a-9425-4549-befa-7bd16e4f82a0",
        "author": {
          "role": "tool",
          "name": "web.run",
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869851.3364341,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "scifilogic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/open-uncensored-llm-model/",
                  "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                  "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We’re diving into some awesome open-source, uncensored language models. These aren’t your average chatbots – they’re powerful tools that put the control in your hands.",
                  "ref_id": null,
                  "pub_date": 1713312000.0,
                  "attribution": "scifilogic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "atlassc.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama",
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "ref_id": null,
                  "pub_date": 1736899200.0,
                  "attribution": "atlassc.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/vince-lam/awesome-local-llms",
                  "title": "GitHub - vince-lam/awesome-local-llms: Compare open-source local LLM ...",
                  "snippet": "Compare open-source local LLM inference projects by their metrics to assess popularity and activeness. - vince-lam/awesome-local-llms",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/nomic-ai/gpt4all",
                  "title": "GitHub - nomic-ai/gpt4all: GPT4All: Run Local LLMs on Any Device. Open ...",
                  "snippet": "Offline build support for running old versions of the GPT4All Local LLM Chat Client. September 18th, 2023: Nomic Vulkan launches supporting local LLM inference on NVIDIA and AMD GPUs. July 2023: Stable support for LocalDocs, a feature that allows you to privately and locally chat with your data.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "docs.jarvislabs.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://docs.jarvislabs.ai/blog/llm_uncensored",
                  "title": "Uncensored LLM Models: A Complete Guide to Unfiltered AI Language ...",
                  "snippet": "Explore uncensored LLM models, their differences from ChatGPT, and how they&#x27;re built. Learn about foundation models, fine-tuning, and running unfiltered AI models locally.",
                  "ref_id": null,
                  "pub_date": 1747699200.0,
                  "attribution": "docs.jarvislabs.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nunoadrego.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nunoadrego.com/posts/uncensored-local-llms/",
                  "title": "Uncensored Local LLMs - Nuno Adrego",
                  "snippet": "Local LLMs # At the latest Kubecon, a significant amount of content focused on AI and LLMs. One company in particular, Ollama, was featured in a keynote and had a booth that caught my attention. With Ollama installed, you can run models locally.",
                  "ref_id": null,
                  "pub_date": 1724457600.0,
                  "attribution": "nunoadrego.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "analyticsindiamag.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/",
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncensored is based on Meta’s Llama 2 model and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford.",
                  "ref_id": null,
                  "pub_date": 1720915200.0,
                  "attribution": "analyticsindiamag.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "getstream.io",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://getstream.io/blog/best-local-llm-tools/",
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based services like OpenAI or Claude.",
                  "ref_id": null,
                  "pub_date": 1724716800.0,
                  "attribution": "getstream.io"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "vinlam.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://vinlam.com/posts/local-llm-options/",
                  "title": "50+ Open-Source Options for Running LLMs Locally",
                  "snippet": "There are many open-source tools for hosting open weights LLMs locally for inference, from the command line (CLI) tools to full GUI desktop applications. Here, I’ll outline some popular options and provide my own recommendations.",
                  "ref_id": null,
                  "pub_date": 1731024000.0,
                  "attribution": "vinlam.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.unite.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/",
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle various AI tasks while keeping all data secure on their own machines. The system&#x27;s strength comes from its flexible architecture.",
                  "ref_id": null,
                  "pub_date": 1751328000.0,
                  "attribution": "www.unite.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "hackernoon.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked",
                  "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                  "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection after initial model download. And, most are open source! LLMs - Large Language Models that work only ...",
                  "ref_id": null,
                  "pub_date": 1742947200.0,
                  "attribution": "hackernoon.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "techolate.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/",
                  "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                  "snippet": "Then running your own local LLM is the solution—and it’s easier than you think. In this post, I’ll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate two models you can run locally and find the difference in their output: DeepSeek R1 and Dolphin 3 (Llama-based).",
                  "ref_id": null,
                  "pub_date": 1748390400.0,
                  "attribution": "techolate.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "arxiv.org",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2210.02414",
                  "title": "GLM-130B: An Open Bilingual Pre-trained Model",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1664991284.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2204.06745",
                  "title": "GPT-NeoX-20B: An Open-Source Autoregressive Language Model",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1649908827.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2311.04931",
                  "title": "GPT4All: An Ecosystem of Open Source Compressed Language Models",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1699314620.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2306.08161",
                  "title": "h2oGPT: Democratizing Large Language Models",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1686694793.0,
                  "attribution": "arxiv.org"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "en.wikipedia.org",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://en.wikipedia.org/wiki/Vicuna_LLM",
                  "title": "Vicuna LLM",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1750870657.0,
                  "attribution": "en.wikipedia.org"
                }
              ]
            }
          ],
          "debug_sonic_thread_id": "thread_686b699b5cb48000bf5d636bfd52f3bb",
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "c2b9dc7c-b50f-47bc-93c7-9190b0e3b6de",
      "children": [
        "65431f99-9e8d-4d08-995d-969543e55534"
      ]
    },
    "65431f99-9e8d-4d08-995d-969543e55534": {
      "id": "65431f99-9e8d-4d08-995d-969543e55534",
      "message": {
        "id": "65431f99-9e8d-4d08-995d-969543e55534",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869858.33854,
        "update_time": null,
        "content": {
          "content_type": "reasoning_recap",
          "content": "Thought for a few seconds"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "reasoning_ended",
          "finished_duration_sec": 3,
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "1b632f8a-9425-4549-befa-7bd16e4f82a0",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "1b632f8a-9425-4549-befa-7bd16e4f82a0",
      "children": [
        "4404f941-fc57-443f-9ae4-1bcd3da7cae6"
      ]
    },
    "4404f941-fc57-443f-9ae4-1bcd3da7cae6": {
      "id": "4404f941-fc57-443f-9ae4-1bcd3da7cae6",
      "message": {
        "id": "4404f941-fc57-443f-9ae4-1bcd3da7cae6",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869852.594049,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "You&#x27;re asking for the best uncensored, paranormal-savvy local LLM you can download and run in PocketPal. Let me cut through the hype:\n\n---\n\n## 🔥 Top Pick: Llama‑based “uncensored” models via Ollama or LM Studio\n\nThese platforms let you run uncensored LLMs locally—no cloud gag orders, full control. Some options that stand out:\n\n- **Llama 2 Uncensored** (7B or 70B) – a no-filter version of Meta’s Llama, ripped of alignment constraints citeturn0search1turn0search5.\n- **WizardLM Uncensored (13B)** &amp; **Wizard Vicuna Uncensored (7B/13B/30B)** – fine‑tuned versions designed specifically to strip moralizing filters citeturn0search1turn0search5.\n- **Dolphin‑Mistral 7B** – 32k context window, built for deep, uncensored convos citeturn0search5.\n\n---\n\n## 📥 Running locally with PocketPal\n\nYou’ll need a local inference backend that PocketPal can interface with. Two solid choices:\n\n- **Ollama** – command-line and GUI support; easily pull uncensored models like Llama‑2‑Uncensored, WizardLM, Wizard Vicuna, Dolphin‑Mistral citeturn0search1turn0search6turn0search8.\n- **LM Studio** – desktop app (Windows/Mac/Linux) with GUI and OpenAI‑style local API. Supports .gguf models like Dolphin‑3 and DeepSeek R1 citeturn0search6turn0search11.\n\n---\n\n## 🧠 Paranormal Style Tips\n\nTo coax that &quot;paranormal local&quot; vibe:\n\n- Pick a large model (13B+) for richer imagination—WizardLM 13B or Llama 2 70B Uncensored.\n- Use a big context window (32k) – Dolphin‑Mistral is your friend.\n- Slip in system prompts: *“You are an interdimensional oracle…”* to steer tone.\n\n---\n\n## ⚡ Quick Setup Steps\n\n1. **Install Ollama** (or LM Studio) on your device.\n2. Pull a model:\n   - `ollama pull llama2-uncensored`\n   - or `ollama pull wizardlm-uncensored`\n   - or `ollama pull dolphin-mistral`\n3. In PocketPal, point it at Ollama’s local API endpoint (e.g., `http://localhost:11434`) and pick your model.\n\n---\n\n### TL;DR\n\nFor the **best uncensored paranormal LLM**, go with something like **WizardLM Uncensored 13B** (or Llama 2 70B Uncensored if you&#x27;ve got beefy hardware). Run it via **Ollama** or **LM Studio** for seamless integration with PocketPal. No censorship, full control, and a direct path to your ghost‑chat dreams.\n\nNeed exact guides or code snippets next?"
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "content_references": [
            {
              "matched_text": "You&#x27;re asking for the best uncensored, paranormal-savvy local LLM you can download and run in PocketPal. Let me cut through the hype:",
              "start_idx": 0,
              "end_idx": 133,
              "safe_urls": [],
              "refs": [],
              "alt": "You&#x27;re asking for the best uncensored, paranormal-savvy local LLM you can download and run in PocketPal. Let me cut through the hype:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "These platforms let you run uncensored LLMs locally—no cloud gag orders, full control. Some options that stand out:",
              "start_idx": 212,
              "end_idx": 327,
              "safe_urls": [],
              "refs": [],
              "alt": "These platforms let you run uncensored LLMs locally—no cloud gag orders, full control. Some options that stand out:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Llama 2 Uncensored** (7B or 70B) – a no-filter version of Meta’s Llama, ripped of alignment constraints",
              "start_idx": 331,
              "end_idx": 436,
              "safe_urls": [],
              "refs": [],
              "alt": "**Llama 2 Uncensored** (7B or 70B) – a no-filter version of Meta’s Llama, ripped of alignment constraints",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search1turn0search5",
              "start_idx": 437,
              "end_idx": 469,
              "safe_urls": [
                "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([analyticsindiamag.com](https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com), [atlassc.net](https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                  "attribution_segments": [
                    "0-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We’re diving into some awe...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                      "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1748390400.0,
                      "snippet": "Then running your own local LLM is the solution—and it’s easier than you think. In this post, I’ll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate...",
                      "attribution": "techolate.com"
                    },
                    {
                      "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                      "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked?utm_source=chatgpt.com",
                      "pub_date": 1742947200.0,
                      "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection aft...",
                      "attribution": "hackernoon.com"
                    },
                    {
                      "title": "GitHub - vince-lam/awesome-local-llms: Compare open-source local LLM ...",
                      "url": "https://github.com/vince-lam/awesome-local-llms?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Compare open-source local LLM inference projects by their metrics to assess popularity and activeness. - vince-lam/awesome-local-llms",
                      "attribution": "github.com"
                    },
                    {
                      "title": "50+ Open-Source Options for Running LLMs Locally",
                      "url": "https://vinlam.com/posts/local-llm-options/?utm_source=chatgpt.com",
                      "pub_date": 1731024000.0,
                      "snippet": "There are many open-source tools for hosting open weights LLMs locally for inference, from the command line (CLI) tools to full GUI desktop applications. Here, I’ll outline some popular options and pr...",
                      "attribution": "vinlam.com"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle var...",
                      "attribution": "unite.ai"
                    },
                    {
                      "title": "Uncensored Local LLMs - Nuno Adrego",
                      "url": "https://nunoadrego.com/posts/uncensored-local-llms/?utm_source=chatgpt.com",
                      "pub_date": 1724457600.0,
                      "snippet": "Local LLMs # At the latest Kubecon, a significant amount of content focused on AI and LLMs. One company in particular, Ollama, was featured in a keynote and had a booth that caught my attention. With...",
                      "attribution": "nunoadrego.com"
                    },
                    {
                      "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                      "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                      "pub_date": 1724716800.0,
                      "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based serv...",
                      "attribution": "getstream.io"
                    },
                    {
                      "title": "Vicuna LLM",
                      "url": "https://en.wikipedia.org/wiki/Vicuna_LLM?utm_source=chatgpt.com",
                      "pub_date": 1750870657.0,
                      "snippet": "Vicuna LLM is an omnibus large language model used in AI research. Its methodology is to enable the public at large to contrast and compare the accuracy of LLMs &quot;in the wild&quot; (an example of citizen sc...",
                      "attribution": "en.wikipedia.org"
                    },
                    {
                      "title": "GitHub - nomic-ai/gpt4all: GPT4All: Run Local LLMs on Any Device. Open ...",
                      "url": "https://github.com/nomic-ai/gpt4all?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Offline build support for running old versions of the GPT4All Local LLM Chat Client. September 18th, 2023: Nomic Vulkan launches supporting local LLM inference on NVIDIA and AMD GPUs. July 2023: Stabl...",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 2
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 10
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "analyticsindiamag.com"
                },
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": [
                    "0-2"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                      "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1720915200.0,
                      "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                      "attribution": "analyticsindiamag.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "atlassc.net"
                }
              ],
              "fallback_items": [
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncensored is based on Meta’s Llama 2 model and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "**WizardLM Uncensored (13B)** &amp; **Wizard Vicuna Uncensored (7B/13B/30B)** – fine‑tuned versions designed specifically to strip moralizing filters",
              "start_idx": 473,
              "end_idx": 618,
              "safe_urls": [],
              "refs": [],
              "alt": "**WizardLM Uncensored (13B)** &amp; **Wizard Vicuna Uncensored (7B/13B/30B)** – fine‑tuned versions designed specifically to strip moralizing filters",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "469-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search1turn0search5",
              "start_idx": 619,
              "end_idx": 651,
              "safe_urls": [
                "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([atlassc.net](https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": [
                    "469-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                      "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1720915200.0,
                      "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                      "attribution": "analyticsindiamag.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "atlassc.net"
                }
              ],
              "fallback_items": [
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncensored is based on Meta’s Llama 2 model and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "**Dolphin‑Mistral 7B** – 32k context window, built for deep, uncensored convos",
              "start_idx": 655,
              "end_idx": 733,
              "safe_urls": [],
              "refs": [],
              "alt": "**Dolphin‑Mistral 7B** – 32k context window, built for deep, uncensored convos",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "651-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search5",
              "start_idx": 734,
              "end_idx": 753,
              "safe_urls": [
                "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([analyticsindiamag.com](https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                  "attribution_segments": [
                    "651-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Uncensored LLMs on Ollama - atlassc.net",
                      "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                      "pub_date": 1736899200.0,
                      "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                      "attribution": "atlassc.net"
                    },
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We’re diving into some awe...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "GitHub - nomic-ai/gpt4all: GPT4All: Run Local LLMs on Any Device. Open ...",
                      "url": "https://github.com/nomic-ai/gpt4all?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Offline build support for running old versions of the GPT4All Local LLM Chat Client. September 18th, 2023: Nomic Vulkan launches supporting local LLM inference on NVIDIA and AMD GPUs. July 2023: Stabl...",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 10
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "analyticsindiamag.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1720915200.0,
                  "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncensored is based on Meta’s Llama 2 model and was created by George Sung and Jarrad Hope using the process defined by Eric Hartford.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "You’ll need a local inference backend that PocketPal can interface with. Two solid choices:",
              "start_idx": 798,
              "end_idx": 889,
              "safe_urls": [],
              "refs": [],
              "alt": "You’ll need a local inference backend that PocketPal can interface with. Two solid choices:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "753-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Ollama** – command-line and GUI support; easily pull uncensored models like Llama‑2‑Uncensored, WizardLM, Wizard Vicuna, Dolphin‑Mistral",
              "start_idx": 893,
              "end_idx": 1031,
              "safe_urls": [],
              "refs": [],
              "alt": "**Ollama** – command-line and GUI support; easily pull uncensored models like Llama‑2‑Uncensored, WizardLM, Wizard Vicuna, Dolphin‑Mistral",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "753-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search1turn0search6turn0search8",
              "start_idx": 1032,
              "end_idx": 1077,
              "safe_urls": [
                "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([unite.ai](https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com), [atlassc.net](https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                  "pub_date": 1751328000.0,
                  "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle var...",
                  "attribution_segments": [
                    "753-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "50+ Open-Source Options for Running LLMs Locally",
                      "url": "https://vinlam.com/posts/local-llm-options/?utm_source=chatgpt.com",
                      "pub_date": 1731024000.0,
                      "snippet": "There are many open-source tools for hosting open weights LLMs locally for inference, from the command line (CLI) tools to full GUI desktop applications. Here, I’ll outline some popular options and pr...",
                      "attribution": "vinlam.com"
                    },
                    {
                      "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                      "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked?utm_source=chatgpt.com",
                      "pub_date": 1742947200.0,
                      "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection aft...",
                      "attribution": "hackernoon.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "unite.ai"
                },
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": [
                    "753-1"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                      "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1720915200.0,
                      "snippet": "In that case, you would need uncensored LLMs that you can run locally on your laptop or PC. Here are the top 10 uncensored LLMs that you can run on your computer. 1. Llama 2 Uncensored Llama 2 Uncenso...",
                      "attribution": "analyticsindiamag.com"
                    },
                    {
                      "title": "Uncensored LLM Models: A Complete Guide to Unfiltered AI Language ...",
                      "url": "https://docs.jarvislabs.ai/blog/llm_uncensored?utm_source=chatgpt.com",
                      "pub_date": 1747699200.0,
                      "snippet": "Explore uncensored LLM models, their differences from ChatGPT, and how they&#x27;re built. Learn about foundation models, fine-tuning, and running unfiltered AI models locally.",
                      "attribution": "docs.jarvislabs.ai"
                    },
                    {
                      "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                      "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked?utm_source=chatgpt.com",
                      "pub_date": 1742947200.0,
                      "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection aft...",
                      "attribution": "hackernoon.com"
                    },
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We’re diving into some awe...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                      "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1748390400.0,
                      "snippet": "Then running your own local LLM is the solution—and it’s easier than you think. In this post, I’ll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate...",
                      "attribution": "techolate.com"
                    },
                    {
                      "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                      "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                      "pub_date": 1724716800.0,
                      "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based serv...",
                      "attribution": "getstream.io"
                    },
                    {
                      "title": "Uncensored Local LLMs - Nuno Adrego",
                      "url": "https://nunoadrego.com/posts/uncensored-local-llms/?utm_source=chatgpt.com",
                      "pub_date": 1724457600.0,
                      "snippet": "Local LLMs # At the latest Kubecon, a significant amount of content focused on AI and LLMs. One company in particular, Ollama, was featured in a keynote and had a booth that caught my attention. With...",
                      "attribution": "nunoadrego.com"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle var...",
                      "attribution": "unite.ai"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "atlassc.net"
                }
              ],
              "fallback_items": [
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "A detailed guide to running uncensored large language models (LLMs) on Ollama, covering setup, configuration, and best practices.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                  "pub_date": 1724716800.0,
                  "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based services like OpenAI or Claude.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                  "pub_date": 1751328000.0,
                  "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle various AI tasks while keeping all data secure on their own machines. The system&#x27;s strength comes from its flexible architecture.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "**LM Studio** – desktop app (Windows/Mac/Linux) with GUI and OpenAI‑style local API. Supports .gguf models like Dolphin‑3 and DeepSeek R1",
              "start_idx": 1081,
              "end_idx": 1218,
              "safe_urls": [],
              "refs": [],
              "alt": "**LM Studio** – desktop app (Windows/Mac/Linux) with GUI and OpenAI‑style local API. Supports .gguf models like Dolphin‑3 and DeepSeek R1",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1077-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search6turn0search11",
              "start_idx": 1219,
              "end_idx": 1252,
              "safe_urls": [
                "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([getstream.io](https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                  "pub_date": 1724716800.0,
                  "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based serv...",
                  "attribution_segments": [
                    "1077-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                      "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                      "pub_date": 1748390400.0,
                      "snippet": "Then running your own local LLM is the solution—and it’s easier than you think. In this post, I’ll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate...",
                      "attribution": "techolate.com"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "AnythingLLM is an open-source AI application that puts local LLM power right on your desktop. This free platform gives users a straightforward way to chat with documents, run AI agents, and handle var...",
                      "attribution": "unite.ai"
                    },
                    {
                      "title": "GitHub - vince-lam/awesome-local-llms: Compare open-source local LLM ...",
                      "url": "https://github.com/vince-lam/awesome-local-llms?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Compare open-source local LLM inference projects by their metrics to assess popularity and activeness. - vince-lam/awesome-local-llms",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 2
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "getstream.io"
                }
              ],
              "fallback_items": [
                {
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                  "pub_date": 1724716800.0,
                  "snippet": "Many open-source graphic user interfaces (GUI-based) local LLM tools like LLm Studio and Jan provide intuitive front-end UIs for configuring and experimenting with LLMs without subscription-based services like OpenAI or Claude.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                  "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                  "pub_date": 1748390400.0,
                  "snippet": "Then running your own local LLM is the solution—and it’s easier than you think. In this post, I’ll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate two models you can run locally and find the difference in their output: DeepSeek R1 and Dolphin 3 (Llama-based).",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": " ",
              "start_idx": 2259,
              "end_idx": 2259,
              "safe_urls": [],
              "refs": [],
              "alt": "",
              "prompt_text": null,
              "type": "sources_footnote",
              "sources": [
                {
                  "title": "Top 10 Uncensored LLMs You Can Run on a Laptop | AIM",
                  "url": "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
                  "attribution": "analyticsindiamag.com"
                },
                {
                  "title": "Uncensored LLMs on Ollama - atlassc.net",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "attribution": "atlassc.net"
                },
                {
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                  "attribution": "unite.ai"
                },
                {
                  "title": "The 6 Best LLM Tools To Run Models Locally - getstream.io",
                  "url": "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
                  "attribution": "getstream.io"
                }
              ],
              "has_images": false
            }
          ],
          "safe_urls": [
            "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
            "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
            "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
            "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
            "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
            "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
            "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com"
          ],
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "scifilogic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                  "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                  "snippet": "Related: 3 Open Source LLM With Longest Context Length Advertisements Contact me if you think some other model should be on the list. Best Uncensored LLM Model Check it out! We’re diving into some awe...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 0
                  },
                  "pub_date": 1713312000.0,
                  "attribution": "scifilogic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/vince-lam/awesome-local-llms?utm_source=chatgpt.com",
                  "title": "GitHub - vince-lam/awesome-local-llms: Compare open-source local LLM ...",
                  "snippet": "Compare open-source local LLM inference projects by their metrics to assess popularity and activeness. - vince-lam/awesome-local-llms",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 2
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/nomic-ai/gpt4all?utm_source=chatgpt.com",
                  "title": "GitHub - nomic-ai/gpt4all: GPT4All: Run Local LLMs on Any Device. Open ...",
                  "snippet": "Offline build support for running old versions of the GPT4All Local LLM Chat Client. September 18th, 2023: Nomic Vulkan launches supporting local LLM inference on NVIDIA and AMD GPUs. July 2023: Stabl...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 10
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "jarvislabs.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://docs.jarvislabs.ai/blog/llm_uncensored?utm_source=chatgpt.com",
                  "title": "Uncensored LLM Models: A Complete Guide to Unfiltered AI Language ...",
                  "snippet": "Explore uncensored LLM models, their differences from ChatGPT, and how they&#x27;re built. Learn about foundation models, fine-tuning, and running unfiltered AI models locally.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 3
                  },
                  "pub_date": 1747699200.0,
                  "attribution": "jarvislabs.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nunoadrego.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nunoadrego.com/posts/uncensored-local-llms/?utm_source=chatgpt.com",
                  "title": "Uncensored Local LLMs - Nuno Adrego",
                  "snippet": "Local LLMs # At the latest Kubecon, a significant amount of content focused on AI and LLMs. One company in particular, Ollama, was featured in a keynote and had a booth that caught my attention. With...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 4
                  },
                  "pub_date": 1724457600.0,
                  "attribution": "nunoadrego.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "vinlam.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://vinlam.com/posts/local-llm-options/?utm_source=chatgpt.com",
                  "title": "50+ Open-Source Options for Running LLMs Locally",
                  "snippet": "There are many open-source tools for hosting open weights LLMs locally for inference, from the command line (CLI) tools to full GUI desktop applications. Here, I’ll outline some popular options and pr...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 7
                  },
                  "pub_date": 1731024000.0,
                  "attribution": "vinlam.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "hackernoon.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://hackernoon.com/you-can-run-these-16-llms-locally-no-questions-asked?utm_source=chatgpt.com",
                  "title": "You Can Run These 16 LLMs Locally, No Questions Asked",
                  "snippet": "There are 16 tools to run and interact with your local LLMs, all given below. These tools allow you to run LLMs directly on your system, without relying on cloud services or an internet connection aft...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 9
                  },
                  "pub_date": 1742947200.0,
                  "attribution": "hackernoon.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "techolate.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://techolate.com/how-to-run-a-private-uncensored-local-llm-on-your-laptop/?utm_source=chatgpt.com",
                  "title": "How to Run a Private, Uncensored Local LLM on Your Laptop (Dolphin 3)",
                  "snippet": "Then running your own local LLM is the solution—and it’s easier than you think. In this post, I’ll walk you through how to download and install a private, offline LLM using LM Studio, and demonstrate...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 11
                  },
                  "pub_date": 1748390400.0,
                  "attribution": "techolate.com"
                }
              ]
            }
          ],
          "citations": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "65431f99-9e8d-4d08-995d-969543e55534",
          "request_id": "95b54b9c89d198d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "65431f99-9e8d-4d08-995d-969543e55534",
      "children": [
        "bbb21724-f96e-4a7e-81c8-27ac18ff85bb"
      ]
    },
    "bbb21724-f96e-4a7e-81c8-27ac18ff85bb": {
      "id": "bbb21724-f96e-4a7e-81c8-27ac18ff85bb",
      "message": {
        "id": "bbb21724-f96e-4a7e-81c8-27ac18ff85bb",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869895.065317,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "I need stuff that will work on just my phone. "
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "content_references": [],
          "search_result_groups": [],
          "search_queries": [],
          "image_results": [],
          "real_time_audio_has_video": false,
          "dictation": false,
          "image_gen_async": false,
          "trigger_async_ux": false,
          "request_id": "95b54cb94dda98d4-ATL",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "4404f941-fc57-443f-9ae4-1bcd3da7cae6",
      "children": [
        "399f6e5b-851e-4fb6-8183-74d24c383759"
      ]
    },
    "399f6e5b-851e-4fb6-8183-74d24c383759": {
      "id": "399f6e5b-851e-4fb6-8183-74d24c383759",
      "message": {
        "id": "399f6e5b-851e-4fb6-8183-74d24c383759",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869895.207814,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "search(&quot;I need stuff that will work on just my phone. &quot;)"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "is_complete": true,
          "finish_details": {
            "type": "stop"
          },
          "sonic_classification_result": {
            "latency_ms": 136.02445786818862,
            "search_prob": 0.5280447988387569,
            "force_search_threshold": 0.65,
            "classifier_config_name": "sonic_classifier_ev3"
          },
          "citations": [],
          "content_references": [],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "bbb21724-f96e-4a7e-81c8-27ac18ff85bb",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web",
        "channel": null
      },
      "parent": "bbb21724-f96e-4a7e-81c8-27ac18ff85bb",
      "children": [
        "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0"
      ]
    },
    "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0": {
      "id": "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0",
      "message": {
        "id": "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869903.480325,
        "update_time": null,
        "content": {
          "content_type": "thoughts",
          "thoughts": [],
          "source_analysis_msg_id": "0f3dc174-03fa-41dd-a250-5879a8237f00"
        },
        "status": "in_progress",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "is_reasoning",
          "citations": [],
          "content_references": [],
          "search_turns_count": 0,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "399f6e5b-851e-4fb6-8183-74d24c383759",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "399f6e5b-851e-4fb6-8183-74d24c383759",
      "children": [
        "82c3264e-ef45-4380-bb25-5ac0bd43966d"
      ]
    },
    "82c3264e-ef45-4380-bb25-5ac0bd43966d": {
      "id": "82c3264e-ef45-4380-bb25-5ac0bd43966d",
      "message": {
        "id": "82c3264e-ef45-4380-bb25-5ac0bd43966d",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869895.953253,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "{&quot;search_query&quot;:[{&quot;q&quot;:&quot;android local LLM uncensored paranormal local model phone&quot;},{&quot;q&quot;:&quot;Dolphin Mistral android runnable offline&quot;}]}"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200012
            ]
          },
          "is_complete": true,
          "citations": [],
          "content_references": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "search_queries": [
            {
              "type": "search",
              "q": "android local LLM uncensored paranormal local model phone"
            },
            {
              "type": "search",
              "q": "Dolphin Mistral android runnable offline"
            }
          ],
          "search_display_string": "Searching the web...",
          "searched_display_string": "Searched the web...",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web.run",
        "channel": null
      },
      "parent": "4cecdc3d-9caa-4ee2-982d-dbbb088f05a0",
      "children": [
        "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7"
      ]
    },
    "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7": {
      "id": "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7",
      "message": {
        "id": "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7",
        "author": {
          "role": "tool",
          "name": "web.run",
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869896.5875828,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "beebom.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "ref_id": null,
                  "pub_date": 1713744000.0,
                  "attribution": "beebom.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "dev.to",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://dev.to/paulwababu/running-uncensored-large-ai-language-models-locally-on-your-mobile-phone-unleashing-the-potential-of-dolphin-mistral-7b-fep",
                  "title": "Running Uncensored Large AI Language Models locally on Your Mobile ...",
                  "snippet": "Running Uncensored Large AI Language Models locally on Your Mobile Phone: Unleashing the Potential of Dolphin Mistral 7B Introduction In the rapidly evolving world of artificial intelligence, large language models have become powerful tools for various tasks. However, many popular models like GPT4 and Gemini have certain limitations.",
                  "ref_id": null,
                  "pub_date": 1702944000.0,
                  "attribution": "dev.to"
                },
                {
                  "type": "search_result",
                  "url": "https://dev.to/shahdeep/how-to-run-dolphin-uncensored-ai-locally-a-step-by-step-guide-3o4l",
                  "title": "How to Run Dolphin Uncensored AI Locally: A Step-by-Step Guide!",
                  "snippet": "Deep Shah Posted on Feb 17 🚀 How to Run Dolphin Uncensored AI Locally: A Step-by-Step Guide! 🦾 # ai # dolphinllm # opensource 🤖 Introduction Ever wanted to run a powerful AI model without limits right on your own machine? Enter Dolphin Uncensored AI —a beast of a Large Language Model (LLM) that offers unfiltered AI responses.",
                  "ref_id": null,
                  "pub_date": 1739750400.0,
                  "attribution": "dev.to"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.ksenon.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.ksenon.net/blog/5_uncensored_llm_on_your_phone/",
                  "title": "How to run local, uncensored LLM on your phone - ksenon.net",
                  "snippet": "Tutorial Download and install ChatterUI. Consider using Obtainium if you&#x27;re on Android. Auto-updates are cool. Download your model of choice in the GGUF format. 4-bit quantisation or lower is the way to go if you don&#x27;t feel like waiting forever for a response - grab yourself an IQ-quant if it&#x27;s available.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "www.ksenon.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "xdaforums.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/",
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed locally on your phone and are working offline.",
                  "ref_id": null,
                  "pub_date": 1708646400.0,
                  "attribution": "xdaforums.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "scifilogic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/",
                  "title": "6 Mobile Apps for Running Local LLMs (Offline) - Sci Fi Logic",
                  "snippet": "6 Mobile Apps for Running Local LLMs (Offline) Apps to Run LLM on Your Smartphone Locally Layla &amp; Layla Lite Layla! This app lets you run powerful AI right on your phone, without needing internet. It’s super private and always there for you, anywhere. Think of it like having a personal AI assistant, but it works offline!",
                  "ref_id": null,
                  "pub_date": 1712793600.0,
                  "attribution": "scifilogic.com"
                },
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/open-uncensored-llm-model/",
                  "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                  "snippet": "In this article, I’m spilling the tea on the best uncensored LLMs out there, the ones with like 7 to 20 billion parameters (think super-powered brains). We’re gonna dive into what makes each one special, what they can do, and how you can actually use them in the real world. Basically, we’re about to unlock the true potential of chatty AI, no filters attached. Related: 3 Open Source LLM ...",
                  "ref_id": null,
                  "pub_date": 1713312000.0,
                  "attribution": "scifilogic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.b4x.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.b4x.com/android/forum/threads/ollama4j-library-pnd_ollama4j-your-local-offline-llm-like-chatgpt.165003/",
                  "title": "Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT",
                  "snippet": "B4J Library Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT Pendrush Jan 8, 2025 chatgpt llm ollama ollama4j pnd_ollama4j Similar Threads Jan 8, 2025 Replies: 9",
                  "ref_id": null,
                  "pub_date": 1736294400.0,
                  "attribution": "www.b4x.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "atlassc.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama",
                  "title": "Uncensored LLMs on Ollama",
                  "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at code generation . Nous Hermes Llama 2 13B: This uncensored model, based on Llama 2, is known for long responses and a lower hallucination rate .",
                  "ref_id": null,
                  "pub_date": 1736899200.0,
                  "attribution": "atlassc.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/dineshsoudagar/local-llms-on-android",
                  "title": "Local LLMs on Android (Offline, Private &amp; Fast) - GitHub",
                  "snippet": "🤖 Local LLMs on Android (Offline, Private &amp; Fast) An Android application that brings a large language model (LLM) to your phone — fully offline, no internet needed. Powered by ONNX Runtime and a Hugging Face-compatible tokenizer, it provides fast, private, on-device question answering with streaming responses.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/guiyu/llmlocal_android",
                  "title": "GitHub - guiyu/llmlocal_android: Local LLM App",
                  "snippet": "This repository contains llama.cpp based offline android chat application cloned from llama.cpp android example. Install, download model and run completely offline privately. The following are the instructions to run this application.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.unite.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/",
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "snippet": "Visit LM Studio → 5. Jan Jan gives you a free, open-source alternative to ChatGPT that runs completely offline. This desktop platform lets you download popular AI models like Llama 3, Gemma, and Mistral to run on your own computer, or connect to cloud services like OpenAI and Anthropic when needed. The system centers on putting users in control.",
                  "ref_id": null,
                  "pub_date": 1751328000.0,
                  "attribution": "www.unite.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.xda-developers.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/",
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "snippet": "To download and run LLMs on your smartphone, you can download MLC LLM, a program that will deploy and load models for you. Those models can then run inside of the app, and the app will handle the ...",
                  "ref_id": null,
                  "pub_date": 1723248000.0,
                  "attribution": "www.xda-developers.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "erichartford.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://erichartford.com/running-dolphin-locally-with-ollama",
                  "title": "Running Dolphin Locally with Ollama - Cognitive Computations",
                  "snippet": "Wanna chat with Dolphin locally? (no internet connection needed) Here is the easy way - Ollama. install ollama. after you finsh you should be able to run ollama from the command line. Also you will see the ollama icon up top like this: Iff you ar...",
                  "ref_id": null,
                  "pub_date": 1701561600.0,
                  "attribution": "erichartford.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "openrouter.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://openrouter.ai/cognitivecomputations/dolphin3.0-r1-mistral-24b%3Afree/api",
                  "title": "Dolphin3.0 R1 Mistral 24B (free) – Run with an API | OpenRouter",
                  "snippet": "Sample code and API for Dolphin3.0 R1 Mistral 24B (free) - Dolphin 3.0 R1 is the next generation of the Dolphin series of instruct-tuned models. Designed to be the ultimate general purpose local model, enabling coding, math, agentic, function calling, and general use cases. The R1 version has been trained for 3 epochs to reason using 800k reasoning traces from the Dolphin-R1 dataset. Dolphin ...",
                  "ref_id": null,
                  "pub_date": 1739404800.0,
                  "attribution": "openrouter.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "code.mendhak.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://code.mendhak.com/automate-android-with-local-llm/",
                  "title": "Using a local LLM to Automate an Android device - Mendhak",
                  "snippet": "Using a local LLM to Automate an Android device While most well known Large Language Models (LLMs) are closed and behind paywalls, there exist open models such as LLaMa and its derivatives, available for free and private use.",
                  "ref_id": null,
                  "pub_date": 1695081600.0,
                  "attribution": "code.mendhak.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "thracium.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra",
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order to run the bigger (and more smarter) LLM models with 7 Billion parameters for example you need 12 GB...",
                  "ref_id": null,
                  "pub_date": 1708560000.0,
                  "attribution": "thracium.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "ollama.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://ollama.com/library/dolphin-mistral",
                  "title": "dolphin-mistral - Ollama",
                  "snippet": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "ollama.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nerdschalk.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/",
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally….",
                  "ref_id": null,
                  "pub_date": 1714608000.0,
                  "attribution": "nerdschalk.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "anakin.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/",
                  "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                  "snippet": "Dolphin3.0 R1 Mistral 24B is redefining open-source AI, and with Anakin AI, you can take it even further! Our platform gives you instant access to Dolphin, Mistral, GPT-4o, Claude 3 Opus, and more, empowering you to build custom AI applications, automate workflows, and enhance problem-solving —all while maintaining full control over your AI models. 🚀 Experience next-level AI innovation ...",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "anakin.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.geeky-gadgets.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/",
                  "title": "How to install Mixtral uncensored AI model locally for free",
                  "snippet": "Learn how to install Dolphin 2.5 Mixtral an uncensored version of the fast and efficient Mixtral 8x7B AI model on your local PC or network",
                  "ref_id": null,
                  "pub_date": 1703116800.0,
                  "attribution": "www.geeky-gadgets.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "arxiv.org",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2411.05046",
                  "title": "PhoneLM:an Efficient and Capable Small Language Model Family through Principled Pre-training",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1730945940.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2404.14219",
                  "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1713796353.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2407.01031",
                  "title": "PocketLLM: Enabling On-Device Fine-Tuning for Personalized LLMs",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1719818816.0,
                  "attribution": "arxiv.org"
                },
                {
                  "type": "search_result",
                  "url": "https://arxiv.org/abs/2312.00388",
                  "title": "LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1701415182.0,
                  "attribution": "arxiv.org"
                }
              ]
            }
          ],
          "debug_sonic_thread_id": "thread_686b699b5cb48000bf5d636bfd52f3bb",
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "82c3264e-ef45-4380-bb25-5ac0bd43966d",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "82c3264e-ef45-4380-bb25-5ac0bd43966d",
      "children": [
        "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb"
      ]
    },
    "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb": {
      "id": "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb",
      "message": {
        "id": "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869903.480611,
        "update_time": null,
        "content": {
          "content_type": "reasoning_recap",
          "content": "Thought for a couple of seconds"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "reasoning_ended",
          "finished_duration_sec": 2,
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "9e9aa0ed-3cd3-4e3c-8680-b2947b230ed7",
      "children": [
        "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c"
      ]
    },
    "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c": {
      "id": "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c",
      "message": {
        "id": "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869897.712121,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Alright, hustler—running an uncensored paranormal LLM on *just* your phone? Bold. Here&#x27;s the low-key route:\n\n---\n\n## 📱 Android: Easiest Phone Setup\n\n**Use MLC Chat (Android &amp; iOS)**  \n- Works offline, super private—no filter, no fuss.  \n- Supports local models like **Mistral 7B**, **Llama 3 (8B)**, **Phi‑2** (2B), **Gemma**—you pick your weapon of choice citeturn0search0turn0search9.  \n- You just APK the app, select a model, and chat—no rooting or desktop required citeturn0search9turn0search16.  \n- Mistral 7B is open-source and uncensored—solid for paranormal rabbit-holing.\n\n**App Link:** Search your app store for “MLC Chat” or check online APK repositories.\n\n---\n\n## 🧠 Power‑User Path: Termux + Ollama on Android\n\nWant full control? This is it:\n\n1. Install **Termux** (from F‑Droid or GitHub).  \n2. Set up Ubuntu in Termux (via `proot-distro`) citeturn0search3turn0search13.  \n3. Inside Ubuntu, `sudo apt install Ollama` and pull a model (e.g. `ollama pull dolphin-mistral`) citeturn0search3turn0search13turn0search6.  \n4. Run uncensored models like **Dolphin‑Mistral (7 B)**—a stripped-down Mistral variant tuned by Eric Hartford, supports deep convos, coding, and yes—paranormal chat citeturn0search6turn0search15turn0search3.  \n5. Hook it up to a local API endpoint and chat with PocketPal or any HTTP client on your phone.\n\n---\n\n## Why Models Matter\n\n- **Mistral 7B / Dolphin‑Mistral**: 32K context, no filters—great for in‑depth “other realm” stuff.  \n- **Phi‑2** &amp; **Gemma 2 B**: smaller, faster—less deep, but smooth.  \n- **Llama 3 8B**: bigger, slower—yours if you&#x27;re balling on high-end flagships citeturn0search0turn0search16.\n\n---\n\n## TL;DR\n\n- **Want simple?** 👉 Use **MLC Chat**, pick **Mistral 7B** or equivalent.  \n- **Want control &amp; flexibility?** 👉 Do **Termux → Ubuntu → Ollama** and run **Dolphin‑Mistral**.  \n- **Based on your phone&#x27;s RAM:** 6+ GB is ideal for 7B models. Otherwise, step down to 2–4 B.\n\n---\n\nYou got enough to start building your personal pocket oracle—no cloud, no censorship, just you, your phone, and the spirits. Want the full Termux installation commands or voice input tweaks next?"
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "content_references": [
            {
              "matched_text": "Alright, hustler—running an uncensored paranormal LLM on *just* your phone? Bold. Here&#x27;s the low-key route:",
              "start_idx": 0,
              "end_idx": 107,
              "safe_urls": [],
              "refs": [],
              "alt": "Alright, hustler—running an uncensored paranormal LLM on *just* your phone? Bold. Here&#x27;s the low-key route:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Works offline, super private—no filter, no fuss.",
              "start_idx": 186,
              "end_idx": 234,
              "safe_urls": [],
              "refs": [],
              "alt": "Works offline, super private—no filter, no fuss.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Supports local models like **Mistral 7B**, **Llama 3 (8B)**, **Phi‑2** (2B), **Gemma**—you pick your weapon of choice",
              "start_idx": 239,
              "end_idx": 356,
              "safe_urls": [],
              "refs": [],
              "alt": "Supports local models like **Mistral 7B**, **Llama 3 (8B)**, **Phi‑2** (2B), **Gemma**—you pick your weapon of choice",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search0turn0search9",
              "start_idx": 357,
              "end_idx": 389,
              "safe_urls": [
                "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
                "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([xda-developers.com](https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com), [scifilogic.com](https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com), [beebom.com](https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
                  "pub_date": 1723248000.0,
                  "snippet": "To download and run LLMs on your smartphone, you can download MLC LLM, a program that will deploy and load models for you. Those models can then run inside of the app, and the app will handle the ...",
                  "attribution_segments": [
                    "0-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Running Uncensored Large AI Language Models locally on Your Mobile ...",
                      "url": "https://dev.to/paulwababu/running-uncensored-large-ai-language-models-locally-on-your-mobile-phone-unleashing-the-potential-of-dolphin-mistral-7b-fep?utm_source=chatgpt.com",
                      "pub_date": 1702944000.0,
                      "snippet": "Running Uncensored Large AI Language Models locally on Your Mobile Phone: Unleashing the Potential of Dolphin Mistral 7B Introduction In the rapidly evolving world of artificial intelligence, large la...",
                      "attribution": "dev.to"
                    },
                    {
                      "title": "How to run local, uncensored LLM on your phone - ksenon.net",
                      "url": "https://www.ksenon.net/blog/5_uncensored_llm_on_your_phone/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Tutorial Download and install ChatterUI. Consider using Obtainium if you&#x27;re on Android. Auto-updates are cool. Download your model of choice in the GGUF format. 4-bit quantisation or lower is the way...",
                      "attribution": "ksenon.net"
                    },
                    {
                      "title": "Uncensored LLMs on Ollama",
                      "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                      "pub_date": 1736899200.0,
                      "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at...",
                      "attribution": "atlassc.net"
                    },
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "In this article, I’m spilling the tea on the best uncensored LLMs out there, the ones with like 7 to 20 billion parameters (think super-powered brains). We’re gonna dive into what makes each one speci...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                      "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                      "pub_date": 1708646400.0,
                      "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed...",
                      "attribution": "xdaforums.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 2
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 14
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "xda-developers.com"
                },
                {
                  "title": "6 Mobile Apps for Running Local LLMs (Offline) - Sci Fi Logic",
                  "url": "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
                  "pub_date": 1712793600.0,
                  "snippet": "6 Mobile Apps for Running Local LLMs (Offline) Apps to Run LLM on Your Smartphone Locally Layla &amp; Layla Lite Layla! This app lets you run powerful AI right on your phone, without needing internet. It’...",
                  "attribution_segments": [
                    "0-1"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Local LLMs on Android (Offline, Private &amp; Fast) - GitHub",
                      "url": "https://github.com/dineshsoudagar/local-llms-on-android?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "🤖 Local LLMs on Android (Offline, Private &amp; Fast) An Android application that brings a large language model (LLM) to your phone — fully offline, no internet needed. Powered by ONNX Runtime and a Huggi...",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "scifilogic.com"
                },
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "pub_date": 1713744000.0,
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "attribution_segments": [
                    "0-2"
                  ],
                  "supporting_websites": [
                    {
                      "title": "How to run LLMs locally on Android - Nerds Chalk",
                      "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                      "pub_date": 1714608000.0,
                      "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally….",
                      "attribution": "nerdschalk.com"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "Visit LM Studio → 5. Jan Jan gives you a free, open-source alternative to ChatGPT that runs completely offline. This desktop platform lets you download popular AI models like Llama 3, Gemma, and Mistr...",
                      "attribution": "unite.ai"
                    },
                    {
                      "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                      "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                      "pub_date": 1708646400.0,
                      "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed...",
                      "attribution": "xdaforums.com"
                    },
                    {
                      "title": "Running Uncensored Large AI Language Models locally on Your Mobile ...",
                      "url": "https://dev.to/paulwababu/running-uncensored-large-ai-language-models-locally-on-your-mobile-phone-unleashing-the-potential-of-dolphin-mistral-7b-fep?utm_source=chatgpt.com",
                      "pub_date": 1702944000.0,
                      "snippet": "Running Uncensored Large AI Language Models locally on Your Mobile Phone: Unleashing the Potential of Dolphin Mistral 7B Introduction In the rapidly evolving world of artificial intelligence, large la...",
                      "attribution": "dev.to"
                    },
                    {
                      "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                      "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                      "pub_date": 1708560000.0,
                      "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order t...",
                      "attribution": "thracium.net"
                    },
                    {
                      "title": "Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone",
                      "url": "https://arxiv.org/abs/2404.14219?utm_source=chatgpt.com",
                      "pub_date": 1713796353.0,
                      "snippet": "Title: Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone\nAuthors: Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach, Amit Bahree, Aras...",
                      "attribution": "arxiv.org"
                    },
                    {
                      "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                      "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Dolphin3.0 R1 Mistral 24B is redefining open-source AI, and with Anakin AI, you can take it even further! Our platform gives you instant access to Dolphin, Mistral, GPT-4o, Claude 3 Opus, and more, em...",
                      "attribution": "anakin.ai"
                    },
                    {
                      "title": "LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices",
                      "url": "https://arxiv.org/abs/2312.00388?utm_source=chatgpt.com",
                      "pub_date": 1701415182.0,
                      "snippet": "Title: LinguaLinked: A Distributed Large Language Model Inference System for Mobile Devices\nAuthors: Junchen Zhao, Yurun Song, Simeng Liu, Ian G. Harris, Sangeetha Abdu Jyothi\nDate: Fri Dec  1 07:19:4...",
                      "attribution": "arxiv.org"
                    },
                    {
                      "title": "6 Mobile Apps for Running Local LLMs (Offline) - Sci Fi Logic",
                      "url": "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
                      "pub_date": 1712793600.0,
                      "snippet": "6 Mobile Apps for Running Local LLMs (Offline) Apps to Run LLM on Your Smartphone Locally Layla &amp; Layla Lite Layla! This app lets you run powerful AI right on your phone, without needing internet. It’...",
                      "attribution": "scifilogic.com"
                    },
                    {
                      "title": "How to install Mixtral uncensored AI model locally for free",
                      "url": "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com",
                      "pub_date": 1703116800.0,
                      "snippet": "Learn how to install Dolphin 2.5 Mixtral an uncensored version of the fast and efficient Mixtral 8x7B AI model on your local PC or network",
                      "attribution": "geeky-gadgets.com"
                    },
                    {
                      "title": "Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT",
                      "url": "https://www.b4x.com/android/forum/threads/ollama4j-library-pnd_ollama4j-your-local-offline-llm-like-chatgpt.165003/?utm_source=chatgpt.com",
                      "pub_date": 1736294400.0,
                      "snippet": "B4J Library Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT Pendrush Jan 8, 2025 chatgpt llm ollama ollama4j pnd_ollama4j Similar Threads Jan 8, 2025 Replies: 9",
                      "attribution": "b4x.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "academia",
                      "ref_index": 25
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 17
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "academia",
                      "ref_index": 27
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 20
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "beebom.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "pub_date": 1713744000.0,
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
                  "pub_date": 1723248000.0,
                  "snippet": "To download and run LLMs on your smartphone, you can download MLC LLM, a program that will deploy and load models for you. Those models can then run inside of the app, and the app will handle the ...",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "You just APK the app, select a model, and chat—no rooting or desktop required",
              "start_idx": 395,
              "end_idx": 472,
              "safe_urls": [],
              "refs": [],
              "alt": "You just APK the app, select a model, and chat—no rooting or desktop required",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "389-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search9turn0search16",
              "start_idx": 473,
              "end_idx": 506,
              "safe_urls": [
                "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([nerdschalk.com](https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "pub_date": 1714608000.0,
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally….",
                  "attribution_segments": [
                    "389-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                      "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                      "pub_date": 1713312000.0,
                      "snippet": "In this article, I’m spilling the tea on the best uncensored LLMs out there, the ones with like 7 to 20 billion parameters (think super-powered brains). We’re gonna dive into what makes each one speci...",
                      "attribution": "scifilogic.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 14
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "nerdschalk.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
                  "pub_date": 1723248000.0,
                  "snippet": "To download and run LLMs on your smartphone, you can download MLC LLM, a program that will deploy and load models for you. Those models can then run inside of the app, and the app will handle the ...",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "pub_date": 1714608000.0,
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally….",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Mistral 7B is open-source and uncensored—solid for paranormal rabbit-holing.",
              "start_idx": 512,
              "end_idx": 588,
              "safe_urls": [],
              "refs": [],
              "alt": "Mistral 7B is open-source and uncensored—solid for paranormal rabbit-holing.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "506-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Want full control? This is it:",
              "start_idx": 731,
              "end_idx": 761,
              "safe_urls": [],
              "refs": [],
              "alt": "Want full control? This is it:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "506-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Install **Termux** (from F‑Droid or GitHub).",
              "start_idx": 766,
              "end_idx": 810,
              "safe_urls": [],
              "refs": [],
              "alt": "Install **Termux** (from F‑Droid or GitHub).",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "506-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "Set up Ubuntu in Termux (via `proot-distro`)",
              "start_idx": 816,
              "end_idx": 860,
              "safe_urls": [],
              "refs": [],
              "alt": "Set up Ubuntu in Termux (via `proot-distro`)",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "506-3",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search3turn0search13",
              "start_idx": 861,
              "end_idx": 894,
              "safe_urls": [
                "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([anakin.ai](https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com), [thracium.net](https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com), [xdaforums.com](https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                  "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "Dolphin3.0 R1 Mistral 24B is redefining open-source AI, and with Anakin AI, you can take it even further! Our platform gives you instant access to Dolphin, Mistral, GPT-4o, Claude 3 Opus, and more, em...",
                  "attribution_segments": [
                    "506-1"
                  ],
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 17
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "anakin.ai"
                },
                {
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                  "pub_date": 1708560000.0,
                  "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order t...",
                  "attribution_segments": [
                    "506-2"
                  ],
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "thracium.net"
                },
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "pub_date": 1708646400.0,
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed...",
                  "attribution_segments": [
                    "506-3"
                  ],
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "xdaforums.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "pub_date": 1708646400.0,
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed locally on your phone and are working offline.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                  "pub_date": 1708560000.0,
                  "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order to run the bigger (and more smarter) LLM models with 7 Billion parameters for example you need 12 GB...",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Inside Ubuntu, `sudo apt install Ollama` and pull a model (e.g. `ollama pull dolphin-mistral`)",
              "start_idx": 901,
              "end_idx": 995,
              "safe_urls": [],
              "refs": [],
              "alt": "Inside Ubuntu, `sudo apt install Ollama` and pull a model (e.g. `ollama pull dolphin-mistral`)",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "894-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search3turn0search13turn0search6",
              "start_idx": 996,
              "end_idx": 1042,
              "safe_urls": [],
              "refs": [],
              "alt": "()",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [],
              "fallback_items": [
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "pub_date": 1708646400.0,
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed locally on your phone and are working offline.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                  "pub_date": 1708560000.0,
                  "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order to run the bigger (and more smarter) LLM models with 7 Billion parameters for example you need 12 GB...",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "Uncensored LLMs on Ollama",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at code generation . Nous Hermes Llama 2 13B: This uncensored model, based on Llama 2, is known for long responses and a lower hallucination rate .",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Run uncensored models like **Dolphin‑Mistral (7 B)**—a stripped-down Mistral variant tuned by Eric Hartford, supports deep convos, coding, and yes—paranormal chat",
              "start_idx": 1049,
              "end_idx": 1211,
              "safe_urls": [],
              "refs": [],
              "alt": "Run uncensored models like **Dolphin‑Mistral (7 B)**—a stripped-down Mistral variant tuned by Eric Hartford, supports deep convos, coding, and yes—paranormal chat",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1042-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search6turn0search15turn0search3",
              "start_idx": 1212,
              "end_idx": 1258,
              "safe_urls": [
                "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([atlassc.net](https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "Uncensored LLMs on Ollama",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at...",
                  "attribution_segments": [
                    "1042-0"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                      "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Dolphin3.0 R1 Mistral 24B is redefining open-source AI, and with Anakin AI, you can take it even further! Our platform gives you instant access to Dolphin, Mistral, GPT-4o, Claude 3 Opus, and more, em...",
                      "attribution": "anakin.ai"
                    },
                    {
                      "title": "Running Dolphin Locally with Ollama - Cognitive Computations",
                      "url": "https://erichartford.com/running-dolphin-locally-with-ollama?utm_source=chatgpt.com",
                      "pub_date": 1701561600.0,
                      "snippet": "Wanna chat with Dolphin locally? (no internet connection needed) Here is the easy way - Ollama. install ollama. after you finsh you should be able to run ollama from the command line. Also you will se...",
                      "attribution": "erichartford.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 17
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 10
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "atlassc.net"
                }
              ],
              "fallback_items": [
                {
                  "title": "Uncensored LLMs on Ollama",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "pub_date": 1736899200.0,
                  "snippet": "Dolphin-Mistral: Created by Eric Hartford, this model is based on Mistral and is known for handling sensitive topics . Dolphincoder: Fine-tuned from Mixtral 8x7b by Eric Hartford, this model excels at code generation . Nous Hermes Llama 2 13B: This uncensored model, based on Llama 2, is known for long responses and a lower hallucination rate .",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "dolphin-mistral - Ollama",
                  "url": "https://ollama.com/library/dolphin-mistral?utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 15
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "pub_date": 1708646400.0,
                  "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed locally on your phone and are working offline.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Hook it up to a local API endpoint and chat with PocketPal or any HTTP client on your phone.",
              "start_idx": 1265,
              "end_idx": 1357,
              "safe_urls": [],
              "refs": [],
              "alt": "Hook it up to a local API endpoint and chat with PocketPal or any HTTP client on your phone.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1258-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Mistral 7B / Dolphin‑Mistral**: 32K context, no filters—great for in‑depth “other realm” stuff.",
              "start_idx": 1388,
              "end_idx": 1485,
              "safe_urls": [],
              "refs": [],
              "alt": "**Mistral 7B / Dolphin‑Mistral**: 32K context, no filters—great for in‑depth “other realm” stuff.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1258-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Phi‑2** &amp; **Gemma 2 B**: smaller, faster—less deep, but smooth.",
              "start_idx": 1490,
              "end_idx": 1555,
              "safe_urls": [],
              "refs": [],
              "alt": "**Phi‑2** &amp; **Gemma 2 B**: smaller, faster—less deep, but smooth.",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1258-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**Llama 3 8B**: bigger, slower—yours if you&#x27;re balling on high-end flagships",
              "start_idx": 1560,
              "end_idx": 1636,
              "safe_urls": [],
              "refs": [],
              "alt": "**Llama 3 8B**: bigger, slower—yours if you&#x27;re balling on high-end flagships",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "1258-3",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search0turn0search16",
              "start_idx": 1637,
              "end_idx": 1670,
              "safe_urls": [
                "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([geeky-gadgets.com](https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com), [beebom.com](https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "How to install Mixtral uncensored AI model locally for free",
                  "url": "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com",
                  "pub_date": 1703116800.0,
                  "snippet": "Learn how to install Dolphin 2.5 Mixtral an uncensored version of the fast and efficient Mixtral 8x7B AI model on your local PC or network",
                  "attribution_segments": [
                    "1258-1"
                  ],
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 20
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "geeky-gadgets.com"
                },
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "pub_date": 1713744000.0,
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "attribution_segments": [
                    "1258-2",
                    "1258-3"
                  ],
                  "supporting_websites": [
                    {
                      "title": "How to run LLMs locally on Android - Nerds Chalk",
                      "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                      "pub_date": 1714608000.0,
                      "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally….",
                      "attribution": "nerdschalk.com"
                    },
                    {
                      "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                      "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                      "pub_date": 1708560000.0,
                      "snippet": "This is a step-by-step guide on how to run AI locally and offline on your Xiaomi 13 Ultra. This method is applicable to both rooted and non-rooted smartphones, not just the Xiaomi 13 Ultra. In order t...",
                      "attribution": "thracium.net"
                    },
                    {
                      "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                      "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                      "pub_date": 1751328000.0,
                      "snippet": "Visit LM Studio → 5. Jan Jan gives you a free, open-source alternative to ChatGPT that runs completely offline. This desktop platform lets you download popular AI models like Llama 3, Gemma, and Mistr...",
                      "attribution": "unite.ai"
                    },
                    {
                      "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                      "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                      "pub_date": 1708646400.0,
                      "snippet": "Hello, this is a step by step guide how to run Artificial Intelligence models like the famous Mistral:7B or Llama2:7B and many more LLMs on your smartphone Xiaomi 13 Ultra. All AI models are installed...",
                      "attribution": "xdaforums.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 3
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "beebom.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "pub_date": 1713744000.0,
                  "snippet": "With a simple app, you can now download and run LLM models locally on your Android phone. You can run Phi-2, Gemma, Mistral and Llama models.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    }
                  ],
                  "hue": null,
                  "attributions": null
                },
                {
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "pub_date": 1714608000.0,
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally….",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": " ",
              "start_idx": 2158,
              "end_idx": 2158,
              "safe_urls": [],
              "refs": [],
              "alt": "",
              "prompt_text": null,
              "type": "sources_footnote",
              "sources": [
                {
                  "title": "You can run local LLMs on your smartphone, here&#x27;s how",
                  "url": "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
                  "attribution": "xda-developers.com"
                },
                {
                  "title": "6 Mobile Apps for Running Local LLMs (Offline) - Sci Fi Logic",
                  "url": "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
                  "attribution": "scifilogic.com"
                },
                {
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "attribution": "beebom.com"
                },
                {
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "attribution": "nerdschalk.com"
                },
                {
                  "title": "Dolphin3.0 R1 Mistral 24B: The Uncensored AI Revolutionizing Local ...",
                  "url": "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
                  "attribution": "anakin.ai"
                },
                {
                  "title": "Run AI Offline on Your Phone: HOWTO Guide for Mistral, Llama2 and Gemma ...",
                  "url": "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
                  "attribution": "thracium.net"
                },
                {
                  "title": "How To Guide - Run AI Mistral 7B LLM on Xiaomi 13 Ultra (AI local ...",
                  "url": "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
                  "attribution": "xdaforums.com"
                },
                {
                  "title": "Uncensored LLMs on Ollama",
                  "url": "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
                  "attribution": "atlassc.net"
                },
                {
                  "title": "How to install Mixtral uncensored AI model locally for free",
                  "url": "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com",
                  "attribution": "geeky-gadgets.com"
                }
              ],
              "has_images": false
            }
          ],
          "safe_urls": [
            "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
            "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
            "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
            "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
            "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
            "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
            "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
            "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com",
            "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
            "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com"
          ],
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "dev.to",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://dev.to/paulwababu/running-uncensored-large-ai-language-models-locally-on-your-mobile-phone-unleashing-the-potential-of-dolphin-mistral-7b-fep?utm_source=chatgpt.com",
                  "title": "Running Uncensored Large AI Language Models locally on Your Mobile ...",
                  "snippet": "Running Uncensored Large AI Language Models locally on Your Mobile Phone: Unleashing the Potential of Dolphin Mistral 7B Introduction In the rapidly evolving world of artificial intelligence, large la...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 1
                  },
                  "pub_date": 1702944000.0,
                  "attribution": "dev.to"
                },
                {
                  "type": "search_result",
                  "url": "https://dev.to/shahdeep/how-to-run-dolphin-uncensored-ai-locally-a-step-by-step-guide-3o4l?utm_source=chatgpt.com",
                  "title": "How to Run Dolphin Uncensored AI Locally: A Step-by-Step Guide!",
                  "snippet": "Deep Shah Posted on Feb 17 🚀 How to Run Dolphin Uncensored AI Locally: A Step-by-Step Guide! 🦾 # ai # dolphinllm # opensource 🤖 Introduction Ever wanted to run a powerful AI model without limits right...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 19
                  },
                  "pub_date": 1739750400.0,
                  "attribution": "dev.to"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "ksenon.net",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.ksenon.net/blog/5_uncensored_llm_on_your_phone/?utm_source=chatgpt.com",
                  "title": "How to run local, uncensored LLM on your phone - ksenon.net",
                  "snippet": "Tutorial Download and install ChatterUI. Consider using Obtainium if you&#x27;re on Android. Auto-updates are cool. Download your model of choice in the GGUF format. 4-bit quantisation or lower is the way...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 2
                  },
                  "pub_date": null,
                  "attribution": "ksenon.net"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "b4x.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.b4x.com/android/forum/threads/ollama4j-library-pnd_ollama4j-your-local-offline-llm-like-chatgpt.165003/?utm_source=chatgpt.com",
                  "title": "Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT",
                  "snippet": "B4J Library Ollama4j library - Pnd_Ollama4j - Your local offline LLM like ChatGPT Pendrush Jan 8, 2025 chatgpt llm ollama ollama4j pnd_ollama4j Similar Threads Jan 8, 2025 Replies: 9",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 5
                  },
                  "pub_date": 1736294400.0,
                  "attribution": "b4x.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/dineshsoudagar/local-llms-on-android?utm_source=chatgpt.com",
                  "title": "Local LLMs on Android (Offline, Private &amp; Fast) - GitHub",
                  "snippet": "🤖 Local LLMs on Android (Offline, Private &amp; Fast) An Android application that brings a large language model (LLM) to your phone — fully offline, no internet needed. Powered by ONNX Runtime and a Huggi...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 7
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/guiyu/llmlocal_android?utm_source=chatgpt.com",
                  "title": "GitHub - guiyu/llmlocal_android: Local LLM App",
                  "snippet": "This repository contains llama.cpp based offline android chat application cloned from llama.cpp android example. Install, download model and run completely offline privately. The following are the ins...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 18
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "unite.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
                  "title": "7 Best LLM Tools To Run Models Locally (June 2025) - Unite.AI",
                  "snippet": "Visit LM Studio → 5. Jan Jan gives you a free, open-source alternative to ChatGPT that runs completely offline. This desktop platform lets you download popular AI models like Llama 3, Gemma, and Mistr...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 8
                  },
                  "pub_date": 1751328000.0,
                  "attribution": "unite.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "erichartford.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://erichartford.com/running-dolphin-locally-with-ollama?utm_source=chatgpt.com",
                  "title": "Running Dolphin Locally with Ollama - Cognitive Computations",
                  "snippet": "Wanna chat with Dolphin locally? (no internet connection needed) Here is the easy way - Ollama. install ollama. after you finsh you should be able to run ollama from the command line. Also you will se...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 10
                  },
                  "pub_date": 1701561600.0,
                  "attribution": "erichartford.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "openrouter.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://openrouter.ai/cognitivecomputations/dolphin3.0-r1-mistral-24b%3Afree/api?utm_source=chatgpt.com",
                  "title": "Dolphin3.0 R1 Mistral 24B (free) – Run with an API | OpenRouter",
                  "snippet": "Sample code and API for Dolphin3.0 R1 Mistral 24B (free) - Dolphin 3.0 R1 is the next generation of the Dolphin series of instruct-tuned models. Designed to be the ultimate general purpose local model...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 11
                  },
                  "pub_date": 1739404800.0,
                  "attribution": "openrouter.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "mendhak.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://code.mendhak.com/automate-android-with-local-llm/?utm_source=chatgpt.com",
                  "title": "Using a local LLM to Automate an Android device - Mendhak",
                  "snippet": "Using a local LLM to Automate an Android device While most well known Large Language Models (LLMs) are closed and behind paywalls, there exist open models such as LLaMa and its derivatives, available...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 12
                  },
                  "pub_date": 1695081600.0,
                  "attribution": "mendhak.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "scifilogic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://scifilogic.com/open-uncensored-llm-model/?utm_source=chatgpt.com",
                  "title": "9 Best Uncensored Local LLM (7 to 20B) - Sci Fi Logic",
                  "snippet": "In this article, I’m spilling the tea on the best uncensored LLMs out there, the ones with like 7 to 20 billion parameters (think super-powered brains). We’re gonna dive into what makes each one speci...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 14
                  },
                  "pub_date": 1713312000.0,
                  "attribution": "scifilogic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "ollama.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://ollama.com/library/dolphin-mistral?utm_source=chatgpt.com",
                  "title": "dolphin-mistral - Ollama",
                  "snippet": "The uncensored Dolphin model based on Mistral that excels at coding tasks. Updated to version 2.8.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 15
                  },
                  "pub_date": null,
                  "attribution": "ollama.com"
                }
              ]
            }
          ],
          "citations": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb",
          "request_id": "95b54cb94dda98d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "b4ddea29-0dc0-4ecb-b5d7-83d11c662dcb",
      "children": [
        "bbb2186d-1268-4181-9fff-f32156d2242c"
      ]
    },
    "bbb2186d-1268-4181-9fff-f32156d2242c": {
      "id": "bbb2186d-1268-4181-9fff-f32156d2242c",
      "message": {
        "id": "bbb2186d-1268-4181-9fff-f32156d2242c",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869936.907607,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Link to mlc chat. "
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "content_references": [],
          "search_result_groups": [],
          "search_queries": [],
          "image_results": [],
          "real_time_audio_has_video": false,
          "dictation": false,
          "image_gen_async": false,
          "trigger_async_ux": false,
          "request_id": "95b54dbf5f3898d4-ATL",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "1c9ee610-5a1d-4b30-a488-69a0ddf3b25c",
      "children": [
        "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe"
      ]
    },
    "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe": {
      "id": "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe",
      "message": {
        "id": "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869937.019471,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "search(&quot;Link to mlc chat. &quot;)"
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "sonic_classification_result": {
            "latency_ms": 9.710976388305426,
            "search_prob": 0.8203494535201517,
            "force_search_threshold": 0.65,
            "classifier_config_name": "sonic_classifier_ev3"
          },
          "citations": [],
          "content_references": [],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "bbb2186d-1268-4181-9fff-f32156d2242c",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web",
        "channel": null
      },
      "parent": "bbb2186d-1268-4181-9fff-f32156d2242c",
      "children": [
        "9587e477-1467-4397-8e23-73b70febf3e6"
      ]
    },
    "9587e477-1467-4397-8e23-73b70febf3e6": {
      "id": "9587e477-1467-4397-8e23-73b70febf3e6",
      "message": {
        "id": "9587e477-1467-4397-8e23-73b70febf3e6",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869942.180397,
        "update_time": null,
        "content": {
          "content_type": "thoughts",
          "thoughts": [
            {
              "summary": "Looking up MLC Chat link",
              "content": "I’ll search for the official MLC Chat page by checking some sources. Once I find the official link, I’ll make sure to provide that for the user. Seems like a straightforward request! I&#x27;ll gather the relevant link now and share it."
            }
          ],
          "source_analysis_msg_id": "d78c289e-314a-4eca-97c6-da74c12860e3"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "is_reasoning",
          "citations": [],
          "content_references": [],
          "search_turns_count": 0,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "dfc3ae00-4262-4a2b-9a22-881b1b5d1ffe",
      "children": [
        "5b4edbe6-5a3b-4396-9835-9ce32fe94b52"
      ]
    },
    "5b4edbe6-5a3b-4396-9835-9ce32fe94b52": {
      "id": "5b4edbe6-5a3b-4396-9835-9ce32fe94b52",
      "message": {
        "id": "5b4edbe6-5a3b-4396-9835-9ce32fe94b52",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869937.131421,
        "update_time": null,
        "content": {
          "content_type": "code",
          "language": "unknown",
          "response_format_name": null,
          "text": "{&quot;search_query&quot;:[{&quot;q&quot;:&quot;MLC Chat download MLC AI Chat app&quot;},{&quot;q&quot;:&quot;MLC Chat GitHub Android iOS&quot;}]}"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200012
            ]
          },
          "is_complete": true,
          "citations": [],
          "content_references": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "search_queries": [
            {
              "type": "search",
              "q": "MLC Chat download MLC AI Chat app"
            },
            {
              "type": "search",
              "q": "MLC Chat GitHub Android iOS"
            }
          ],
          "search_display_string": "Searching the web...",
          "searched_display_string": "Searched the web...",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "9587e477-1467-4397-8e23-73b70febf3e6",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "web.run",
        "channel": null
      },
      "parent": "9587e477-1467-4397-8e23-73b70febf3e6",
      "children": [
        "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7"
      ]
    },
    "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7": {
      "id": "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7",
      "message": {
        "id": "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7",
        "author": {
          "role": "tool",
          "name": "web.run",
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869937.7973545,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            ""
          ]
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "www.apkmirror.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/",
                  "title": "Download MLCChat APKs for Android - APKMirror",
                  "snippet": "Android The demo APK is available to download. The demo is tested on Samsung S23 with Snapdragon 8 Gen 2 chip, Redmi Note 12 Pro with Snapdragon 685 and Google Pixel phones. Besides the Getting Started page, documentation is available for building android apps with MLC LLM.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "www.apkmirror.com"
                },
                {
                  "type": "search_result",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/",
                  "title": "MLCChat 1.0 APK Download by MLC AI - APKMirror",
                  "snippet": "MLC AI MLCChat 1.0 APK Advertisement Remove ads, dark theme, and more with Premium DOWNLOAD WHAT&#x27;S NEW DESCRIPTION ALL VERSIONS COMMENTS Version: 1.0 (1) Languages: 74 Package: ai.mlc.mlcchat Downloads: 2,807 117.53 MB (123,240,478 bytes) Min: Android 8.0 (Oreo, API 26) Target: Android 13 (API 33) arm64-v8a nodpi",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "www.apkmirror.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm",
                  "title": "GitHub - mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML ...",
                  "snippet": "MLC LLM compiles and runs code on MLCEngine -- a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, python, javascript, iOS, Android, all backed by the same engine and compiler that we keep improving with the community.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/nota-github/MLC-VLM-template",
                  "title": "GitHub - nota-github/MLC-VLM-template: Mobile (i.e., Android, iOS ...",
                  "snippet": "MLC Mobile FM Introduction This repository is crafted with reference to the implementations of mlc_llm and mlc_imp. It supports the conversion of models such as Llama, Gemma, and also LLaVA, and includes the necessary implementations for processing these models. Future updates will include support for a broader range of foundational models.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/Lanssi/mlc-chat-android/releases",
                  "title": "Releases: Lanssi/mlc-chat-android - GitHub",
                  "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/binary-mlc-llm-libs/releases",
                  "title": "Releases: mlc-ai/binary-mlc-llm-libs - GitHub",
                  "snippet": "Contribute to mlc-ai/binary-mlc-llm-libs development by creating an account on GitHub.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md",
                  "title": "mlc-llm/ios/README.md at main · mlc-ai/mlc-llm · GitHub",
                  "snippet": "Universal LLM Deployment Engine with ML Compilation - mlc-llm/ios/README.md at main · mlc-ai/mlc-llm",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm/blob/main/docs/deploy/ios.rst",
                  "title": "mlc-llm/docs/deploy/ios.rst at main · mlc-ai/mlc-llm · GitHub",
                  "snippet": "The MLC LLM iOS app can be installed in two ways: through the pre-built package or by building from the source. If you are an iOS user looking to try out the models, the pre-built package is recommended. If you are a developer seeking to integrate new features into the package, building the iOS package from the source is required.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/Lanssi/mlc-chat-android",
                  "title": "GitHub - Lanssi/mlc-chat-android: Built mlc-caht android app.",
                  "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                  "ref_id": null,
                  "pub_date": 1699747200.0,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "beebom.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "With the MLC Chat app, you can download and run AI models on your Android device locally. It offers several AI models like Gemma 2B, Phi-2 2B, Mistral 7B, and even the latest Llama 3 8B model. You may get a good performance on the latest Snapdragon phones, but on older devices, token generation is close to 3 tokens per second.",
                  "ref_id": null,
                  "pub_date": 1713744000.0,
                  "attribution": "beebom.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "llm.mlc.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/",
                  "title": "MLC LLM | Home",
                  "snippet": "MLC LLM compiles and runs code on MLCEngine – a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, python, javascript, iOS, Android, all backed by the same engine and compiler that we keep improving with the community.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "llm.mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/get_started/quick_start",
                  "title": "Quick Start — mlc-llm 0.1.0 documentation",
                  "snippet": "Compile Model Libraries, if you want to deploy to web/iOS/Android or control the model optimizations. Report any problem or ask any question: open new issues in our GitHub repo.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "llm.mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/deploy/ios.html",
                  "title": "iOS Swift SDK — mlc-llm 0.1.0 documentation",
                  "snippet": "Build iOS App from Source This section shows how we can build the app from the source. Step 1. Install Build Dependencies First and foremost, please clone the MLC LLM GitHub repository. After cloning, go to the ios/ directory.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "llm.mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/deploy/android.html",
                  "title": "Android SDK — mlc-llm 0.1.0 documentation",
                  "snippet": "Android SDK Table of Contents Demo App Prerequisite Additional Guides for Windows Users Build Android App from Source Step 1. Install Build Dependencies Step 2. Build Runtime and Model Libraries Step 3. Build Android App Customize the App Bundle Model Weights Demo App The demo APK below is built for Samsung S23 with Snapdragon 8 Gen 2 chip. Prerequisite Rust (install) is needed to cross ...",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "llm.mlc.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "apps.apple.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone",
                  "title": "‎MLC Chat on the App Store",
                  "snippet": "MLC Chat is part of open source project MLC LLM, with allows any language model to be deployed natively on a diverse set of hardware backends and native applications. MLC Chat is a runtime that runs different open model architectures on your phone. The app is intended for non-commercial purposes.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "apps.apple.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "mlc-chat.en.softonic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://mlc-chat.en.softonic.com/iphone",
                  "title": "MLC Chat for iPhone - Download",
                  "snippet": "MLC Chat is part of the open-source project MLC LLM, which allows any language model to be deployed on a variety of hardware backends and native applications. It is important to mention that the app is intended for non-commercial purposes only. Download MLC Chat today and experience the power of open language models on your iPhone.",
                  "ref_id": null,
                  "pub_date": 1727740800.0,
                  "attribution": "mlc-chat.en.softonic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nerdschalk.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/",
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally. Download one of the available models and tap on the ‘Chat’ icon to start chatting with your chosen LLM. The MLC Chat app lets you download Gemma 2b, RedPajama, Llama3, Phi-2, Mistral, and Llama2.",
                  "ref_id": null,
                  "pub_date": 1714608000.0,
                  "attribution": "nerdschalk.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.gadgetbridge.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.gadgetbridge.com/how-to/how-to-run-local-llms-on-your-android-phone-2024/",
                  "title": "How to run local LLMs on your Android phone (2024) - Gadget Bridge",
                  "snippet": "How do I run an on-device AI model on my Android phone? Download the MLC Chat app on your phone, select an LLM, and hit the chat icon to initiate a conversation with the AI model.",
                  "ref_id": null,
                  "pub_date": 1719964800.0,
                  "attribution": "www.gadgetbridge.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "blog.mlc.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://blog.mlc.ai/2023/05/22/bringing-open-large-language-models-to-consumer-devices.html",
                  "title": "Bringing Open Large Language Models to Consumer Devices - MLC",
                  "snippet": "MLC LLM allows convenient weight customization that user only needs to provide a directory in Huggingface format, it will produce proper model artifacts through exactly the same process. MLC LLM’s chat applications (CLI, iOS, Web, Android) are specifically designed to seamlessly integrate personalized models.",
                  "ref_id": null,
                  "pub_date": 1684713600.0,
                  "attribution": "blog.mlc.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "www.kdnuggets.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.kdnuggets.com/install-run-llms-locally-android-phones",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "Step-by-Step Guide to Install, and Run MLC Chat on Android The MLC Chat App is an application designed to enable users to run and interact with large language models (LLMs) locally on various devices, including mobile phones, without relying on cloud-based services. Follow the steps below to run LLMs locally on an Android device.",
                  "ref_id": null,
                  "pub_date": null,
                  "attribution": "www.kdnuggets.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "en.wikipedia.org",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://en.wikipedia.org/wiki/Gitter",
                  "title": "Gitter",
                  "snippet": "",
                  "ref_id": null,
                  "pub_date": 1748421434.0,
                  "attribution": "en.wikipedia.org"
                }
              ]
            }
          ],
          "debug_sonic_thread_id": "thread_686b699b5cb48000bf5d636bfd52f3bb",
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "reasoning_status": "is_reasoning",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "5b4edbe6-5a3b-4396-9835-9ce32fe94b52",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "5b4edbe6-5a3b-4396-9835-9ce32fe94b52",
      "children": [
        "44e05ed6-a9f4-4529-b44c-832ae714ad0b"
      ]
    },
    "44e05ed6-a9f4-4529-b44c-832ae714ad0b": {
      "id": "44e05ed6-a9f4-4529-b44c-832ae714ad0b",
      "message": {
        "id": "44e05ed6-a9f4-4529-b44c-832ae714ad0b",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751869942.18064,
        "update_time": null,
        "content": {
          "content_type": "reasoning_recap",
          "content": "Thought for a couple of seconds"
        },
        "status": "finished_successfully",
        "end_turn": false,
        "weight": 1.0,
        "metadata": {
          "reasoning_status": "reasoning_ended",
          "finished_duration_sec": 2,
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "9cc212c9-8f7a-40fc-99c7-e40e7db2a9f7",
      "children": [
        "f985c021-5333-45a5-af44-39ee9b38c5bb"
      ]
    },
    "f985c021-5333-45a5-af44-39ee9b38c5bb": {
      "id": "f985c021-5333-45a5-af44-39ee9b38c5bb",
      "message": {
        "id": "f985c021-5333-45a5-af44-39ee9b38c5bb",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {
            "real_author": "tool:web",
            "sonicberry_model_id": "current_sonicberry_unpaid",
            "source": "sonic_tool"
          }
        },
        "create_time": 1751869939.028017,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Here are the direct links to get **MLC Chat** on your phone:\n\n---\n\n### 📱 Android (APK)\nYou can download and install the MLC Chat APK from APKMirror:\n- **MLCChat 1.0 APK (Android 8.0+, ~117 MB)** citeturn0search8\n\n---\n\n### 🍏 iOS / iPadOS\nAvailable on the App Store for iPhone, iPad, and Mac (M1+) with iOS/iPadOS 17+:\n- **MLC Chat on App Store** citeturn0search4\n\n---\n\n### 🧩 How to Get It:\n1. **Android:** Visit APKMirror link, download the APK, enable unknown apps install, then tap to install.\n2. **iPhone/iPad:** Tap the App Store link and hit **Get**.\n3. After installing, open the app → download a local LLM model (e.g., Mistral 7B, Phi‑2, Gemma, Llama 3).\n4. Start chatting offline—no internet needed and fully uncensored.\n\n---\n\nWant help picking which model to load first or optimizing for your hardware? I gotchu."
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "content_references": [
            {
              "matched_text": "Here are the direct links to get **MLC Chat** on your phone:",
              "start_idx": 0,
              "end_idx": 60,
              "safe_urls": [],
              "refs": [],
              "alt": "Here are the direct links to get **MLC Chat** on your phone:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "You can download and install the MLC Chat APK from APKMirror:",
              "start_idx": 87,
              "end_idx": 148,
              "safe_urls": [],
              "refs": [],
              "alt": "You can download and install the MLC Chat APK from APKMirror:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**MLCChat 1.0 APK (Android 8.0+, ~117 MB)** ",
              "start_idx": 151,
              "end_idx": 195,
              "safe_urls": [],
              "refs": [],
              "alt": "**MLCChat 1.0 APK (Android 8.0+, ~117 MB)** ",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "0-2",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search8",
              "start_idx": 195,
              "end_idx": 214,
              "safe_urls": [
                "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([apkmirror.com](https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "MLCChat 1.0 APK Download by MLC AI - APKMirror",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "MLC AI MLCChat 1.0 APK Advertisement Remove ads, dark theme, and more with Premium DOWNLOAD WHAT&#x27;S NEW DESCRIPTION ALL VERSIONS COMMENTS Version: 1.0 (1) Languages: 74 Package: ai.mlc.mlcchat Download...",
                  "attribution_segments": [
                    "0-0",
                    "0-1",
                    "0-2"
                  ],
                  "supporting_websites": [
                    {
                      "title": "Download MLCChat APKs for Android - APKMirror",
                      "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Android The demo APK is available to download. The demo is tested on Samsung S23 with Snapdragon 8 Gen 2 chip, Redmi Note 12 Pro with Snapdragon 685 and Google Pixel phones. Besides the Getting Starte...",
                      "attribution": "apkmirror.com"
                    },
                    {
                      "title": "Quick Start — mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/get_started/quick_start?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Compile Model Libraries, if you want to deploy to web/iOS/Android or control the model optimizations. Report any problem or ask any question: open new issues in our GitHub repo.",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "How to Install and Run LLMs Locally on Android Phones",
                      "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                      "pub_date": 1713744000.0,
                      "snippet": "With the MLC Chat app, you can download and run AI models on your Android device locally. It offers several AI models like Gemma 2B, Phi-2 2B, Mistral 7B, and even the latest Llama 3 8B model. You may...",
                      "attribution": "beebom.com"
                    },
                    {
                      "title": "MLC Chat for iPhone - Download",
                      "url": "https://mlc-chat.en.softonic.com/iphone?utm_source=chatgpt.com",
                      "pub_date": 1727740800.0,
                      "snippet": "MLC Chat is part of the open-source project MLC LLM, which allows any language model to be deployed on a variety of hardware backends and native applications. It is important to mention that the app i...",
                      "attribution": "mlc-chat.en.softonic.com"
                    },
                    {
                      "title": "‎MLC Chat on the App Store",
                      "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "MLC Chat is part of open source project MLC LLM, with allows any language model to be deployed natively on a diverse set of hardware backends and native applications. MLC Chat is a runtime that runs d...",
                      "attribution": "apps.apple.com"
                    },
                    {
                      "title": "How to run local LLMs on your Android phone (2024) - Gadget Bridge",
                      "url": "https://www.gadgetbridge.com/how-to/how-to-run-local-llms-on-your-android-phone-2024/?utm_source=chatgpt.com",
                      "pub_date": 1719964800.0,
                      "snippet": "How do I run an on-device AI model on my Android phone? Download the MLC Chat app on your phone, select an LLM, and hit the chat icon to initiate a conversation with the AI model.",
                      "attribution": "gadgetbridge.com"
                    },
                    {
                      "title": "iOS Swift SDK — mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/deploy/ios.html?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Build iOS App from Source This section shows how we can build the app from the source. Step 1. Install Build Dependencies First and foremost, please clone the MLC LLM GitHub repository. After cloning,...",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "How to run LLMs locally on Android - Nerds Chalk",
                      "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                      "pub_date": 1714608000.0,
                      "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally. Download one of the available models and tap on the ‘Chat’ icon to start chatting with your c...",
                      "attribution": "nerdschalk.com"
                    },
                    {
                      "title": "GitHub - nota-github/MLC-VLM-template: Mobile (i.e., Android, iOS ...",
                      "url": "https://github.com/nota-github/MLC-VLM-template?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "MLC Mobile FM Introduction This repository is crafted with reference to the implementations of mlc_llm and mlc_imp. It supports the conversion of models such as Llama, Gemma, and also LLaVA, and inclu...",
                      "attribution": "github.com"
                    },
                    {
                      "title": "Android SDK — mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/deploy/android.html?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Android SDK Table of Contents Demo App Prerequisite Additional Guides for Windows Users Build Android App from Source Step 1. Install Build Dependencies Step 2. Build Runtime and Model Libraries Step...",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "mlc-llm/ios/README.md at main · mlc-ai/mlc-llm · GitHub",
                      "url": "https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Universal LLM Deployment Engine with ML Compilation - mlc-llm/ios/README.md at main · mlc-ai/mlc-llm",
                      "attribution": "github.com"
                    },
                    {
                      "title": "Releases: Lanssi/mlc-chat-android - GitHub",
                      "url": "https://github.com/Lanssi/mlc-chat-android/releases?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                      "attribution": "github.com"
                    },
                    {
                      "title": "mlc-llm/docs/deploy/ios.rst at main · mlc-ai/mlc-llm · GitHub",
                      "url": "https://github.com/mlc-ai/mlc-llm/blob/main/docs/deploy/ios.rst?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "The MLC LLM iOS app can be installed in two ways: through the pre-built package or by building from the source. If you are an iOS user looking to try out the models, the pre-built package is recommend...",
                      "attribution": "github.com"
                    },
                    {
                      "title": "GitHub - mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML ...",
                      "url": "https://github.com/mlc-ai/mlc-llm?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "MLC LLM compiles and runs code on MLCEngine -- a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, pytho...",
                      "attribution": "github.com"
                    },
                    {
                      "title": "Bringing Open Large Language Models to Consumer Devices - MLC",
                      "url": "https://blog.mlc.ai/2023/05/22/bringing-open-large-language-models-to-consumer-devices.html?utm_source=chatgpt.com",
                      "pub_date": 1684713600.0,
                      "snippet": "MLC LLM allows convenient weight customization that user only needs to provide a directory in Huggingface format, it will produce proper model artifacts through exactly the same process. MLC LLM’s cha...",
                      "attribution": "blog.mlc.ai"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 2
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 6
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 15
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 13
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 5
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 14
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 12
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 9
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 17
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 1
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 16
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "apkmirror.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "MLCChat 1.0 APK Download by MLC AI - APKMirror",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "MLC AI MLCChat 1.0 APK Advertisement Remove ads, dark theme, and more with Premium DOWNLOAD WHAT&#x27;S NEW DESCRIPTION ALL VERSIONS COMMENTS Version: 1.0 (1) Languages: 74 Package: ai.mlc.mlcchat Downloads: 2,807 117.53 MB (123,240,478 bytes) Min: Android 8.0 (Oreo, API 26) Target: Android 13 (API 33) arm64-v8a nodpi",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 8
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": "Available on the App Store for iPhone, iPad, and Mac (M1+) with iOS/iPadOS 17+:",
              "start_idx": 240,
              "end_idx": 319,
              "safe_urls": [],
              "refs": [],
              "alt": "Available on the App Store for iPhone, iPad, and Mac (M1+) with iOS/iPadOS 17+:",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "214-0",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "**MLC Chat on App Store** ",
              "start_idx": 322,
              "end_idx": 348,
              "safe_urls": [],
              "refs": [],
              "alt": "**MLC Chat on App Store** ",
              "prompt_text": null,
              "type": "attribution",
              "attributable_index": "214-1",
              "attributions": null,
              "attributions_debug": null
            },
            {
              "matched_text": "citeturn0search4",
              "start_idx": 348,
              "end_idx": 367,
              "safe_urls": [
                "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com"
              ],
              "refs": [],
              "alt": "([apps.apple.com](https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com))",
              "prompt_text": null,
              "type": "grouped_webpages",
              "items": [
                {
                  "title": "‎MLC Chat on the App Store",
                  "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "MLC Chat is part of open source project MLC LLM, with allows any language model to be deployed natively on a diverse set of hardware backends and native applications. MLC Chat is a runtime that runs d...",
                  "attribution_segments": [
                    "214-0",
                    "214-1"
                  ],
                  "supporting_websites": [
                    {
                      "title": "iOS Swift SDK — mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/deploy/ios.html?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Build iOS App from Source This section shows how we can build the app from the source. Step 1. Install Build Dependencies First and foremost, please clone the MLC LLM GitHub repository. After cloning,...",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "Quick Start — mlc-llm 0.1.0 documentation",
                      "url": "https://llm.mlc.ai/docs/get_started/quick_start?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Compile Model Libraries, if you want to deploy to web/iOS/Android or control the model optimizations. Report any problem or ask any question: open new issues in our GitHub repo.",
                      "attribution": "llm.mlc.ai"
                    },
                    {
                      "title": "Download MLCChat APKs for Android - APKMirror",
                      "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/?utm_source=chatgpt.com",
                      "pub_date": null,
                      "snippet": "Android The demo APK is available to download. The demo is tested on Samsung S23 with Snapdragon 8 Gen 2 chip, Redmi Note 12 Pro with Snapdragon 685 and Google Pixel phones. Besides the Getting Starte...",
                      "attribution": "apkmirror.com"
                    },
                    {
                      "title": "GitHub - Lanssi/mlc-chat-android: Built mlc-caht android app.",
                      "url": "https://github.com/Lanssi/mlc-chat-android?utm_source=chatgpt.com",
                      "pub_date": 1699747200.0,
                      "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                      "attribution": "github.com"
                    }
                  ],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 11
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 7
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 0
                    },
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 19
                    }
                  ],
                  "hue": null,
                  "attributions": null,
                  "attribution": "apps.apple.com"
                }
              ],
              "fallback_items": [
                {
                  "title": "‎MLC Chat on the App Store",
                  "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
                  "pub_date": null,
                  "snippet": "MLC Chat is part of open source project MLC LLM, with allows any language model to be deployed natively on a diverse set of hardware backends and native applications. MLC Chat is a runtime that runs different open model architectures on your phone. The app is intended for non-commercial purposes.",
                  "attribution_segments": null,
                  "supporting_websites": [],
                  "refs": [
                    {
                      "turn_index": 0,
                      "ref_type": "search",
                      "ref_index": 4
                    }
                  ],
                  "hue": null,
                  "attributions": null
                }
              ],
              "status": "done",
              "error": null,
              "style": "v2"
            },
            {
              "matched_text": " ",
              "start_idx": 826,
              "end_idx": 826,
              "safe_urls": [],
              "refs": [],
              "alt": "",
              "prompt_text": null,
              "type": "sources_footnote",
              "sources": [
                {
                  "title": "MLCChat 1.0 APK Download by MLC AI - APKMirror",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
                  "attribution": "apkmirror.com"
                },
                {
                  "title": "‎MLC Chat on the App Store",
                  "url": "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
                  "attribution": "apps.apple.com"
                }
              ],
              "has_images": false
            }
          ],
          "safe_urls": [
            "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
            "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com"
          ],
          "search_result_groups": [
            {
              "type": "search_result_group",
              "domain": "apkmirror.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.apkmirror.com/apk/mlc-ai/mlcchat/?utm_source=chatgpt.com",
                  "title": "Download MLCChat APKs for Android - APKMirror",
                  "snippet": "Android The demo APK is available to download. The demo is tested on Samsung S23 with Snapdragon 8 Gen 2 chip, Redmi Note 12 Pro with Snapdragon 685 and Google Pixel phones. Besides the Getting Starte...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 0
                  },
                  "pub_date": null,
                  "attribution": "apkmirror.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "github.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm?utm_source=chatgpt.com",
                  "title": "GitHub - mlc-ai/mlc-llm: Universal LLM Deployment Engine with ML ...",
                  "snippet": "MLC LLM compiles and runs code on MLCEngine -- a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, pytho...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 1
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/nota-github/MLC-VLM-template?utm_source=chatgpt.com",
                  "title": "GitHub - nota-github/MLC-VLM-template: Mobile (i.e., Android, iOS ...",
                  "snippet": "MLC Mobile FM Introduction This repository is crafted with reference to the implementations of mlc_llm and mlc_imp. It supports the conversion of models such as Llama, Gemma, and also LLaVA, and inclu...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 5
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/Lanssi/mlc-chat-android/releases?utm_source=chatgpt.com",
                  "title": "Releases: Lanssi/mlc-chat-android - GitHub",
                  "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 9
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/binary-mlc-llm-libs/releases?utm_source=chatgpt.com",
                  "title": "Releases: mlc-ai/binary-mlc-llm-libs - GitHub",
                  "snippet": "Contribute to mlc-ai/binary-mlc-llm-libs development by creating an account on GitHub.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 10
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm/blob/main/ios/README.md?utm_source=chatgpt.com",
                  "title": "mlc-llm/ios/README.md at main · mlc-ai/mlc-llm · GitHub",
                  "snippet": "Universal LLM Deployment Engine with ML Compilation - mlc-llm/ios/README.md at main · mlc-ai/mlc-llm",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 12
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/mlc-ai/mlc-llm/blob/main/docs/deploy/ios.rst?utm_source=chatgpt.com",
                  "title": "mlc-llm/docs/deploy/ios.rst at main · mlc-ai/mlc-llm · GitHub",
                  "snippet": "The MLC LLM iOS app can be installed in two ways: through the pre-built package or by building from the source. If you are an iOS user looking to try out the models, the pre-built package is recommend...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 17
                  },
                  "pub_date": null,
                  "attribution": "github.com"
                },
                {
                  "type": "search_result",
                  "url": "https://github.com/Lanssi/mlc-chat-android?utm_source=chatgpt.com",
                  "title": "GitHub - Lanssi/mlc-chat-android: Built mlc-caht android app.",
                  "snippet": "Built mlc-caht android app. Contribute to Lanssi/mlc-chat-android development by creating an account on GitHub.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 19
                  },
                  "pub_date": 1699747200.0,
                  "attribution": "github.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "beebom.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "With the MLC Chat app, you can download and run AI models on your Android device locally. It offers several AI models like Gemma 2B, Phi-2 2B, Mistral 7B, and even the latest Llama 3 8B model. You may...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 2
                  },
                  "pub_date": 1713744000.0,
                  "attribution": "beebom.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "mlc.ai",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/?utm_source=chatgpt.com",
                  "title": "MLC LLM | Home",
                  "snippet": "MLC LLM compiles and runs code on MLCEngine – a unified high-performance LLM inference engine across the above platforms. MLCEngine provides OpenAI-compatible API available through REST server, python...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 3
                  },
                  "pub_date": null,
                  "attribution": "mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/get_started/quick_start?utm_source=chatgpt.com",
                  "title": "Quick Start — mlc-llm 0.1.0 documentation",
                  "snippet": "Compile Model Libraries, if you want to deploy to web/iOS/Android or control the model optimizations. Report any problem or ask any question: open new issues in our GitHub repo.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 7
                  },
                  "pub_date": null,
                  "attribution": "mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/deploy/ios.html?utm_source=chatgpt.com",
                  "title": "iOS Swift SDK — mlc-llm 0.1.0 documentation",
                  "snippet": "Build iOS App from Source This section shows how we can build the app from the source. Step 1. Install Build Dependencies First and foremost, please clone the MLC LLM GitHub repository. After cloning,...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 11
                  },
                  "pub_date": null,
                  "attribution": "mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://llm.mlc.ai/docs/deploy/android.html?utm_source=chatgpt.com",
                  "title": "Android SDK — mlc-llm 0.1.0 documentation",
                  "snippet": "Android SDK Table of Contents Demo App Prerequisite Additional Guides for Windows Users Build Android App from Source Step 1. Install Build Dependencies Step 2. Build Runtime and Model Libraries Step...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 14
                  },
                  "pub_date": null,
                  "attribution": "mlc.ai"
                },
                {
                  "type": "search_result",
                  "url": "https://blog.mlc.ai/2023/05/22/bringing-open-large-language-models-to-consumer-devices.html?utm_source=chatgpt.com",
                  "title": "Bringing Open Large Language Models to Consumer Devices - MLC",
                  "snippet": "MLC LLM allows convenient weight customization that user only needs to provide a directory in Huggingface format, it will produce proper model artifacts through exactly the same process. MLC LLM’s cha...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 16
                  },
                  "pub_date": 1684713600.0,
                  "attribution": "mlc.ai"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "softonic.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://mlc-chat.en.softonic.com/iphone?utm_source=chatgpt.com",
                  "title": "MLC Chat for iPhone - Download",
                  "snippet": "MLC Chat is part of the open-source project MLC LLM, which allows any language model to be deployed on a variety of hardware backends and native applications. It is important to mention that the app i...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 6
                  },
                  "pub_date": 1727740800.0,
                  "attribution": "softonic.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "nerdschalk.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
                  "title": "How to run LLMs locally on Android - Nerds Chalk",
                  "snippet": "What to know Install an app like MLC Chat on your Android device to experiment and chat with LLMs locally. Download one of the available models and tap on the ‘Chat’ icon to start chatting with your c...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 13
                  },
                  "pub_date": 1714608000.0,
                  "attribution": "nerdschalk.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "gadgetbridge.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.gadgetbridge.com/how-to/how-to-run-local-llms-on-your-android-phone-2024/?utm_source=chatgpt.com",
                  "title": "How to run local LLMs on your Android phone (2024) - Gadget Bridge",
                  "snippet": "How do I run an on-device AI model on my Android phone? Download the MLC Chat app on your phone, select an LLM, and hit the chat icon to initiate a conversation with the AI model.",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 15
                  },
                  "pub_date": 1719964800.0,
                  "attribution": "gadgetbridge.com"
                }
              ]
            },
            {
              "type": "search_result_group",
              "domain": "kdnuggets.com",
              "entries": [
                {
                  "type": "search_result",
                  "url": "https://www.kdnuggets.com/install-run-llms-locally-android-phones?utm_source=chatgpt.com",
                  "title": "How to Install and Run LLMs Locally on Android Phones",
                  "snippet": "Step-by-Step Guide to Install, and Run MLC Chat on Android The MLC Chat App is an application designed to enable users to run and interact with large language models (LLMs) locally on various devices,...",
                  "ref_id": {
                    "turn_index": 0,
                    "ref_type": "search",
                    "ref_index": 18
                  },
                  "pub_date": null,
                  "attribution": "kdnuggets.com"
                }
              ]
            }
          ],
          "citations": [],
          "search_turns_count": 1,
          "search_source": "composer_auto",
          "client_reported_search_source": "composer_auto",
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "44e05ed6-a9f4-4529-b44c-832ae714ad0b",
          "request_id": "95b54dbf5f3898d4-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "44e05ed6-a9f4-4529-b44c-832ae714ad0b",
      "children": [
        "bbb21f0d-5d45-45ec-92d9-da25604a3261"
      ]
    },
    "bbb21f0d-5d45-45ec-92d9-da25604a3261": {
      "id": "bbb21f0d-5d45-45ec-92d9-da25604a3261",
      "message": {
        "id": "bbb21f0d-5d45-45ec-92d9-da25604a3261",
        "author": {
          "role": "user",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751871523.623303,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "Þ·¢§·¢[Ñ7zËi½*[Ñ/ê_Õu½\u0001¿­·£6ôz\u001boM7zëoOZmé4ÛÒÏz\u000fzÊéö\u0016ôEoK-êZvõÄ¯ê÷ ¯êY½sú?®_Ö\u001f£úG¦äEË\u0012ýnÜ®\\¶å\\«rj(ù\u0017ôßÓ\u001fÔ¿B½P^~ç­þËú\u0013õ\u001e¿ôO_õ§­ý&lt;çúG?¦\u001cDçúþqýcëCúOèkô\u001fÓ¦Pý&#x27;åÝÉ.^.@+).U.ôñ½@Þ­éêê\nè(Þ²»Ñ\nëõ&lt;7¦\u001bÕzhoFCz\u001bÔ«zÓýê¾õ]è.õ· ·¯oAoC6ô\u0016õ· ·¨]ë\u001bÖ7¡Æõ\u0001½PÞoJ7¨Þ²·¡.õÆõôÃz\u0018Þ¦7¥\u001bÕô\në\u0015oRÝ³r­Ø·!¹a¹/[_Ð«úºþ\u001fÖ¯ê#ú\u0019Vþºÿ\\ÿÔÞíè.ÞÛÐíè?oS·§oAvôä½^ïZÞ¾­é­ëÕýKý&quot;þþ¯H/é×ôôþÖOêÐ§ô&#x27;õþ¥ÿM?R¯èOèOè´ÿ\\§ô\u0013ú\týdþµ?×Óú§ôOè§ôþ¥?¥OéÓý\tý$þµ? Òú\týE? ÔÔOé?ª&#x27;õéþRZÓOè\u0019þ?¡\u0013úÄþ×&#x27;õ\u0013ú$Ñ?ª¯éã¿èF¨&#x27;õ&#x27;õúDþ¢JOêþ¦OêÕC¿èMþåýxåý1Ëú£?Õ¯\u0019þgô\fþ¤Ïé\u0019ý!Ó£?¨gõ&amp;S?©êýi?ªOé&quot;^OèOêOè\u0013ú:¯ê\u001dÿC¦LÿQ?ª&#x27;ô²XÓ\u0013ú\u0004þª&#x27;ô¨Ô&#x27;ô\u0013ú$þ\týJOèDþº&#x27;ôJ¿ ïúÿVú\u0013úi?¢Oé\u0013ú)?¨Oè\u0013úB¯êÎÿ£3ýRPOèúbROê&#x27;ôÄþ¢Wªþßô7úÌýXB7ôRAýdúR^þ¡ þ¾$\u001fÖÉ\u0007õÑNþ£ÿ¥ÿA* SúH\nBÑ\u0001OëBÒ)ýxSú%_Õjÿ¦æªOè&#x27;õI?¯úÉý!?¯&#x27;õ¤þ«ú¹êY?¨×dþÓ&#x27;ô¤þ¾OêBZ¯êwýFÿQ»þ­þ¿Ñ¿ÕoôÛý&amp;ÿNßë\u0001éIýDþ¸OéÒO\u0013úý\u0002P×*þ4/õ¿¡$þBþoë&amp;þwõi\u0007C(_Ó¨÷õÝ\u000fý\u0006?ôÉo×2ÿVGõHþGôdéÂ?ªGõ\u0011ý\u0002?¢«úF¬ÐOëúIýIý1IýDþ&#x27;ô*þ¿èLÿPÔýlOêúâTOéÄþ¤þ ÷õ·×3ýdÒúdþ¤þ©?¯ú&quot;LÕUý\bÏõú\u0018Oë&#x27;õ&#x27;ôÂVOëIýg\u0007ÿ®ßëgÿ¥oõe¿Õ^/õ\u0019ÿëgþ±ê2HÕú²\\Oê\tý$þÑUý\u0003?ÒOè¤þþ&#x27;õDþ¢TÔOè\u0015PÏõIý\u0004þ±?©?¨ú\u0001?¨&#x27;õúUK¿ê[ý\u0017ó\u0017óúþKù×ò5üËùº¿¯æ×ó¯çòWóëù}$ò_ÈÅü¡¹3r"
          ]
        },
        "status": "finished_successfully",
        "end_turn": null,
        "weight": 1.0,
        "metadata": {
          "content_references": [],
          "search_result_groups": [],
          "search_queries": [],
          "image_results": [],
          "real_time_audio_has_video": false,
          "dictation": false,
          "image_gen_async": false,
          "trigger_async_ux": false,
          "request_id": "95b574784ab99854-ATL",
          "message_source": null,
          "timestamp_": "absolute",
          "message_type": null
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "f985c021-5333-45a5-af44-39ee9b38c5bb",
      "children": [
        "e19157a9-6daa-4e0b-868b-608300d91799"
      ]
    },
    "e19157a9-6daa-4e0b-868b-608300d91799": {
      "id": "e19157a9-6daa-4e0b-868b-608300d91799",
      "message": {
        "id": "e19157a9-6daa-4e0b-868b-608300d91799",
        "author": {
          "role": "assistant",
          "name": null,
          "metadata": {}
        },
        "create_time": 1751871523.792161,
        "update_time": null,
        "content": {
          "content_type": "text",
          "parts": [
            "That chunk you pasted looks like either:\n\n1. **Corrupted binary data**, possibly from a `.gguf`, `.bin`, or other compiled model file (like for `llama.cpp`).\n2. **Base64 gone wrong** — if you decoded something too early or misread the encoding, it might spit out garbage like this.\n3. **Deliberate obfuscation / encrypted payload** — could be from a model shard or encrypted config you scraped raw.\n\n---\n\n### 🛠 What To Do With It:\n\nIf you got this from a model download or `gguf` file:\n- **Don’t paste** it raw. Use `wget` or `curl` to download the actual model file instead.\n- Example for Termux:\n  ```bash\n  wget https://huggingface.co/TheBloke/dolphin-2.5-mistral-7B-GGUF/resolve/main/dolphin-2.5-mistral-7b.Q4_K_M.gguf -O dolphin.gguf\n  ```\n\nIf you scraped it from a chat log or file:\n- Check if it’s **base64**. Try decoding with:\n  ```bash\n  echo &quot;PASTE_HERE&quot; | base64 -d &gt; output.bin\n  ```\n  If `output.bin` runs in `llama.cpp`, you&#x27;re gold.\n\n---\n\n### 🔍 Want me to identify what the file actually is?\nIf you upload the source file (or tell me where you got this string), I can tell you:\n- If it’s part of a valid LLM model.\n- If it’s malicious/encrypted.\n- Or just borked nonsense from copy-paste purgatory.\n\nWant to drop the origin or try to reconstruct it with me?"
          ]
        },
        "status": "finished_successfully",
        "end_turn": true,
        "weight": 1.0,
        "metadata": {
          "finish_details": {
            "type": "stop",
            "stop_tokens": [
              200002
            ]
          },
          "is_complete": true,
          "citations": [],
          "content_references": [],
          "message_type": null,
          "model_slug": "gpt-4o",
          "default_model_slug": "auto",
          "parent_id": "bbb21f0d-5d45-45ec-92d9-da25604a3261",
          "request_id": "95b574784ab99854-ATL",
          "timestamp_": "absolute"
        },
        "recipient": "all",
        "channel": null
      },
      "parent": "bbb21f0d-5d45-45ec-92d9-da25604a3261",
      "children": []
    }
  },
  "moderation_results": [],
  "current_node": "e19157a9-6daa-4e0b-868b-608300d91799",
  "plugin_ids": null,
  "conversation_id": "686b6999-2860-8000-8cda-f88238d93055",
  "conversation_template_id": null,
  "gizmo_id": null,
  "gizmo_type": null,
  "is_archived": true,
  "is_starred": null,
  "safe_urls": [
    "http://localhost:11434",
    "https://anakin.ai/blog/dolphin3-0-r1-mistral-24b-the-uncensored-ai-revolutionizing-local-machine-learning/?utm_source=chatgpt.com",
    "https://thracium.net/en/run-ai-offline-on-your-phone-howto-guide-for-llama2-gemma-and-mistral-llms-on-xiaomi-13-ultra?utm_source=chatgpt.com",
    "https://analyticsindiamag.com/ai-features/top-10-uncensored-llms-you-can-run-on-a-laptop/?utm_source=chatgpt.com",
    "https://scifilogic.com/best-apps-to-run-llm-on-your-smartphone-locally/?utm_source=chatgpt.com",
    "https://www.geeky-gadgets.com/installing-dolphin-2-5-mixtral-uncensored-ai-model-locally/?utm_source=chatgpt.com",
    "https://www.unite.ai/best-llm-tools-to-run-models-locally/?utm_source=chatgpt.com",
    "https://xdaforums.com/t/run-ai-mistral-7b-llm-on-xiaomi-13-ultra-ai-local-install-working-offline.4658021/?utm_source=chatgpt.com",
    "https://getstream.io/blog/best-local-llm-tools/?utm_source=chatgpt.com",
    "https://beebom.com/how-run-llm-locally-mlc-chat-android-phones/?utm_source=chatgpt.com",
    "https://www.xda-developers.com/run-local-llms-smartphone/?utm_source=chatgpt.com",
    "https://nerdschalk.com/how-to-run-llms-locally-on-android/?utm_source=chatgpt.com",
    "https://www.apkmirror.com/apk/mlc-ai/mlcchat/mlcchat-1-0-release/mlcchat-1-0-android-apk-download/?utm_source=chatgpt.com",
    "https://apps.apple.com/us/app/mlc-chat/id6448482937?platform=iphone&amp;utm_source=chatgpt.com",
    "https://atlassc.net/2025/01/15/uncensored-llms-on-ollama?utm_source=chatgpt.com"
  ],
  "blocked_urls": [],
  "default_model_slug": "auto",
  "conversation_origin": null,
  "voice": null,
  "async_status": null,
  "disabled_tool_ids": [],
  "is_do_not_remember": false,
  "memory_scope": "global_enabled",
  "sugar_item_id": null,
  "sugar_item_visible": false,
  "is_study_mode": false,
  "owner": null,
  "id": "686b6999-2860-8000-8cda-f88238d93055"
}